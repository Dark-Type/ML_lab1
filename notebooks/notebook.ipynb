{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:20:40.597237Z",
     "start_time": "2025-03-20T05:20:39.763759Z"
    }
   },
   "source": [
    "!pip3 install catboost\n",
    "!pip3 install optuna"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;31merror\u001B[0m: \u001B[1mexternally-managed-environment\u001B[0m\r\n",
      "\r\n",
      "\u001B[31m×\u001B[0m This environment is externally managed\r\n",
      "\u001B[31m╰─>\u001B[0m To install Python packages system-wide, try brew install\r\n",
      "\u001B[31m   \u001B[0m xyz, where xyz is the package you are trying to\r\n",
      "\u001B[31m   \u001B[0m install.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m If you wish to install a Python library that isn't in Homebrew,\r\n",
      "\u001B[31m   \u001B[0m use a virtual environment:\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m python3 -m venv path/to/venv\r\n",
      "\u001B[31m   \u001B[0m source path/to/venv/bin/activate\r\n",
      "\u001B[31m   \u001B[0m python3 -m pip install xyz\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m If you wish to install a Python application that isn't in Homebrew,\r\n",
      "\u001B[31m   \u001B[0m it may be easiest to use 'pipx install xyz', which will manage a\r\n",
      "\u001B[31m   \u001B[0m virtual environment for you. You can install pipx with\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m brew install pipx\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m You may restore the old behavior of pip by passing\r\n",
      "\u001B[31m   \u001B[0m the '--break-system-packages' flag to pip, or by adding\r\n",
      "\u001B[31m   \u001B[0m 'break-system-packages = true' to your pip.conf file. The latter\r\n",
      "\u001B[31m   \u001B[0m will permanently disable this error.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m If you disable this error, we STRONGLY recommend that you additionally\r\n",
      "\u001B[31m   \u001B[0m pass the '--user' flag to pip, or set 'user = true' in your pip.conf\r\n",
      "\u001B[31m   \u001B[0m file. Failure to do this can result in a broken Homebrew installation.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m Read more about this behavior here: <https://peps.python.org/pep-0668/>\r\n",
      "\r\n",
      "\u001B[1;35mnote\u001B[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\r\n",
      "\u001B[1;36mhint\u001B[0m: See PEP 668 for the detailed specification.\r\n",
      "\u001B[1;31merror\u001B[0m: \u001B[1mexternally-managed-environment\u001B[0m\r\n",
      "\r\n",
      "\u001B[31m×\u001B[0m This environment is externally managed\r\n",
      "\u001B[31m╰─>\u001B[0m To install Python packages system-wide, try brew install\r\n",
      "\u001B[31m   \u001B[0m xyz, where xyz is the package you are trying to\r\n",
      "\u001B[31m   \u001B[0m install.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m If you wish to install a Python library that isn't in Homebrew,\r\n",
      "\u001B[31m   \u001B[0m use a virtual environment:\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m python3 -m venv path/to/venv\r\n",
      "\u001B[31m   \u001B[0m source path/to/venv/bin/activate\r\n",
      "\u001B[31m   \u001B[0m python3 -m pip install xyz\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m If you wish to install a Python application that isn't in Homebrew,\r\n",
      "\u001B[31m   \u001B[0m it may be easiest to use 'pipx install xyz', which will manage a\r\n",
      "\u001B[31m   \u001B[0m virtual environment for you. You can install pipx with\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m brew install pipx\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m You may restore the old behavior of pip by passing\r\n",
      "\u001B[31m   \u001B[0m the '--break-system-packages' flag to pip, or by adding\r\n",
      "\u001B[31m   \u001B[0m 'break-system-packages = true' to your pip.conf file. The latter\r\n",
      "\u001B[31m   \u001B[0m will permanently disable this error.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m If you disable this error, we STRONGLY recommend that you additionally\r\n",
      "\u001B[31m   \u001B[0m pass the '--user' flag to pip, or set 'user = true' in your pip.conf\r\n",
      "\u001B[31m   \u001B[0m file. Failure to do this can result in a broken Homebrew installation.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m Read more about this behavior here: <https://peps.python.org/pep-0668/>\r\n",
      "\r\n",
      "\u001B[1;35mnote\u001B[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\r\n",
      "\u001B[1;36mhint\u001B[0m: See PEP 668 for the detailed specification.\r\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "14b889d84a930772",
   "metadata": {},
   "source": [
    "\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef436265d21bf02c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:23:02.083217Z",
     "start_time": "2025-03-16T13:23:02.081503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's running\n"
     ]
    }
   ],
   "source": [
    "print(\"It's running\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "2096b1bb6184ad6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:20:04.347190Z",
     "start_time": "2025-03-20T05:20:04.291538Z"
    }
   },
   "source": [
    "train_data = pd.read_csv('/Users/nikitaskazutin/ML_lab1/data/train.csv')\n",
    "test_data = pd.read_csv('/Users/nikitaskazutin/ML_lab1/data/test.csv')"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e43cc56c344a98d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:44:26.537210Z",
     "start_time": "2025-03-16T13:44:26.488278Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_spaceship_data(train_data, test_data, val_size=0.2, random_state=42):\n",
    "    print(\"Loading and preparing Spaceship Titanic data with preserved categorical features...\")\n",
    "\n",
    "    print(f\"Training data: {train_data.shape[0]} rows, {train_data.shape[1]} columns\")\n",
    "    print(f\"Test data: {test_data.shape[0]} rows, {test_data.shape[1]} columns\")\n",
    "\n",
    "    train_ids = train_data['PassengerId'].copy() if 'PassengerId' in train_data.columns else None\n",
    "    test_ids = test_data['PassengerId'].copy() if 'PassengerId' in test_data.columns else None\n",
    "\n",
    "    if 'Transported' in train_data.columns:\n",
    "        y = train_data['Transported'].copy()\n",
    "        if y.dtype == bool:\n",
    "            y = y.astype(int)\n",
    "            print(\"Converted boolean target to integer (0/1)\")\n",
    "        X = train_data.drop('Transported', axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"No 'Transported' column found in training data\")\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=val_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"Split into {X_train.shape[0]} training samples and {X_val.shape[0]} validation samples\")\n",
    "\n",
    "    dfs = [\n",
    "        (X_train, 'train'),\n",
    "        (X_val, 'val'),\n",
    "        (test_data, 'test')\n",
    "    ]\n",
    "\n",
    "    combined = pd.concat([df.assign(source=source) for df, source in dfs], axis=0)\n",
    "\n",
    "    if 'PassengerId' in combined.columns:\n",
    "        combined['PassengerGroup'] = combined['PassengerId'].str.split('_').str[0].astype(int)\n",
    "        combined['PassengerNumber'] = combined['PassengerId'].str.split('_').str[1].astype(int)\n",
    "\n",
    "        group_sizes = combined['PassengerGroup'].value_counts()\n",
    "        combined['GroupSize'] = combined['PassengerGroup'].map(group_sizes)\n",
    "        combined['TravelingAlone'] = (combined['GroupSize'] == 1).astype(int)\n",
    "\n",
    "    if 'Cabin' in combined.columns:\n",
    "        combined['CabinDeck'] = 'Unknown'\n",
    "        combined['CabinNum'] = np.nan\n",
    "        combined['CabinSide'] = 'Unknown'\n",
    "        combined['HasCabin'] = combined['Cabin'].notna().astype(int)\n",
    "\n",
    "        cabin_mask = combined['Cabin'].notna()\n",
    "        if cabin_mask.any():\n",
    "            cabin_parts = combined.loc[cabin_mask, 'Cabin'].str.split('/', expand=True)\n",
    "            if cabin_parts.shape[1] >= 3:\n",
    "                combined.loc[cabin_mask, 'CabinDeck'] = cabin_parts[0]\n",
    "                combined.loc[cabin_mask, 'CabinNum'] = pd.to_numeric(cabin_parts[1], errors='coerce')\n",
    "                combined.loc[cabin_mask, 'CabinSide'] = cabin_parts[2]\n",
    "\n",
    "    if 'Name' in combined.columns:\n",
    "        combined['LastName'] = combined['Name'].str.split(' ').str[0]\n",
    "        combined['FirstName'] = combined['Name'].str.split(' ').str[1:].str.join(' ')\n",
    "\n",
    "        family_sizes = combined['LastName'].value_counts()\n",
    "        combined['FamilySize'] = combined['LastName'].map(family_sizes)\n",
    "        combined['HasFamily'] = (combined['FamilySize'] > 1).astype(int)\n",
    "\n",
    "    num_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    for col in num_cols:\n",
    "        if col in combined.columns:\n",
    "            group_medians = combined.groupby('PassengerGroup')[col].transform('median')\n",
    "            combined[col] = combined[col].fillna(group_medians)\n",
    "\n",
    "            if 'HomePlanet' in combined.columns:\n",
    "                planet_medians = combined.groupby('HomePlanet')[col].transform('median')\n",
    "                combined[col] = combined[col].fillna(planet_medians)\n",
    "\n",
    "            combined[col] = combined[col].fillna(combined[col].median())\n",
    "\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    spending_cols = [col for col in spending_cols if col in combined.columns]\n",
    "    if spending_cols:\n",
    "        combined['TotalSpend'] = combined[spending_cols].sum(axis=1)\n",
    "        combined['HasSpent'] = (combined['TotalSpend'] > 0).astype(int)\n",
    "\n",
    "        combined['TotalSpendLog'] = np.log1p(combined['TotalSpend'])\n",
    "        for col in spending_cols:\n",
    "            combined[f'{col}Log'] = np.log1p(combined[col])\n",
    "\n",
    "        for col in spending_cols:\n",
    "            combined[f'{col}Ratio'] = 0\n",
    "            spend_mask = combined['TotalSpend'] > 0\n",
    "            if spend_mask.any():\n",
    "                combined.loc[spend_mask, f'{col}Ratio'] = combined.loc[spend_mask, col] / combined.loc[\n",
    "                    spend_mask, 'TotalSpend']\n",
    "\n",
    "        for col in spending_cols:\n",
    "            combined[f'Used{col}'] = (combined[col] > 0).astype(int)\n",
    "\n",
    "    cat_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n",
    "    cat_cols = [col for col in cat_cols if col in combined.columns]\n",
    "\n",
    "    for col in cat_cols:\n",
    "        for group in combined[combined[col].isna()]['PassengerGroup'].unique():\n",
    "            group_mode = combined[(combined['PassengerGroup'] == group) & combined[col].notna()][col].mode()\n",
    "            if not group_mode.empty:\n",
    "                combined.loc[(combined['PassengerGroup'] == group) & combined[col].isna(), col] = group_mode.iloc[0]\n",
    "\n",
    "        combined[col] = combined[col].fillna(combined[col].mode().iloc[0])\n",
    "\n",
    "    if 'Age' in combined.columns:\n",
    "        combined['AgeGroup'] = pd.cut(\n",
    "            combined['Age'],\n",
    "            bins=[0, 12, 18, 25, 40, 60, 1000],\n",
    "            labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'MiddleAge', 'Senior']\n",
    "        )\n",
    "\n",
    "    if 'CryoSleep' in combined.columns and 'TotalSpend' in combined.columns:\n",
    "        combined['ActiveSpender'] = ((combined['CryoSleep'] == False) & (combined['TotalSpend'] > 0)).astype(int)\n",
    "        combined['CryoSleepSpender'] = ((combined['CryoSleep'] == True) & (combined['TotalSpend'] > 0)).astype(int)\n",
    "\n",
    "    if 'HomePlanet' in combined.columns and 'Destination' in combined.columns:\n",
    "        combined['Route'] = combined['HomePlanet'].astype(str) + \"_to_\" + combined['Destination'].astype(str)\n",
    "\n",
    "    important_cat_cols = [\n",
    "        'HomePlanet', 'Destination', 'CabinDeck', 'CabinSide',\n",
    "        'VIP', 'CryoSleep', 'AgeGroup', 'Route', 'PassengerGroup'\n",
    "    ]\n",
    "\n",
    "    preserved_cat_features = {}\n",
    "\n",
    "    for col in important_cat_cols:\n",
    "        if col in combined.columns:\n",
    "            if combined[col].dtype == 'object' or isinstance(combined[col].dtype, pd.CategoricalDtype):\n",
    "                preserved_cat_features[col] = combined[col].copy()\n",
    "                print(f\"Preserving categorical feature: {col}\")\n",
    "\n",
    "    cols_to_drop = ['Name', 'Cabin', 'PassengerId']\n",
    "    cols_to_drop = [col for col in cols_to_drop if col in combined.columns]\n",
    "    combined = combined.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    cat_cols_to_encode = [\n",
    "        col for col in combined.columns\n",
    "        if col != 'source' and (\n",
    "                combined[col].dtype == 'object' or\n",
    "                isinstance(combined[col].dtype, pd.CategoricalDtype)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    combined = pd.get_dummies(combined, columns=cat_cols_to_encode, drop_first=True)\n",
    "\n",
    "    print(f\"After preprocessing: {combined.shape[1] - 1} features created\")\n",
    "\n",
    "    for col, values in preserved_cat_features.items():\n",
    "        combined[f'cat_{col}'] = values\n",
    "\n",
    "    print(f\"Added {len(preserved_cat_features)} preserved categorical features\")\n",
    "\n",
    "    X_train_proc = combined[combined['source'] == 'train'].drop('source', axis=1)\n",
    "    X_val_proc = combined[combined['source'] == 'val'].drop('source', axis=1)\n",
    "    X_test_proc = combined[combined['source'] == 'test'].drop('source', axis=1)\n",
    "\n",
    "    all_cols = sorted(list(set(X_train_proc.columns) |\n",
    "                           set(X_val_proc.columns) |\n",
    "                           set(X_test_proc.columns)))\n",
    "\n",
    "    for col in all_cols:\n",
    "        if col not in X_train_proc.columns:\n",
    "            X_train_proc[col] = 0\n",
    "        if col not in X_val_proc.columns:\n",
    "            X_val_proc[col] = 0\n",
    "        if col not in X_test_proc.columns:\n",
    "            X_test_proc[col] = 0\n",
    "\n",
    "    for name, df in [('X_train_proc', X_train_proc), ('X_val_proc', X_val_proc), ('X_test_proc', X_test_proc)]:\n",
    "        nan_cols = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "        if nan_cols:\n",
    "            print(f\"Found NaN values in {name} for columns: {nan_cols}\")\n",
    "            print(\"Filling remaining NaNs with appropriate values...\")\n",
    "\n",
    "            for col in nan_cols:\n",
    "                if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                    fill_value = df[col].median()\n",
    "                    if pd.isna(fill_value):\n",
    "                        fill_value = 0\n",
    "                    df[col] = df[col].fillna(fill_value)\n",
    "                    print(f\"  - {col}: filled with median ({fill_value})\")\n",
    "                else:\n",
    "                    fill_value = df[col].mode().iloc[0] if not df[col].mode().empty else \"Unknown\"\n",
    "                    df[col] = df[col].fillna(fill_value)\n",
    "                    print(f\"  - {col}: filled with mode ({fill_value})\")\n",
    "\n",
    "    if 'Age' in combined.columns:\n",
    "        combined['Age_squared'] = combined['Age'] ** 2\n",
    "\n",
    "    if 'Age' in combined.columns and 'CryoSleep' in combined.columns:\n",
    "        combined['Age_CryoSleep'] = combined['Age'] * combined['CryoSleep'].astype(int)\n",
    "\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    spending_cols = [col for col in spending_cols if col in combined.columns]\n",
    "\n",
    "    if spending_cols and 'GroupSize' in combined.columns:\n",
    "        combined['SpendPerPerson'] = combined['TotalSpend'] / combined['GroupSize']\n",
    "\n",
    "        combined['SpendingDiversity'] = (combined[spending_cols] > 0).sum(axis=1)\n",
    "\n",
    "        combined['SpendingPercentile'] = pd.qcut(combined['TotalSpend'].rank(method='first'),\n",
    "                                                 q=10, labels=False, duplicates='drop')\n",
    "\n",
    "    planet_map = {'Earth': 0, 'Europa': 1, 'Mars': 2}\n",
    "    dest_map = {'TRAPPIST-1e': 0, 'PSO J318.5-22': 1, '55 Cancri e': 2}\n",
    "\n",
    "    if 'HomePlanet' in combined.columns and 'Destination' in combined.columns:\n",
    "        combined['HomePlanetNum'] = combined['HomePlanet'].map(planet_map)\n",
    "        combined['DestinationNum'] = combined['Destination'].map(dest_map)\n",
    "\n",
    "        combined['HomePlanetNum'] = combined['HomePlanetNum'].fillna(-1)\n",
    "        combined['DestinationNum'] = combined['DestinationNum'].fillna(-1)\n",
    "\n",
    "        combined['TravelDistance'] = abs(combined['DestinationNum'] - combined['HomePlanetNum'])\n",
    "\n",
    "    if 'VIP' in combined.columns and 'TotalSpend' in combined.columns:\n",
    "        combined['VIP_Spending'] = combined['VIP'].astype(int) * combined['TotalSpend']\n",
    "    all_clean = all([\n",
    "        not X_train_proc.isna().any().any(),\n",
    "        not X_val_proc.isna().any().any(),\n",
    "        not X_test_proc.isna().any().any()\n",
    "    ])\n",
    "\n",
    "    if all_clean:\n",
    "        print(\"All datasets are now free of NaN values!\")\n",
    "    else:\n",
    "        print(\"WARNING: There are still NaN values remaining. Check your data processing.\")\n",
    "\n",
    "    X_train_proc = X_train_proc[sorted(X_train_proc.columns)]\n",
    "    X_val_proc = X_val_proc[sorted(X_val_proc.columns)]\n",
    "    X_test_proc = X_test_proc[sorted(X_test_proc.columns)]\n",
    "\n",
    "    preserved_categorical_cols = [f'cat_{col}' for col in preserved_cat_features.keys()]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    cols_to_scale = [col for col in X_train_proc.columns if col not in preserved_categorical_cols]\n",
    "\n",
    "    scaler.fit(X_train_proc[cols_to_scale])\n",
    "\n",
    "    for name, df in [('X_train', X_train_proc), ('X_val', X_val_proc), ('X_test', X_test_proc)]:\n",
    "        scaled_numerical = pd.DataFrame(\n",
    "            scaler.transform(df[cols_to_scale]),\n",
    "            columns=cols_to_scale,\n",
    "            index=df.index\n",
    "        )\n",
    "\n",
    "        for col in cols_to_scale:\n",
    "            df[col] = scaled_numerical[col]\n",
    "\n",
    "    print(\"Data scaling completed with StandardScaler (preserved categorical features were NOT scaled)\")\n",
    "    print(f\"Processed training features: {X_train_proc.shape}\")\n",
    "    print(f\"Processed validation features: {X_val_proc.shape}\")\n",
    "    print(f\"Processed test features: {X_test_proc.shape}\")\n",
    "\n",
    "    return {\n",
    "        'X_train': X_train_proc,\n",
    "        'X_val': X_val_proc,\n",
    "        'X_test': X_test_proc,\n",
    "        'y_train': y_train,\n",
    "        'y_val': y_val,\n",
    "        'train_ids': train_ids,\n",
    "        'test_ids': test_ids,\n",
    "        'preserved_categorical_cols': preserved_categorical_cols\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b3ae33130dc18ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:44:34.127166Z",
     "start_time": "2025-03-16T13:44:34.120506Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_base_models(data_dict, use_stratified_cv=True, cv_folds=5):\n",
    "    from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "    X_train = data_dict['X_train']\n",
    "    X_val = data_dict['X_val']\n",
    "    y_train = data_dict['y_train']\n",
    "    y_val = data_dict['y_val']\n",
    "\n",
    "    print(\"Training individual base models...\")\n",
    "\n",
    "    models = {\n",
    "        'logistic': LogisticRegression(\n",
    "            C=0.1,\n",
    "            max_iter=1000,\n",
    "            solver='liblinear',\n",
    "            random_state=42\n",
    "        ),\n",
    "        'random_forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "        'xgboost': xgb.XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42),\n",
    "        'catboost': cb.CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, random_state=42, verbose=0)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    if use_stratified_cv:\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        print(f\"Using {cv_folds}-fold StratifiedKFold cross-validation\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        val_pred = model.predict(X_val)\n",
    "        val_prob = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        accuracy = accuracy_score(y_val, val_pred)\n",
    "        roc_auc = roc_auc_score(y_val, val_prob)\n",
    "\n",
    "        if use_stratified_cv:\n",
    "            cv_probs = cross_val_predict(\n",
    "                model, X_train, y_train,\n",
    "                cv=skf,\n",
    "                method='predict_proba'\n",
    "            )[:, 1]\n",
    "\n",
    "            cv_auc = roc_auc_score(y_train, cv_probs)\n",
    "\n",
    "            overfit_gap = roc_auc - cv_auc\n",
    "\n",
    "            print(f\"CV ROC AUC: {cv_auc:.4f}\")\n",
    "            print(f\"Validation ROC AUC: {roc_auc:.4f}\")\n",
    "            print(f\"Potential overfitting: {overfit_gap:.4f}\")\n",
    "\n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'val_accuracy': accuracy,\n",
    "                'val_auc': roc_auc,\n",
    "                'cv_auc': cv_auc,\n",
    "                'overfit_gap': overfit_gap,\n",
    "                'val_predictions': val_pred,\n",
    "                'val_probabilities': val_prob\n",
    "            }\n",
    "        else:\n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'val_accuracy': accuracy,\n",
    "                'val_auc': roc_auc,\n",
    "                'val_predictions': val_pred,\n",
    "                'val_probabilities': val_prob\n",
    "            }\n",
    "\n",
    "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Validation ROC AUC: {roc_auc:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_val, val_pred))\n",
    "\n",
    "    comparison_columns = ['Model', 'Accuracy', 'ROC AUC']\n",
    "    if use_stratified_cv:\n",
    "        comparison_columns.extend(['CV AUC', 'Overfit Gap'])\n",
    "\n",
    "    comparison_data = {'Model': list(results.keys())}\n",
    "    comparison_data['Accuracy'] = [results[m]['val_accuracy'] for m in results]\n",
    "    comparison_data['ROC AUC'] = [results[m]['val_auc'] for m in results]\n",
    "\n",
    "    if use_stratified_cv:\n",
    "        comparison_data['CV AUC'] = [results[m]['cv_auc'] for m in results]\n",
    "        comparison_data['Overfit Gap'] = [results[m]['overfit_gap'] for m in results]\n",
    "\n",
    "    comparison = pd.DataFrame(comparison_data).sort_values('ROC AUC', ascending=False)\n",
    "\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    print(comparison)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5794ba78ecccef0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:44:38.398524Z",
     "start_time": "2025-03-16T13:44:38.254170Z"
    }
   },
   "outputs": [],
   "source": [
    "class StackingEnsemble(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, base_models, meta_learner):\n",
    "\n",
    "        self.base_models = base_models\n",
    "        self.meta_learner = meta_learner\n",
    "        self.fitted_base_models = None\n",
    "        self.fitted_meta_learner = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.fitted_base_models = {}\n",
    "\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "\n",
    "        for i, (name, model) in enumerate(self.base_models.items()):\n",
    "            print(f\"Training base model: {name}\")\n",
    "\n",
    "            model.fit(X, y)\n",
    "\n",
    "            self.fitted_base_models[name] = model\n",
    "\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                meta_features[:, i] = model.predict_proba(X)[:, 1]\n",
    "            else:\n",
    "                meta_features[:, i] = model.predict(X)\n",
    "\n",
    "        print(\"Training meta-learner\")\n",
    "        self.fitted_meta_learner = self.meta_learner.fit(meta_features, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "\n",
    "        for i, (name, model) in enumerate(self.fitted_base_models.items()):\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                meta_features[:, i] = model.predict_proba(X)[:, 1]\n",
    "            else:\n",
    "                meta_features[:, i] = model.predict(X)\n",
    "\n",
    "        return self.fitted_meta_learner.predict(meta_features)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "\n",
    "        for i, (name, model) in enumerate(self.fitted_base_models.items()):\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                meta_features[:, i] = model.predict_proba(X)[:, 1]\n",
    "            else:\n",
    "                meta_features[:, i] = model.predict(X)\n",
    "\n",
    "        return self.fitted_meta_learner.predict_proba(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d9022be9fa0e1ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T08:42:45.603101Z",
     "start_time": "2025-03-10T08:42:45.564243Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_advanced_ensemble(X_train, y_train, X_val, y_val, X_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import xgboost as xgb\n",
    "    import catboost as cb\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "    import optuna\n",
    "    from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    base_models = tune_base_models_with_optuna(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        n_trials=50,\n",
    "        timeout=1800,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    expected_models = ['logistic', 'xgboost', 'catboost']\n",
    "    for model_name in expected_models:\n",
    "        if model_name not in base_models:\n",
    "            print(f\"Warning: {model_name} is missing from base_models!\")\n",
    "\n",
    "    meta_features_train = np.zeros((X_train.shape[0], len(base_models)))\n",
    "    meta_features_val = np.zeros((X_val.shape[0], len(base_models)))\n",
    "    meta_features_test = np.zeros((X_test.shape[0], len(base_models)))\n",
    "\n",
    "    used_models = []\n",
    "\n",
    "    i = 0\n",
    "    for name, model in base_models.items():\n",
    "        print(f\"Generating meta-features from {name}...\")\n",
    "        used_models.append(name)\n",
    "\n",
    "        try:\n",
    "            _ = model.predict(X_train[:1])\n",
    "        except:\n",
    "            print(f\"Model {name} wasn't fitted, fitting now...\")\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            meta_features_train[:, i] = model.predict_proba(X_train)[:, 1]\n",
    "            meta_features_val[:, i] = model.predict_proba(X_val)[:, 1]\n",
    "            meta_features_test[:, i] = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            meta_features_train[:, i] = model.predict(X_train)\n",
    "            meta_features_val[:, i] = model.predict(X_val)\n",
    "            meta_features_test[:, i] = model.predict(X_test)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print(f\"Generated meta-features from {len(used_models)} models: {', '.join(used_models)}\")\n",
    "\n",
    "    def optimize_meta_learner(model_type, X, y, cv=5):\n",
    "        \"\"\"Optimize meta-learner hyperparameters with Optuna\"\"\"\n",
    "        cv_object = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "        if model_type == 'logistic':\n",
    "            def objective(trial):\n",
    "                C = trial.suggest_float('C', 0.001, 10.0, log=True)\n",
    "                model = LogisticRegression(C=C, max_iter=2000, random_state=42)\n",
    "                scores = cross_val_score(model, X, y, cv=cv_object, scoring='roc_auc')\n",
    "                return scores.mean()\n",
    "\n",
    "            study = optuna.create_study(direction='maximize')\n",
    "            study.optimize(objective, n_trials=30)\n",
    "\n",
    "            best_params = study.best_params\n",
    "            print(f\"Best logistic meta-learner params: {best_params}\")\n",
    "            return LogisticRegression(C=best_params['C'], max_iter=2000, random_state=42)\n",
    "\n",
    "        elif model_type == 'xgb':\n",
    "            def objective(trial):\n",
    "                params = {\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "                    'max_depth': trial.suggest_int('max_depth', 2, 5),\n",
    "                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "                }\n",
    "                model = xgb.XGBClassifier(**params, random_state=42)\n",
    "                scores = cross_val_score(model, X, y, cv=cv_object, scoring='roc_auc')\n",
    "                return scores.mean()\n",
    "\n",
    "            study = optuna.create_study(direction='maximize')\n",
    "            study.optimize(objective, n_trials=30)\n",
    "\n",
    "            best_params = study.best_params\n",
    "            print(f\"Best XGBoost meta-learner params: {best_params}\")\n",
    "            return xgb.XGBClassifier(**best_params, random_state=42)\n",
    "\n",
    "        elif model_type == 'catboost':\n",
    "            def objective(trial):\n",
    "                params = {\n",
    "                    'iterations': trial.suggest_int('iterations', 50, 200),\n",
    "                    'depth': trial.suggest_int('depth', 2, 5),\n",
    "                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "                }\n",
    "                model = cb.CatBoostClassifier(**params, random_state=42, verbose=0)\n",
    "                scores = cross_val_score(model, X, y, cv=cv_object, scoring='roc_auc')\n",
    "                return scores.mean()\n",
    "\n",
    "            study = optuna.create_study(direction='maximize')\n",
    "            study.optimize(objective, n_trials=30)\n",
    "\n",
    "            best_params = study.best_params\n",
    "            print(f\"Best CatBoost meta-learner params: {best_params}\")\n",
    "            return cb.CatBoostClassifier(**best_params, random_state=42, verbose=0)\n",
    "\n",
    "    meta_learners = {}\n",
    "    for model_type in ['logistic', 'xgb', 'catboost']:\n",
    "        print(f\"Optimizing meta-learner: {model_type}...\")\n",
    "        optimized_model = optimize_meta_learner(model_type, meta_features_train, y_train)\n",
    "        optimized_model.fit(meta_features_train, y_train)\n",
    "        meta_learners[model_type] = optimized_model\n",
    "\n",
    "    meta_preds_val = {}\n",
    "    meta_preds_test = {}\n",
    "\n",
    "    for name, model in meta_learners.items():\n",
    "        print(f\"Evaluating meta-learner: {name}...\")\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            val_pred = model.predict_proba(meta_features_val)[:, 1]\n",
    "        else:\n",
    "            val_pred = model.predict(meta_features_val)\n",
    "\n",
    "        acc = accuracy_score(y_val, (val_pred > 0.5).astype(int))\n",
    "        auc = roc_auc_score(y_val, val_pred)\n",
    "        print(f\"{name} - Accuracy: {acc:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "        meta_preds_val[name] = val_pred\n",
    "        meta_preds_test[name] = model.predict_proba(meta_features_test)[:, 1] if hasattr(model,\n",
    "                                                                                         \"predict_proba\") else model.predict(\n",
    "            meta_features_test)\n",
    "\n",
    "    print(\"\\nOptimizing ensemble weights...\")\n",
    "\n",
    "    def objective(trial):\n",
    "        raw_weights = [\n",
    "            trial.suggest_float(f'weight_{name}', 0.1, 1.0)\n",
    "            for name in meta_preds_val.keys()\n",
    "        ]\n",
    "\n",
    "        weights_sum = sum(raw_weights)\n",
    "        normalized_weights = [w / weights_sum for w in raw_weights]\n",
    "\n",
    "        weighted_preds = np.zeros(len(X_val))\n",
    "        for i, (name, pred) in enumerate(meta_preds_val.items()):\n",
    "            weighted_preds += normalized_weights[i] * pred\n",
    "\n",
    "        return roc_auc_score(y_val, weighted_preds)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    raw_weights = [\n",
    "        study.best_params[f'weight_{name}']\n",
    "        for name in meta_preds_val.keys()\n",
    "    ]\n",
    "    weights_sum = sum(raw_weights)\n",
    "    weights = {\n",
    "        name: raw_weights[i] / weights_sum\n",
    "        for i, name in enumerate(meta_preds_val.keys())\n",
    "    }\n",
    "\n",
    "    print(\"\\nOptimized meta-learner weights:\")\n",
    "    for name, weight in weights.items():\n",
    "        print(f\"{name}: {weight:.4f}\")\n",
    "\n",
    "    final_preds = np.zeros(len(X_test))\n",
    "    for i, (name, pred) in enumerate(meta_preds_test.items()):\n",
    "        final_preds += weights[name] * pred\n",
    "\n",
    "    final_val_preds = np.zeros(len(X_val))\n",
    "    for i, (name, pred) in enumerate(meta_preds_val.items()):\n",
    "        final_val_preds += weights[name] * pred\n",
    "\n",
    "    default_threshold = 0.5\n",
    "    default_val_preds = (final_val_preds > default_threshold).astype(int)\n",
    "    default_acc = accuracy_score(y_val, default_val_preds)\n",
    "    ensemble_auc = roc_auc_score(y_val, final_val_preds)\n",
    "\n",
    "    print(\"\\n===== DEFAULT THRESHOLD EVALUATION =====\")\n",
    "    print(f\"Default Threshold: {default_threshold}\")\n",
    "    print(f\"Validation Accuracy: {default_acc:.4f}\")\n",
    "    print(f\"Validation AUC: {ensemble_auc:.4f}\")\n",
    "\n",
    "    print(\"\\nDefault Classification Report:\")\n",
    "    print(classification_report(y_val, default_val_preds))\n",
    "\n",
    "    print(\"\\n===== THRESHOLD OPTIMIZATION WITH OPTUNA =====\")\n",
    "\n",
    "    def threshold_objective(trial):\n",
    "        threshold = trial.suggest_float('threshold', 0.3, 0.7)\n",
    "        preds = (final_val_preds > threshold).astype(int)\n",
    "        return accuracy_score(y_val, preds)\n",
    "\n",
    "    threshold_study = optuna.create_study(direction='maximize')\n",
    "    threshold_study.optimize(threshold_objective, n_trials=100)\n",
    "\n",
    "    optimal_threshold = threshold_study.best_params['threshold']\n",
    "    optimal_acc = threshold_study.best_value\n",
    "\n",
    "    optimal_val_preds = (final_val_preds > optimal_threshold).astype(int)\n",
    "\n",
    "    print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "    print(f\"Optimal Validation Accuracy: {optimal_acc:.4f}\")\n",
    "    print(f\"Improvement: {(optimal_acc - default_acc) * 100:.4f}%\")\n",
    "\n",
    "    print(\"\\nOptimized Classification Report:\")\n",
    "    print(classification_report(y_val, optimal_val_preds))\n",
    "\n",
    "    optimal_test_preds = (final_preds > optimal_threshold).astype(int)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTotal ensemble building time: {elapsed:.2f} seconds ({elapsed / 60:.2f} minutes)\")\n",
    "\n",
    "    return {\n",
    "        'base_models': base_models,\n",
    "        'meta_learners': meta_learners,\n",
    "        'weights': weights,\n",
    "        'final_predictions': final_preds,\n",
    "        'final_binary_predictions': {\n",
    "            'default': (final_preds > default_threshold).astype(int),\n",
    "            'optimized': optimal_test_preds\n",
    "        },\n",
    "        'validation_predictions': final_val_preds,\n",
    "        'validation_binary_predictions': {\n",
    "            'default': default_val_preds,\n",
    "            'optimized': optimal_val_preds\n",
    "        },\n",
    "        'thresholds': {\n",
    "            'default': default_threshold,\n",
    "            'optimal': optimal_threshold\n",
    "        },\n",
    "        'meta_features': {\n",
    "            'train': meta_features_train,\n",
    "            'val': meta_features_val,\n",
    "            'test': meta_features_test\n",
    "        },\n",
    "        'performance': {\n",
    "            'default_accuracy': default_acc,\n",
    "            'optimal_accuracy': optimal_acc,\n",
    "            'improvement': optimal_acc - default_acc,\n",
    "            'auc': ensemble_auc\n",
    "        },\n",
    "        'optuna_studies': {\n",
    "            'base_models': None,\n",
    "            'meta_weights': study,\n",
    "            'threshold': threshold_study\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9bb6bb3c44c822a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T14:13:40.815180Z",
     "start_time": "2025-03-09T14:13:40.806471Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_nan_values(data_dict):\n",
    "    results = {}\n",
    "\n",
    "    for key in ['X_train', 'X_val', 'X_test']:\n",
    "        if key in data_dict and data_dict[key] is not None:\n",
    "            df = data_dict[key]\n",
    "\n",
    "            has_nan = df.isna().any().any()\n",
    "\n",
    "            if has_nan:\n",
    "                nan_cols = df.columns[df.isna().any()].tolist()\n",
    "                nan_counts = {col: df[col].isna().sum() for col in nan_cols}\n",
    "                nan_percent = {col: (count / len(df) * 100) for col, count in nan_counts.items()}\n",
    "\n",
    "                results[key] = {\n",
    "                    'has_nan': True,\n",
    "                    'nan_columns': nan_cols,\n",
    "                    'nan_counts': nan_counts,\n",
    "                    'nan_percentages': nan_percent\n",
    "                }\n",
    "\n",
    "                print(f\"\\n{key} contains NaN values:\")\n",
    "                for col in nan_cols:\n",
    "                    print(f\"  - {col}: {nan_counts[col]} NaNs ({nan_percent[col]:.2f}%)\")\n",
    "            else:\n",
    "                results[key] = {'has_nan': False}\n",
    "                print(f\"\\n{key} does not contain any NaN values.\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5d201770499dd0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T09:18:56.765693Z",
     "start_time": "2025-03-10T09:18:56.694138Z"
    }
   },
   "outputs": [],
   "source": [
    "def tune_base_models(X_train, y_train, cv=5, use_stratified_cv=True):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    print(\"Tuning model hyperparameters...\")\n",
    "\n",
    "    param_grids = {\n",
    "        'logistic': {\n",
    "            'C': [0.01, 0.1, 1.0, 10.0],\n",
    "            'solver': ['liblinear'],\n",
    "            'penalty': ['l1', 'l2']\n",
    "        },\n",
    "        # 'random_forest': {\n",
    "        #     'n_estimators': [100, 200],\n",
    "        #     'max_depth': [8, 10, 12, 15],\n",
    "        #     'min_samples_split': [2, 5, 10],\n",
    "        #     'min_samples_leaf': [1, 2, 4]\n",
    "        # },\n",
    "        'xgboost': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [4, 5, 6],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        },\n",
    "        'catboost': {\n",
    "            'iterations': [100, 200],\n",
    "            'depth': [5, 6, 7],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'l2_leaf_reg': [1, 3, 5, 7]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    base_estimators = {\n",
    "        'logistic': LogisticRegression(random_state=42, max_iter=2000),\n",
    "        #'random_forest': RandomForestClassifier(random_state=42),\n",
    "        'xgboost': xgb.XGBClassifier(random_state=42),\n",
    "        'catboost': cb.CatBoostClassifier(random_state=42, verbose=0)\n",
    "    }\n",
    "\n",
    "    best_models = {}\n",
    "\n",
    "    if use_stratified_cv:\n",
    "        stratified_cv = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "        print(f\"Using {cv}-fold StratifiedKFold cross-validation for hyperparameter tuning\")\n",
    "        cv_object = stratified_cv\n",
    "    else:\n",
    "        cv_object = cv\n",
    "\n",
    "    for name, estimator in base_estimators.items():\n",
    "        print(f\"\\nTuning {name}...\")\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=estimator,\n",
    "            param_grid=param_grids[name],\n",
    "            cv=cv_object,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=os.cpu_count() - 1,\n",
    "            verbose=2,\n",
    "            return_train_score=True\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Grid search completed in {elapsed:.2f} seconds ({elapsed / 60:.2f} minutes)\")\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        best_index = grid_search.best_index_\n",
    "        if hasattr(grid_search, 'cv_results_') and 'mean_train_score' in grid_search.cv_results_:\n",
    "            train_score = grid_search.cv_results_['mean_train_score'][best_index]\n",
    "            cv_score = grid_search.best_score_\n",
    "            overfit_gap = train_score - cv_score\n",
    "            print(f\"Train score: {train_score:.4f}\")\n",
    "            print(f\"CV score: {cv_score:.4f}\")\n",
    "            print(f\"Potential overfitting: {overfit_gap:.4f}\")\n",
    "\n",
    "        best_models[name] = grid_search.best_estimator_\n",
    "\n",
    "        print(f\"Best {name} parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    return best_models\n",
    "\n",
    "\n",
    "def tune_base_models_with_optuna(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        n_trials=200,\n",
    "        timeout=None,\n",
    "        random_state=42\n",
    "):\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"Tuning model hyperparameters with Optuna...\")\n",
    "    print(f\"Using {cv}-fold StratifiedKFold cross-validation\")\n",
    "\n",
    "    best_models = {}\n",
    "\n",
    "    cv_object = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "\n",
    "    def optimize_logistic(trial):\n",
    "        C = trial.suggest_float('C', 0.001, 100, log=True)\n",
    "        penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "        solver = 'liblinear'\n",
    "\n",
    "        model = LogisticRegression(\n",
    "            C=C,\n",
    "            penalty=penalty,\n",
    "            solver=solver,\n",
    "            random_state=random_state,\n",
    "            max_iter=2000\n",
    "        )\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model, X_train, y_train,\n",
    "            cv=cv_object,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=os.cpu_count() - 1\n",
    "        )\n",
    "\n",
    "        return scores.mean()\n",
    "\n",
    "    def optimize_xgboost(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True)\n",
    "        }\n",
    "\n",
    "        model = xgb.XGBClassifier(\n",
    "            **params,\n",
    "            random_state=random_state,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model, X_train, y_train,\n",
    "            cv=cv_object,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=os.cpu_count() - 1\n",
    "        )\n",
    "\n",
    "        return scores.mean()\n",
    "\n",
    "    def optimize_catboost(trial):\n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('iterations', 50, 300),\n",
    "            'depth': trial.suggest_int('depth', 4, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.1, 10.0, log=True),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 10.0),\n",
    "            'random_strength': trial.suggest_float('random_strength', 1e-9, 10.0, log=True),\n",
    "            'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "            'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide'])\n",
    "        }\n",
    "\n",
    "        model = cb.CatBoostClassifier(\n",
    "            **params,\n",
    "            random_state=random_state,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model, X_train, y_train,\n",
    "            cv=cv_object,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=os.cpu_count() - 1\n",
    "        )\n",
    "\n",
    "        return scores.mean()\n",
    "\n",
    "    optimization_funcs = {\n",
    "        'logistic': optimize_logistic,\n",
    "        'xgboost': optimize_xgboost,\n",
    "        'catboost': optimize_catboost\n",
    "    }\n",
    "\n",
    "    for model_name, objective_func in optimization_funcs.items():\n",
    "        print(f\"\\nTuning {model_name}...\")\n",
    "        model_start_time = time.time()\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective_func, n_trials=n_trials, timeout=timeout)\n",
    "\n",
    "        model_elapsed = time.time() - model_start_time\n",
    "        print(f\"Optimization completed in {model_elapsed:.2f} seconds ({model_elapsed / 60:.2f} minutes)\")\n",
    "\n",
    "        best_params = study.best_params\n",
    "        best_score = study.best_value\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best CV score: {best_score:.4f}\")\n",
    "\n",
    "        if model_name == 'logistic':\n",
    "            best_model = LogisticRegression(\n",
    "                C=best_params['C'],\n",
    "                penalty=best_params['penalty'],\n",
    "                solver='liblinear',\n",
    "                random_state=random_state,\n",
    "                max_iter=2000\n",
    "            )\n",
    "        elif model_name == 'xgboost':\n",
    "            best_model = xgb.XGBClassifier(\n",
    "                **best_params,\n",
    "                random_state=random_state,\n",
    "                use_label_encoder=False,\n",
    "                eval_metric='logloss'\n",
    "            )\n",
    "        elif model_name == 'catboost':\n",
    "            best_model = cb.CatBoostClassifier(\n",
    "                **best_params,\n",
    "                random_state=random_state,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        if hasattr(best_model, \"predict_proba\"):\n",
    "            train_preds = best_model.predict_proba(X_train)[:, 1]\n",
    "        else:\n",
    "            train_preds = best_model.predict(X_train)\n",
    "\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        train_score = roc_auc_score(y_train, train_preds)\n",
    "        cv_score = best_score\n",
    "        overfit_gap = train_score - cv_score\n",
    "\n",
    "        print(f\"Train score: {train_score:.4f}\")\n",
    "        print(f\"CV score: {cv_score:.4f}\")\n",
    "        print(f\"Potential overfitting: {overfit_gap:.4f}\")\n",
    "\n",
    "        best_models[model_name] = best_model\n",
    "\n",
    "        print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "        print(f\"Best {model_name} parameters: {best_params}\")\n",
    "        print(f\"Best CV score: {best_score:.4f}\")\n",
    "\n",
    "        optuna.visualization.plot_optimization_history(study)\n",
    "        plt.title(f\"{model_name} Optimization History\")\n",
    "        plt.show()\n",
    "\n",
    "    total_elapsed = time.time() - start_time\n",
    "    print(f\"\\nTotal hyperparameter tuning time: {total_elapsed:.2f} seconds ({total_elapsed / 60:.2f} minutes)\")\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8ab1d1f373d936f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T06:43:18.395839Z",
     "start_time": "2025-03-10T06:43:18.380243Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_best_features(X_train, y_train, X_val, X_test):\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    import xgboost as xgb\n",
    "\n",
    "    print(\"Performing feature selection...\")\n",
    "\n",
    "    model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    selection = SelectFromModel(model, threshold='median', prefit=True).set_output(transform=\"pandas\")\n",
    "\n",
    "    X_train_selected = selection.transform(X_train)\n",
    "    X_val_selected = selection.transform(X_val)\n",
    "    X_test_selected = selection.transform(X_test)\n",
    "\n",
    "    print(f\"Selected {X_train_selected.shape[1]} features out of {X_train.shape[1]}\")\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': model.feature_importances_\n",
    "    })\n",
    "    top_features = feature_importance.sort_values('Importance', ascending=False).head(10)\n",
    "    print(\"Top 10 most important features:\")\n",
    "    print(top_features)\n",
    "\n",
    "    return X_train_selected, X_val_selected, X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e36a7da10e3afd60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T06:43:54.643496Z",
     "start_time": "2025-03-10T06:43:54.626645Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize_threshold(y_true, y_prob, metric='accuracy', thresholds=None):\n",
    "    from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "    import numpy as np\n",
    "\n",
    "    if thresholds is None:\n",
    "        thresholds = np.arange(0.3, 0.7, 0.01)\n",
    "\n",
    "    best_threshold = 0.5\n",
    "    best_score = 0.0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob > threshold).astype(int)\n",
    "\n",
    "        if metric == 'accuracy':\n",
    "            score = accuracy_score(y_true, y_pred)\n",
    "        elif metric == 'f1':\n",
    "            score = f1_score(y_true, y_pred)\n",
    "        elif metric == 'precision':\n",
    "            score = precision_score(y_true, y_pred)\n",
    "        elif metric == 'recall':\n",
    "            score = recall_score(y_true, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1586f35f-ed7e-44ad-947b-ef0e455eecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_feature_engineering(combined):\n",
    "    \"\"\"Apply advanced feature engineering techniques\"\"\"\n",
    "    print(\"Adding enhanced features...\")\n",
    "\n",
    "    if 'Age' in combined.columns and 'TotalSpend' in combined.columns:\n",
    "        combined['Age_TotalSpend'] = combined['Age'] * combined['TotalSpend']\n",
    "        combined['Age_TotalSpendRatio'] = combined['Age'] / (combined['TotalSpend'] + 1)\n",
    "\n",
    "    if 'Age' in combined.columns:\n",
    "        age_valid = combined['Age'] >= 0\n",
    "        combined['Age_log'] = np.nan\n",
    "        combined['Age_sqrt'] = np.nan\n",
    "\n",
    "        combined.loc[age_valid, 'Age_log'] = np.log1p(combined.loc[age_valid, 'Age'])\n",
    "        combined.loc[age_valid, 'Age_sqrt'] = np.sqrt(combined.loc[age_valid, 'Age'])\n",
    "\n",
    "    if 'PassengerGroup' in combined.columns and 'TotalSpend' in combined.columns:\n",
    "        group_spend_mean = combined.groupby('PassengerGroup')['TotalSpend'].transform('mean')\n",
    "        group_spend_std = combined.groupby('PassengerGroup')['TotalSpend'].transform('std').fillna(0)\n",
    "        combined['GroupSpendDeviation'] = (combined['TotalSpend'] - group_spend_mean) / (group_spend_std + 1)\n",
    "\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    spending_cols = [col for col in spending_cols if col in combined.columns]\n",
    "    if spending_cols:\n",
    "        for col in spending_cols:\n",
    "            other_cols = [c for c in spending_cols if c != col]\n",
    "            if other_cols:\n",
    "                combined[f'{col}_Dominance'] = combined[col] / (combined[other_cols].sum(axis=1) + 1)\n",
    "\n",
    "    return combined\n",
    "\n",
    "\n",
    "def advanced_feature_selection(X_train, y_train, X_val, X_test, selection_method='combined', n_features=None):\n",
    "    \"\"\"\n",
    "    Advanced feature selection using multiple methods with NaN handling\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.feature_selection import mutual_info_classif\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    print(f\"Performing feature selection using {selection_method} method...\")\n",
    "\n",
    "    if X_train.isna().any().any():\n",
    "        print(\"Detected NaN values in training data. Applying imputation...\")\n",
    "\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        X_train_imputed = pd.DataFrame(\n",
    "            imputer.fit_transform(X_train),\n",
    "            columns=X_train.columns,\n",
    "            index=X_train.index\n",
    "        )\n",
    "\n",
    "        X_val_imputed = pd.DataFrame(\n",
    "            imputer.transform(X_val),\n",
    "            columns=X_val.columns,\n",
    "            index=X_val.index\n",
    "        )\n",
    "\n",
    "        X_test_imputed = pd.DataFrame(\n",
    "            imputer.transform(X_test),\n",
    "            columns=X_test.columns,\n",
    "            index=X_test.index\n",
    "        )\n",
    "    else:\n",
    "        X_train_imputed = X_train\n",
    "        X_val_imputed = X_val\n",
    "        X_test_imputed = X_test\n",
    "\n",
    "    if selection_method == 'importance' or selection_method == 'combined':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train_imputed, y_train)\n",
    "\n",
    "        importances = pd.Series(model.feature_importances_, index=X_train_imputed.columns)\n",
    "\n",
    "    if selection_method == 'mutual_info' or selection_method == 'combined':\n",
    "        mi_scores = pd.Series(\n",
    "            mutual_info_classif(X_train_imputed, y_train, random_state=42),\n",
    "            index=X_train_imputed.columns\n",
    "        )\n",
    "\n",
    "    if selection_method == 'combined':\n",
    "        importances = (importances - importances.min()) / (importances.max() - importances.min())\n",
    "        mi_scores = (mi_scores - mi_scores.min()) / (mi_scores.max() - mi_scores.min())\n",
    "\n",
    "        combined_scores = (importances + mi_scores) / 2\n",
    "        scores = combined_scores\n",
    "    elif selection_method == 'importance':\n",
    "        scores = importances\n",
    "    else:\n",
    "        scores = mi_scores\n",
    "\n",
    "    sorted_features = scores.sort_values(ascending=False)\n",
    "\n",
    "    if n_features is not None:\n",
    "        selected = sorted_features.index[:n_features].tolist()\n",
    "    else:\n",
    "        threshold = sorted_features.mean()\n",
    "        selected = sorted_features[sorted_features > threshold].index.tolist()\n",
    "\n",
    "    print(f\"Selected {len(selected)} features\")\n",
    "    if len(selected) > 0:\n",
    "        print(f\"Top 5 features: {selected[:5]}\")\n",
    "\n",
    "    return X_train_imputed[selected], X_val_imputed[selected], X_test_imputed[selected], selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4cea515f-21e8-4b6e-8b22-7f20c51756a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stacked_ensemble(X_train, y_train, X_val, y_val, X_test, n_folds=5):\n",
    "    \"\"\"\n",
    "    Build a stacked ensemble model using out-of-fold predictions\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "    from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import xgboost as xgb\n",
    "    import catboost as cb\n",
    "    import numpy as np\n",
    "\n",
    "    def get_oof_predictions(model, X, y, X_test, n_folds):\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "        oof = np.zeros(len(X))\n",
    "        test_preds = np.zeros(len(X_test))\n",
    "\n",
    "        for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            print(f\"Training fold {i + 1}/{n_folds}\")\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold = y.iloc[train_idx]\n",
    "\n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                oof[val_idx] = model_clone.predict_proba(X_val_fold)[:, 1]\n",
    "                test_preds += model_clone.predict_proba(X_test)[:, 1] / n_folds\n",
    "            else:\n",
    "                oof[val_idx] = model_clone.predict(X_val_fold)\n",
    "                test_preds += model_clone.predict(X_test) / n_folds\n",
    "\n",
    "        return oof, test_preds\n",
    "\n",
    "    base_models = {\n",
    "        'catboost': cb.CatBoostClassifier(iterations=500, depth=6, learning_rate=0.05, verbose=False, random_seed=42),\n",
    "        'xgboost': xgb.XGBClassifier(n_estimators=500, max_depth=4, learning_rate=0.05, random_state=42),\n",
    "        'extratrees': ExtraTreesClassifier(n_estimators=500, max_depth=12, random_state=42),\n",
    "        'gbm': GradientBoostingClassifier(n_estimators=300, max_depth=3, learning_rate=0.05, random_state=42),\n",
    "        'logistic': LogisticRegression(C=0.1, max_iter=1000, random_state=42)\n",
    "    }\n",
    "\n",
    "    meta_features_train = np.zeros((X_train.shape[0], len(base_models)))\n",
    "    meta_features_val = np.zeros((X_val.shape[0], len(base_models)))\n",
    "    meta_features_test = np.zeros((X_test.shape[0], len(base_models)))\n",
    "\n",
    "    for i, (name, model) in enumerate(base_models.items()):\n",
    "        print(f\"Building meta-features for {name}\")\n",
    "        oof_preds, test_preds = get_oof_predictions(model, X_train, y_train, X_test, n_folds)\n",
    "        meta_features_train[:, i] = oof_preds\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        meta_features_val[:, i] = model.predict_proba(X_val)[:, 1] if hasattr(model,\n",
    "                                                                              'predict_proba') else model.predict(X_val)\n",
    "        meta_features_test[:, i] = test_preds\n",
    "\n",
    "        oof_auc = roc_auc_score(y_train, oof_preds)\n",
    "        print(f\"{name} OOF AUC: {oof_auc:.4f}\")\n",
    "\n",
    "    meta_model = cb.CatBoostClassifier(iterations=300, depth=4, learning_rate=0.03, verbose=False, random_seed=42)\n",
    "    meta_model.fit(meta_features_train, y_train)\n",
    "\n",
    "    val_probs = meta_model.predict_proba(meta_features_val)[:, 1]\n",
    "    test_probs = meta_model.predict_proba(meta_features_test)[:, 1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, meta_model.predict_proba(meta_features_train)[:, 1])\n",
    "    val_auc = roc_auc_score(y_val, val_probs)\n",
    "\n",
    "    default_threshold = 0.5\n",
    "    default_val_preds = (val_probs > default_threshold).astype(int)\n",
    "    default_accuracy = accuracy_score(y_val, default_val_preds)\n",
    "\n",
    "    thresholds = np.linspace(0.3, 0.7, 40)\n",
    "    best_threshold = 0.5\n",
    "    best_accuracy = default_accuracy\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        val_preds = (val_probs > threshold).astype(int)\n",
    "        acc = accuracy_score(y_val, val_preds)\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    optimized_val_preds = (val_probs > best_threshold).astype(int)\n",
    "\n",
    "    print(f\"Meta-model training AUC: {train_auc:.4f}\")\n",
    "    print(f\"Meta-model validation AUC: {val_auc:.4f}\")\n",
    "    print(f\"Default accuracy: {default_accuracy:.4f}\")\n",
    "    print(f\"Optimal threshold: {best_threshold:.4f}\")\n",
    "    print(f\"Optimized accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'meta_model': meta_model,\n",
    "        'base_models': base_models,\n",
    "        'final_predictions': test_probs,\n",
    "        'validation_predictions': {\n",
    "            'default': val_probs,\n",
    "            'optimized': optimized_val_preds\n",
    "        },\n",
    "        'validation_binary_predictions': {\n",
    "            'default': default_val_preds,\n",
    "            'optimized': optimized_val_preds\n",
    "        },\n",
    "        'thresholds': {\n",
    "            'default': default_threshold,\n",
    "            'optimal': best_threshold\n",
    "        },\n",
    "        'performance': {\n",
    "            'default_accuracy': default_accuracy,\n",
    "            'optimal_accuracy': best_accuracy,\n",
    "            'auc': val_auc\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3e3ebe85-9655-431c-a896-4d753aa997b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_features(X_train, y_train, n_features=None, method='importance'):\n",
    "    \"\"\"\n",
    "    Select top features based on importance from a tree-based model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : DataFrame\n",
    "        Training features\n",
    "    y_train : Series\n",
    "        Target values\n",
    "    n_features : int, optional\n",
    "        Number of features to select. If None, selects based on importance threshold\n",
    "    method : str\n",
    "        Method for feature selection ('importance', 'mutual_info', or 'combined')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        Names of selected features\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "    if method == 'importance' or method == 'combined':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "\n",
    "    if method == 'mutual_info' or method == 'combined':\n",
    "        mi_scores = pd.Series(\n",
    "            mutual_info_classif(X_train, y_train, random_state=42),\n",
    "            index=X_train.columns\n",
    "        )\n",
    "\n",
    "    if method == 'combined':\n",
    "\n",
    "        importances = (importances - importances.min()) / (importances.max() - importances.min())\n",
    "        mi_scores = (mi_scores - mi_scores.min()) / (mi_scores.max() - mi_scores.min())\n",
    "\n",
    "        combined_scores = (importances + mi_scores) / 2\n",
    "        scores = combined_scores\n",
    "    elif method == 'importance':\n",
    "        scores = importances\n",
    "    else:\n",
    "        scores = mi_scores\n",
    "\n",
    "    sorted_features = scores.sort_values(ascending=False)\n",
    "\n",
    "    if n_features is not None:\n",
    "        selected = sorted_features.index[:n_features].tolist()\n",
    "    else:\n",
    "        threshold = sorted_features.mean()\n",
    "        selected = sorted_features[sorted_features > threshold].index.tolist()\n",
    "\n",
    "    return selected\n",
    "\n",
    "\n",
    "def optimize_threshold(predictions, y_true, metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Find the optimal threshold to maximize a given metric\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : array-like\n",
    "        Predicted probabilities\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    metric : str\n",
    "        Metric to optimize ('accuracy', 'f1', 'precision', 'recall')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Optimal threshold\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "    metric_funcs = {\n",
    "        'accuracy': accuracy_score,\n",
    "        'f1': f1_score,\n",
    "        'precision': precision_score,\n",
    "        'recall': recall_score\n",
    "    }\n",
    "\n",
    "    metric_func = metric_funcs.get(metric, accuracy_score)\n",
    "\n",
    "    thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "\n",
    "    best_score = 0\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        pred_labels = (predictions > threshold).astype(int)\n",
    "        score = metric_func(y_true, pred_labels)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"Optimized threshold: {best_threshold:.4f} with {metric} score: {best_score:.4f}\")\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7a19c50e-5a8f-4e0d-b34b-abfb1de2ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_spaceship_data_prep():\n",
    "    data_dict = prepare_spaceship_data(train_data, test_data)\n",
    "\n",
    "    X_train = data_dict['X_train']\n",
    "    X_val = data_dict['X_val']\n",
    "    X_test = data_dict['X_test']\n",
    "\n",
    "    best_features = select_top_features(X_train, data_dict['y_train'])\n",
    "\n",
    "    data_dict['X_train'] = X_train[best_features]\n",
    "    data_dict['X_val'] = X_val[best_features]\n",
    "    data_dict['X_test'] = X_test[best_features]\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "813af6e4-0e5f-43b4-ad87-714d843404da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "import time\n",
    "\n",
    "\n",
    "def tune_with_optuna_multi_data(data_dict, categorical_cols=None, n_trials=100, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Comprehensive Optuna tuning for ensemble model with model-specific data formats\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary containing all training and validation data\n",
    "    categorical_cols : list, default=None\n",
    "        List of categorical column names for CatBoost\n",
    "    n_trials : int, default=100\n",
    "        Number of trials for hyperparameter optimization\n",
    "    n_jobs : int, default=1\n",
    "        Number of parallel jobs. -1 for using all processors.\n",
    "    \"\"\"\n",
    "    print(\"Starting comprehensive Optuna tuning with model-specific data formats...\")\n",
    "\n",
    "    X_train = data_dict['X_train']\n",
    "    y_train = data_dict['y_train']\n",
    "    X_val = data_dict['X_val']\n",
    "    y_val = data_dict['y_val']\n",
    "\n",
    "    print(\"Creating model-specific datasets...\")\n",
    "\n",
    "    X_train_catboost = X_train.copy()\n",
    "    X_val_catboost = X_val.copy()\n",
    "\n",
    "    if categorical_cols:\n",
    "        for col in categorical_cols:\n",
    "            if col in X_train_catboost.columns:\n",
    "                X_train_catboost[col] = X_train_catboost[col].astype(str)\n",
    "                X_val_catboost[col] = X_val_catboost[col].astype(str)\n",
    "\n",
    "    X_train_xgb = X_train.copy()\n",
    "    X_val_xgb = X_val.copy()\n",
    "\n",
    "    if categorical_cols:\n",
    "        for col in categorical_cols:\n",
    "            if col in X_train_xgb.columns:\n",
    "                X_train_xgb[col] = X_train_xgb[col].astype('category')\n",
    "                X_val_xgb[col] = X_val_xgb[col].astype('category')\n",
    "\n",
    "    X_train_sklearn = X_train.copy()\n",
    "    X_val_sklearn = X_val.copy()\n",
    "\n",
    "    cat_cols_to_encode = []\n",
    "    for col in X_train_sklearn.columns:\n",
    "        if X_train_sklearn[col].dtype == 'object' or isinstance(X_train_sklearn[col].dtype, pd.CategoricalDtype):\n",
    "            cat_cols_to_encode.append(col)\n",
    "\n",
    "    if cat_cols_to_encode:\n",
    "        from sklearn.preprocessing import OrdinalEncoder\n",
    "        encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "        cat_encoded = encoder.fit_transform(X_train_sklearn[cat_cols_to_encode])\n",
    "        for i, col in enumerate(cat_cols_to_encode):\n",
    "            X_train_sklearn[col] = cat_encoded[:, i]\n",
    "\n",
    "        cat_encoded_val = encoder.transform(X_val_sklearn[cat_cols_to_encode])\n",
    "        for i, col in enumerate(cat_cols_to_encode):\n",
    "            X_val_sklearn[col] = cat_encoded_val[:, i]\n",
    "\n",
    "    print(f\"Created specialized datasets for each model type\")\n",
    "\n",
    "    base_models = {}\n",
    "\n",
    "    if categorical_cols and len(categorical_cols) > 0:\n",
    "        print(f\"First 5 categorical features: {categorical_cols[:5]}\")\n",
    "\n",
    "    catboost_model, catboost_score = tune_catboost(\n",
    "        X_train_catboost, y_train, X_val_catboost, y_val,\n",
    "        categorical_cols=categorical_cols,\n",
    "        n_trials=n_trials,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    base_models['catboost'] = catboost_model\n",
    "    print(f\"Best CatBoost validation accuracy: {catboost_score:.4f}\")\n",
    "\n",
    "    print(f\"\\n==== Tuning XGBoost ({n_jobs} parallel jobs) ====\")\n",
    "    print(f\"Tuning XGBoost with {n_jobs} threads\")\n",
    "    xgb_model, xgb_score = tune_xgboost(\n",
    "        X_train_xgb, y_train, X_val_xgb, y_val,\n",
    "        n_trials=n_trials,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    base_models['xgboost'] = xgb_model\n",
    "    print(f\"Best XGBoost validation accuracy: {xgb_score:.4f}\")\n",
    "\n",
    "    print(f\"\\n==== Tuning RandomForest ({n_jobs} parallel jobs) ====\")\n",
    "    rf_model, rf_score = tune_random_forest(\n",
    "        X_train_sklearn, y_train, X_val_sklearn, y_val,\n",
    "        n_trials=n_trials,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    base_models['random_forest'] = rf_model\n",
    "    print(f\"Best RandomForest validation accuracy: {rf_score:.4f}\")\n",
    "\n",
    "    print(f\"\\n==== Tuning GradientBoosting ({n_jobs} parallel jobs) ====\")\n",
    "    gb_model, gb_score = tune_gradient_boosting(\n",
    "        X_train_sklearn, y_train, X_val_sklearn, y_val,\n",
    "        n_trials=n_trials,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    base_models['gradient_boosting'] = gb_model\n",
    "    print(f\"Best GradientBoosting validation accuracy: {gb_score:.4f}\")\n",
    "\n",
    "    print(f\"\\n==== Tuning ExtraTrees ({n_jobs} parallel jobs) ====\")\n",
    "    et_model, et_score = tune_extra_trees(\n",
    "        X_train_sklearn, y_train, X_val_sklearn, y_val,\n",
    "        n_trials=n_trials,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    base_models['extra_trees'] = et_model\n",
    "    print(f\"Best ExtraTrees validation accuracy: {et_score:.4f}\")\n",
    "\n",
    "    data_dict['X_test_catboost'] = data_dict['X_test'].copy()\n",
    "    data_dict['X_test_xgb'] = data_dict['X_test'].copy()\n",
    "    data_dict['X_test_sklearn'] = data_dict['X_test'].copy()\n",
    "\n",
    "    if categorical_cols:\n",
    "        for col in categorical_cols:\n",
    "            if col in data_dict['X_test_catboost'].columns:\n",
    "                data_dict['X_test_catboost'][col] = data_dict['X_test_catboost'][col].astype(str)\n",
    "                data_dict['X_test_xgb'][col] = data_dict['X_test_xgb'][col].astype('category')\n",
    "\n",
    "    if cat_cols_to_encode:\n",
    "        cat_encoded_test = encoder.transform(data_dict['X_test_sklearn'][cat_cols_to_encode])\n",
    "        for i, col in enumerate(cat_cols_to_encode):\n",
    "            data_dict['X_test_sklearn'][col] = cat_encoded_test[:, i]\n",
    "\n",
    "    print(\"\\n==== Generating Meta Features with Model-Specific Data ====\")\n",
    "    meta_features_train = np.zeros((X_train.shape[0], len(base_models)))\n",
    "    meta_preds_val = np.zeros((X_val.shape[0], len(base_models)))\n",
    "\n",
    "    model_data_map = {\n",
    "        'catboost': (X_train_catboost, X_val_catboost),\n",
    "        'xgboost': (X_train_xgb, X_val_xgb),\n",
    "        'random_forest': (X_train_sklearn, X_val_sklearn),\n",
    "        'gradient_boosting': (X_train_sklearn, X_val_sklearn),\n",
    "        'extra_trees': (X_train_sklearn, X_val_sklearn)\n",
    "    }\n",
    "\n",
    "    for i, (name, model) in enumerate(base_models.items()):\n",
    "        print(f\"Generating meta-features for {name}\")\n",
    "\n",
    "        X_train_model, X_val_model = model_data_map[name]\n",
    "\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        from sklearn.base import clone\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        oof_preds = np.zeros(X_train.shape[0])\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X_train_model, y_train):\n",
    "            X_fold_train = X_train_model.iloc[train_idx]\n",
    "            X_fold_val = X_train_model.iloc[val_idx]\n",
    "            y_fold_train = y_train.iloc[train_idx]\n",
    "\n",
    "            model_clone = clone(model)\n",
    "\n",
    "            if name == 'catboost':\n",
    "                model_clone.fit(\n",
    "                    X_fold_train,\n",
    "                    y_fold_train,\n",
    "                    cat_features=categorical_cols,\n",
    "                    verbose=False\n",
    "                )\n",
    "            else:\n",
    "                model_clone.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "            if hasattr(model_clone, 'predict_proba'):\n",
    "                fold_preds = model_clone.predict_proba(X_fold_val)[:, 1]\n",
    "            else:\n",
    "                fold_preds = model_clone.predict(X_fold_val)\n",
    "\n",
    "            oof_preds[val_idx] = fold_preds\n",
    "\n",
    "        meta_features_train[:, i] = oof_preds\n",
    "\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            val_preds = model.predict_proba(X_val_model)[:, 1]\n",
    "        else:\n",
    "            val_preds = model.predict(X_val_model)\n",
    "\n",
    "        meta_preds_val[:, i] = val_preds\n",
    "\n",
    "    print(f\"\\n==== Tuning Meta-Learner ({n_jobs} parallel jobs) ====\")\n",
    "    meta_learner, meta_score = tune_meta_learner(\n",
    "        meta_features_train, y_train, meta_preds_val, y_val,\n",
    "        n_trials=n_trials,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    print(f\"Best meta-learner validation accuracy: {meta_score:.4f}\")\n",
    "\n",
    "    ensemble = {\n",
    "        'base_models': base_models,\n",
    "        'meta_learner': meta_learner,\n",
    "        'model_data_map': model_data_map,\n",
    "        'meta_score': meta_score\n",
    "    }\n",
    "\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "def tune_catboost(X_train, y_train, X_val, y_val, categorical_cols=None, n_trials=50, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Tune CatBoost hyperparameters with proper categorical feature handling and parallel processing\n",
    "    \"\"\"\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = []\n",
    "\n",
    "    print(f\"Tuning CatBoost with {len(categorical_cols)} categorical features\")\n",
    "    print(f\"First 5 categorical features: {categorical_cols[:5]}\")\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('iterations', 800, 2000),\n",
    "            'depth': trial.suggest_int('depth', 6, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.1, 10.0, log=True),\n",
    "            'random_strength': trial.suggest_float('random_strength', 0.1, 10.0, log=True),\n",
    "            'bootstrap_type': 'Bayesian',\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 1.0, 10.0),\n",
    "            'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise']),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 20),\n",
    "            'max_ctr_complexity': trial.suggest_int('max_ctr_complexity', 1, 4),\n",
    "            'one_hot_max_size': trial.suggest_int('one_hot_max_size', 10, 255),\n",
    "            'verbose': 0,\n",
    "            'thread_count': n_jobs if n_jobs > 0 else None,\n",
    "            'random_seed': 42\n",
    "        }\n",
    "\n",
    "        model = cb.CatBoostClassifier(**params)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            cat_features=categorical_cols,\n",
    "            eval_set=(X_val, y_val),\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        preds = model.predict_proba(X_val)[:, 1]\n",
    "        thresholds = np.linspace(0.4, 0.6, 20)\n",
    "        best_acc = 0\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            binary_preds = (preds > threshold).astype(int)\n",
    "            acc = accuracy_score(y_val, binary_preds)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "\n",
    "        return best_acc\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=n_jobs)\n",
    "\n",
    "    print(f\"Best CatBoost parameters: {study.best_params}\")\n",
    "\n",
    "    best_params = study.best_params.copy()\n",
    "    best_params['random_seed'] = 42\n",
    "    best_params['verbose'] = 100\n",
    "    best_params['thread_count'] = n_jobs if n_jobs > 0 else None\n",
    "\n",
    "    best_model = cb.CatBoostClassifier(**best_params)\n",
    "    best_model.fit(\n",
    "        X_train, y_train,\n",
    "        cat_features=categorical_cols,\n",
    "        eval_set=(X_val, y_val),\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    best_model.categorical_features = categorical_cols\n",
    "\n",
    "    val_preds = best_model.predict_proba(X_val)[:, 1]\n",
    "    thresholds = np.linspace(0.3, 0.7, 40)\n",
    "    best_acc = 0\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        binary_preds = (val_preds > threshold).astype(int)\n",
    "        acc = accuracy_score(y_val, binary_preds)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"Best accuracy: {best_acc:.4f} with threshold: {best_threshold:.4f}\")\n",
    "    best_model.threshold = best_threshold\n",
    "\n",
    "    return best_model, best_acc\n",
    "\n",
    "\n",
    "def tune_xgboost(X_train, y_train, X_val, y_val, n_trials=50, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Tune XGBoost hyperparameters with proper categorical feature handling\n",
    "    \"\"\"\n",
    "    import xgboost as xgb\n",
    "    import pandas as pd\n",
    "\n",
    "    print(f\"Tuning XGBoost with {n_jobs} threads\")\n",
    "\n",
    "    if not isinstance(X_train, pd.DataFrame):\n",
    "        X_train = pd.DataFrame(X_train)\n",
    "    if not isinstance(X_val, pd.DataFrame):\n",
    "        X_val = pd.DataFrame(X_val)\n",
    "\n",
    "    for col in X_train.select_dtypes(include=['object']).columns:\n",
    "        X_train[col] = X_train[col].astype('category')\n",
    "        X_val[col] = X_val[col].astype('category')\n",
    "\n",
    "    print(f\"Converted {len(X_train.select_dtypes(include=['category']).columns)} columns to category type\")\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0.01, 1.0, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0, log=True),\n",
    "            'n_jobs': n_jobs,\n",
    "            'enable_categorical': True\n",
    "        }\n",
    "\n",
    "        model = xgb.XGBClassifier(**params, random_state=42)\n",
    "\n",
    "        try:\n",
    "            callbacks = [xgb.callback.EarlyStopping(rounds=50, verbose=False)]\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=callbacks, verbose=False)\n",
    "        except:\n",
    "            try:\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "                          early_stopping_rounds=50, verbose=False)\n",
    "            except:\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict_proba(X_val)[:, 1]\n",
    "        thresholds = np.linspace(0.4, 0.6, 20)\n",
    "        best_acc = 0\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            binary_preds = (preds > threshold).astype(int)\n",
    "            acc = accuracy_score(y_val, binary_preds)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "\n",
    "        return best_acc\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials,\n",
    "                   n_jobs=1)\n",
    "    print(f\"Best XGBoost parameters: {study.best_params}\")\n",
    "\n",
    "    best_params = study.best_params.copy()\n",
    "    best_params['random_state'] = 42\n",
    "    best_params['n_jobs'] = n_jobs\n",
    "    best_params['enable_categorical'] = True\n",
    "\n",
    "    for col in X_train.select_dtypes(include=['object']).columns:\n",
    "        X_train[col] = X_train[col].astype('category')\n",
    "        X_val[col] = X_val[col].astype('category')\n",
    "\n",
    "    best_model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "    try:\n",
    "        callbacks = [xgb.callback.EarlyStopping(rounds=50, verbose=True)]\n",
    "        best_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=callbacks)\n",
    "    except:\n",
    "        try:\n",
    "            best_model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "                           early_stopping_rounds=50, verbose=True)\n",
    "        except:\n",
    "            best_model.fit(X_train, y_train)\n",
    "\n",
    "    val_preds = best_model.predict_proba(X_val)[:, 1]\n",
    "    thresholds = np.linspace(0.3, 0.7, 40)\n",
    "    best_acc = 0\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        binary_preds = (val_preds > threshold).astype(int)\n",
    "        acc = accuracy_score(y_val, binary_preds)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"Best accuracy: {best_acc:.4f} with threshold: {best_threshold:.4f}\")\n",
    "    best_model.threshold = best_threshold\n",
    "\n",
    "    return best_model, best_acc\n",
    "\n",
    "\n",
    "def tune_random_forest(X_train, y_train, X_val, y_val, n_trials=50, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Tune RandomForest hyperparameters with parallel processing\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train, X_val, y_val : training and validation data\n",
    "    n_trials : int, number of Optuna trials\n",
    "    n_jobs : int, number of parallel jobs (-1 for all cores)\n",
    "    \"\"\"\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "            'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "            'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "            'n_jobs': n_jobs,\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        return accuracy_score(y_val, y_pred)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=600, n_jobs=n_jobs)\n",
    "\n",
    "    print(f\"Best RandomForest parameters: {study.best_params}\")\n",
    "\n",
    "    best_params = study.best_params.copy()\n",
    "    best_params['n_jobs'] = n_jobs\n",
    "    best_model = RandomForestClassifier(**best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    best_score = accuracy_score(y_val, best_model.predict(X_val))\n",
    "    print(f\"Best accuracy: {best_score:.4f}\")\n",
    "    return best_model, best_score\n",
    "\n",
    "\n",
    "def tune_gradient_boosting(X_train, y_train, X_val, y_val, n_trials=50, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Tune GradientBoosting hyperparameters with early stopping\n",
    "    \n",
    "    Note: GradientBoostingClassifier doesn't support n_jobs internally,\n",
    "    but we can use parallelization for the trials.\n",
    "    \"\"\"\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        model = GradientBoostingClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        staged_preds = list(model.staged_predict(X_val))\n",
    "        best_iter = np.argmax([accuracy_score(y_val, pred) for pred in staged_preds])\n",
    "\n",
    "        best_score = accuracy_score(y_val, staged_preds[best_iter])\n",
    "\n",
    "        return best_score\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=600, n_jobs=n_jobs)\n",
    "\n",
    "    print(f\"Best GradientBoosting parameters: {study.best_params}\")\n",
    "\n",
    "    best_params = study.best_params.copy()\n",
    "    best_model = GradientBoostingClassifier(**best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    staged_preds = list(best_model.staged_predict(X_val))\n",
    "    best_iter = np.argmax([accuracy_score(y_val, pred) for pred in staged_preds])\n",
    "    print(f\"Best iteration for GradientBoosting: {best_iter + 1}/{best_params['n_estimators']}\")\n",
    "\n",
    "    if best_iter + 1 < best_params['n_estimators']:\n",
    "        print(f\"Pruning model to {best_iter + 1} trees (early stopping)\")\n",
    "        final_model = GradientBoostingClassifier(\n",
    "            n_estimators=best_iter + 1,\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            subsample=best_params['subsample'],\n",
    "            max_features=best_params['max_features'],\n",
    "            random_state=42\n",
    "        )\n",
    "        final_model.fit(X_train, y_train)\n",
    "        best_model = final_model\n",
    "\n",
    "    best_score = accuracy_score(y_val, best_model.predict(X_val))\n",
    "    print(f\"Best accuracy: {best_score:.4f}\")\n",
    "    return best_model, best_score\n",
    "\n",
    "\n",
    "def tune_extra_trees(X_train, y_train, X_val, y_val, n_trials=50, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Tune ExtraTrees hyperparameters with parallel processing\n",
    "    \"\"\"\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "            'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "            'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "            'n_jobs': n_jobs,\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        model = ExtraTreesClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        return accuracy_score(y_val, y_pred)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=600, n_jobs=n_jobs)\n",
    "\n",
    "    print(f\"Best ExtraTrees parameters: {study.best_params}\")\n",
    "\n",
    "    best_params = study.best_params.copy()\n",
    "    best_params['n_jobs'] = n_jobs\n",
    "    best_model = ExtraTreesClassifier(**best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    best_score = accuracy_score(y_val, best_model.predict(X_val))\n",
    "    print(f\"Best accuracy: {best_score:.4f}\")\n",
    "    return best_model, best_score\n",
    "\n",
    "\n",
    "def generate_meta_features(base_models, X_train, y_train, X_val, categorical_cols=None):\n",
    "    \"\"\"Generate meta-features for stacking with support for categorical features\"\"\"\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    meta_features_train = np.zeros((X_train.shape[0], len(base_models)))\n",
    "\n",
    "    for i, (name, model) in enumerate(base_models.items()):\n",
    "        print(f\"Generating OOF predictions for {name}\")\n",
    "        oof_preds = np.zeros(X_train.shape[0])\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train = y_train.iloc[train_idx]\n",
    "\n",
    "            model_clone = model.__class__(**model.get_params())\n",
    "\n",
    "            if name == 'catboost' and hasattr(model, 'categorical_features'):\n",
    "                model_clone.fit(\n",
    "                    X_fold_train, y_fold_train,\n",
    "                    cat_features=model.categorical_features,\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "                fold_preds = model_clone.predict_proba(X_fold_val)[:, 1]\n",
    "            else:\n",
    "                model_clone.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "                if hasattr(model_clone, 'predict_proba'):\n",
    "                    fold_preds = model_clone.predict_proba(X_fold_val)[:, 1]\n",
    "                else:\n",
    "                    fold_preds = model_clone.predict(X_fold_val)\n",
    "\n",
    "            oof_preds[val_idx] = fold_preds\n",
    "\n",
    "        meta_features_train[:, i] = oof_preds\n",
    "\n",
    "    meta_preds_val = np.zeros((X_val.shape[0], len(base_models)))\n",
    "\n",
    "    for i, (name, model) in enumerate(base_models.items()):\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            val_preds = model.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            val_preds = model.predict(X_val)\n",
    "\n",
    "        meta_preds_val[:, i] = val_preds\n",
    "\n",
    "    return meta_features_train, meta_preds_val\n",
    "\n",
    "\n",
    "def tune_meta_learner(meta_features_train, y_train, meta_preds_val, y_val, n_trials=50, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Tune meta-learner model with parallel processing\n",
    "    \"\"\"\n",
    "\n",
    "    def objective(trial):\n",
    "        model_type = trial.suggest_categorical('model_type', ['catboost', 'xgboost', 'logistic'])\n",
    "\n",
    "        if model_type == 'catboost':\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 100, 500),\n",
    "                'depth': trial.suggest_int('depth', 3, 8),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.1, 10.0, log=True),\n",
    "                'verbose': 0,\n",
    "                'thread_count': n_jobs if n_jobs > 0 else None,\n",
    "                'random_seed': 42\n",
    "            }\n",
    "            model = cb.CatBoostClassifier(**params)\n",
    "\n",
    "        elif model_type == 'xgboost':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 2, 7),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'n_jobs': n_jobs,\n",
    "                'random_state': 42\n",
    "            }\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "\n",
    "        else:\n",
    "            params = {\n",
    "                'C': trial.suggest_float('C', 0.001, 10.0, log=True),\n",
    "                'solver': trial.suggest_categorical('solver', ['liblinear', 'saga']),\n",
    "                'max_iter': 1000,\n",
    "                'n_jobs': n_jobs,\n",
    "                'random_state': 42\n",
    "            }\n",
    "            model = LogisticRegression(**params)\n",
    "\n",
    "        model.fit(meta_features_train, y_train)\n",
    "\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba = model.predict_proba(meta_preds_val)[:, 1]\n",
    "\n",
    "            thresholds = np.linspace(0.3, 0.7, 20)\n",
    "            best_acc = 0\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba > threshold).astype(int)\n",
    "                acc = accuracy_score(y_val, y_pred)\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "\n",
    "            return best_acc\n",
    "        else:\n",
    "            y_pred = model.predict(meta_preds_val)\n",
    "            return accuracy_score(y_val, y_pred)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=600, n_jobs=n_jobs)\n",
    "\n",
    "    print(f\"Best meta-learner parameters: {study.best_params}\")\n",
    "\n",
    "    best_params = study.best_params.copy()\n",
    "    model_type = best_params.pop('model_type')\n",
    "\n",
    "    if model_type == 'catboost':\n",
    "        best_params['verbose'] = 0\n",
    "        best_params['thread_count'] = n_jobs if n_jobs > 0 else None\n",
    "        best_params['random_seed'] = 42\n",
    "        best_model = cb.CatBoostClassifier(**best_params)\n",
    "    elif model_type == 'xgboost':\n",
    "        best_params['n_jobs'] = n_jobs\n",
    "        best_params['random_state'] = 42\n",
    "        best_model = xgb.XGBClassifier(**best_params)\n",
    "    else:  # logistic\n",
    "        best_params['n_jobs'] = n_jobs\n",
    "        best_params['max_iter'] = 1000\n",
    "        best_params['random_state'] = 42\n",
    "        best_model = LogisticRegression(**best_params)\n",
    "\n",
    "    best_model.fit(meta_features_train, y_train)\n",
    "\n",
    "    if hasattr(best_model, 'predict_proba'):\n",
    "        y_pred_proba = best_model.predict_proba(meta_preds_val)[:, 1]\n",
    "\n",
    "        thresholds = np.linspace(0.3, 0.7, 40)\n",
    "        best_acc = 0\n",
    "        best_threshold = 0.5\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba > threshold).astype(int)\n",
    "            acc = accuracy_score(y_val, y_pred)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_threshold = threshold\n",
    "\n",
    "        print(f\"Best threshold: {best_threshold:.4f}\")\n",
    "        best_model.threshold = best_threshold\n",
    "        best_score = best_acc\n",
    "    else:\n",
    "        best_score = accuracy_score(y_val, best_model.predict(meta_preds_val))\n",
    "\n",
    "    print(f\"Best meta-learner accuracy: {best_score:.4f}\")\n",
    "    return best_model, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2a0c841f23ca62b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T09:39:30.603376Z",
     "start_time": "2025-03-10T09:19:08.590765Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(os.cpu_count())\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def run_optimized_spaceship_solution(n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Run the fully optimized spaceship Titanic solution with separate data formats for each model type\n",
    "    \"\"\"\n",
    "    print(\"===== DATA PREPARATION =====\")\n",
    "    data_dict = prepare_spaceship_data(train_data, test_data)\n",
    "\n",
    "    print(\"Applying enhanced feature engineering...\")\n",
    "    dfs = [\n",
    "        (data_dict['X_train'], 'train'),\n",
    "        (data_dict['X_val'], 'val'),\n",
    "        (data_dict['X_test'], 'test')\n",
    "    ]\n",
    "    combined = pd.concat([df.assign(source=source) for df, source in dfs], axis=0)\n",
    "\n",
    "    combined = enhanced_feature_engineering(combined)\n",
    "\n",
    "    data_dict['X_train'] = combined[combined['source'] == 'train'].drop('source', axis=1)\n",
    "    data_dict['X_val'] = combined[combined['source'] == 'val'].drop('source', axis=1)\n",
    "    data_dict['X_test'] = combined[combined['source'] == 'test'].drop('source', axis=1)\n",
    "\n",
    "    print(\"Removing individual name features to prevent dimensionality explosion...\")\n",
    "    name_columns = [col for col in data_dict['X_train'].columns if col.startswith(('FirstName_', 'LastName_'))]\n",
    "    print(f\"Removing {len(name_columns)} name-based features\")\n",
    "\n",
    "    for dataset_name in ['X_train', 'X_val', 'X_test']:\n",
    "        data_dict[dataset_name] = data_dict[dataset_name].drop(columns=name_columns)\n",
    "\n",
    "    print(f\"Feature count after name removal: {data_dict['X_train'].shape[1]}\")\n",
    "\n",
    "    print(\"\\n===== STRICT CATEGORICAL FEATURE SELECTION =====\")\n",
    "    preserved_cat_cols = []\n",
    "    if 'preserved_categorical_cols' in data_dict:\n",
    "        preserved_cat_cols = data_dict['preserved_categorical_cols']\n",
    "        print(f\"Found {len(preserved_cat_cols)} preserved categorical features\")\n",
    "    else:\n",
    "        preserved_cat_cols = [col for col in data_dict['X_train'].columns if col.startswith('cat_')]\n",
    "        print(f\"Identified {len(preserved_cat_cols)} preserved categorical features by prefix\")\n",
    "\n",
    "    binary_cat_cols = []\n",
    "\n",
    "    strict_binary_patterns = [\n",
    "        'CryoSleep',\n",
    "        'VIP',\n",
    "        'PassengerGroup',\n",
    "        'TravelingAlone',\n",
    "        'HasFamily',\n",
    "        'HomePlanet_',\n",
    "        'Destination_',\n",
    "        'CabinDeck_',\n",
    "        'CabinSide_',\n",
    "        'Route_'\n",
    "    ]\n",
    "\n",
    "    for col in data_dict['X_train'].columns:\n",
    "\n",
    "        if any(pattern in col for pattern in strict_binary_patterns):\n",
    "            binary_cat_cols.append(col)\n",
    "\n",
    "    if len(binary_cat_cols) > 50:\n",
    "        print(f\"WARNING: Too many binary categorical features ({len(binary_cat_cols)}), limiting to 50 most important\")\n",
    "        binary_cat_cols = binary_cat_cols[:50]\n",
    "\n",
    "    print(f\"Selected {len(binary_cat_cols)} additional binary categorical features\")\n",
    "\n",
    "    categorical_cols = preserved_cat_cols + binary_cat_cols\n",
    "    print(f\"Using total of {len(categorical_cols)} categorical features for CatBoost\")\n",
    "\n",
    "    if preserved_cat_cols:\n",
    "        print(f\"Sample preserved features: {preserved_cat_cols[:5]}\")\n",
    "    if binary_cat_cols:\n",
    "        print(f\"Sample binary features: {binary_cat_cols[:5]}\")\n",
    "\n",
    "    numerical_cols = [col for col in data_dict['X_train'].columns if col not in categorical_cols]\n",
    "    print(f\"Identified {len(numerical_cols)} numerical features\")\n",
    "\n",
    "    print(\"\\n===== FEATURE COUNT DIAGNOSTICS =====\")\n",
    "    print(f\"Total features before selection: {data_dict['X_train'].shape[1]}\")\n",
    "    print(f\"Number of preserved categorical features: {len(preserved_cat_cols)}\")\n",
    "    print(f\"Number of binary categorical features: {len(binary_cat_cols)}\")\n",
    "    print(f\"Number of numerical features: {len(numerical_cols)}\")\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    if numerical_cols:\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "        num_imputer.fit(data_dict['X_train'][numerical_cols])\n",
    "\n",
    "        for dataset_name in ['X_train', 'X_val', 'X_test']:\n",
    "            numerical_data = data_dict[dataset_name][numerical_cols]\n",
    "            imputed_data = pd.DataFrame(\n",
    "                num_imputer.transform(numerical_data),\n",
    "                columns=numerical_cols,\n",
    "                index=data_dict[dataset_name].index\n",
    "            )\n",
    "\n",
    "            for col in numerical_cols:\n",
    "                data_dict[dataset_name][col] = imputed_data[col]\n",
    "\n",
    "    if categorical_cols:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "        cat_imputer.fit(data_dict['X_train'][categorical_cols])\n",
    "\n",
    "        for dataset_name in ['X_train', 'X_val', 'X_test']:\n",
    "            categorical_data = data_dict[dataset_name][categorical_cols]\n",
    "            imputed_data = pd.DataFrame(\n",
    "                cat_imputer.transform(categorical_data),\n",
    "                columns=categorical_cols,\n",
    "                index=data_dict[dataset_name].index\n",
    "            )\n",
    "\n",
    "            for col in categorical_cols:\n",
    "                data_dict[dataset_name][col] = imputed_data[col]\n",
    "\n",
    "    print(\"\\n===== CREATING MODEL-SPECIFIC DATASETS =====\")\n",
    "\n",
    "    data_dict['X_train_catboost'] = data_dict['X_train'].copy()\n",
    "    data_dict['X_val_catboost'] = data_dict['X_val'].copy()\n",
    "    data_dict['X_test_catboost'] = data_dict['X_test'].copy()\n",
    "\n",
    "    print(\"Creating CatBoost dataset with string categorical features...\")\n",
    "    for col in categorical_cols:\n",
    "        for dataset_name in ['X_train_catboost', 'X_val_catboost', 'X_test_catboost']:\n",
    "            data_dict[dataset_name][col] = data_dict[dataset_name][col].astype(str)\n",
    "\n",
    "    data_dict['X_train_xgb'] = data_dict['X_train'].copy()\n",
    "    data_dict['X_val_xgb'] = data_dict['X_val'].copy()\n",
    "    data_dict['X_test_xgb'] = data_dict['X_test'].copy()\n",
    "\n",
    "    print(\"Creating XGBoost dataset with pandas category features...\")\n",
    "    for col in categorical_cols:\n",
    "        for dataset_name in ['X_train_xgb', 'X_val_xgb', 'X_test_xgb']:\n",
    "            data_dict[dataset_name][col] = data_dict[dataset_name][col].astype('category')\n",
    "\n",
    "    data_dict['X_train_sklearn'] = data_dict['X_train'].copy()\n",
    "    data_dict['X_val_sklearn'] = data_dict['X_val'].copy()\n",
    "    data_dict['X_test_sklearn'] = data_dict['X_test'].copy()\n",
    "\n",
    "    print(\"Creating sklearn dataset with numerical features only...\")\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "    cols_to_encode = []\n",
    "    for col in data_dict['X_train_sklearn'].columns:\n",
    "        if data_dict['X_train_sklearn'][col].dtype == 'object' or isinstance(data_dict['X_train_sklearn'][col].dtype,\n",
    "                                                                             pd.CategoricalDtype):\n",
    "            cols_to_encode.append(col)\n",
    "\n",
    "    if cols_to_encode:\n",
    "        print(f\"Encoding {len(cols_to_encode)} categorical features for sklearn models\")\n",
    "        ord_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "        ord_encoder.fit(data_dict['X_train_sklearn'][cols_to_encode])\n",
    "\n",
    "        for dataset_name in ['X_train_sklearn', 'X_val_sklearn', 'X_test_sklearn']:\n",
    "            encoded_data = ord_encoder.transform(data_dict[dataset_name][cols_to_encode])\n",
    "\n",
    "            for i, col in enumerate(cols_to_encode):\n",
    "                data_dict[dataset_name][col] = encoded_data[:, i]\n",
    "\n",
    "    print(\"\\n===== OPTUNA HYPERPARAMETER OPTIMIZATION =====\")\n",
    "    import multiprocessing\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    print(f\"System has {cpu_count} CPUs available\")\n",
    "\n",
    "    if n_jobs == -1:\n",
    "        n_jobs = cpu_count\n",
    "\n",
    "    print(f\"Using {n_jobs} parallel jobs for optimization\")\n",
    "\n",
    "    data_dict['categorical_features'] = categorical_cols\n",
    "\n",
    "    ensemble = tune_with_optuna_multi_data(\n",
    "        data_dict,\n",
    "        categorical_cols=categorical_cols,\n",
    "        n_trials=100,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    print(\"\\n===== FINAL PREDICTION =====\")\n",
    "    meta_features_test = np.zeros((data_dict['X_test'].shape[0], len(ensemble['base_models'])))\n",
    "\n",
    "    for i, (name, model) in enumerate(ensemble['base_models'].items()):\n",
    "        if name == 'catboost':\n",
    "            meta_features_test[:, i] = model.predict_proba(data_dict['X_test_catboost'])[:, 1]\n",
    "        elif name == 'xgboost':\n",
    "            meta_features_test[:, i] = model.predict_proba(data_dict['X_test_xgb'])[:, 1]\n",
    "        else:\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                meta_features_test[:, i] = model.predict_proba(data_dict['X_test_sklearn'])[:, 1]\n",
    "            else:\n",
    "                meta_features_test[:, i] = model.predict(data_dict['X_test_sklearn'])\n",
    "\n",
    "    meta_learner = ensemble['meta_learner']\n",
    "    if hasattr(meta_learner, 'predict_proba'):\n",
    "        final_probs = meta_learner.predict_proba(meta_features_test)[:, 1]\n",
    "        threshold = meta_learner.threshold if hasattr(meta_learner, 'threshold') else 0.5\n",
    "        final_preds = (final_probs > threshold).astype(bool)\n",
    "    else:\n",
    "        final_preds = meta_learner.predict(meta_features_test).astype(bool)\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': data_dict['test_ids'],\n",
    "        'Transported': final_preds\n",
    "    })\n",
    "\n",
    "    submission_path = 'optimized_submission.csv'\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\"Optimized submission file created: {submission_path}\")\n",
    "\n",
    "    return {\n",
    "        'ensemble': ensemble,\n",
    "        'submission': submission,\n",
    "        'data_dict': data_dict\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "54225336-29d5-43cb-82d3-6d8319f9897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weighted_ensemble(base_models, meta_features_train, meta_preds_val, y_train, y_val):\n",
    "    \"\"\"\n",
    "    Create a weighted ensemble using the pre-calculated weights\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_models : dict\n",
    "        Dictionary of trained base models\n",
    "    meta_features_train : numpy.ndarray\n",
    "        Meta-features for training (predictions from base models)\n",
    "    meta_preds_val : numpy.ndarray\n",
    "        Meta-predictions for validation (predictions from base models)\n",
    "    y_train : pandas.Series\n",
    "        Training target values\n",
    "    y_val : pandas.Series\n",
    "        Validation target values\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Ensemble dictionary with base models and meta-learner\n",
    "    \"\"\"\n",
    "    print(\"\\n==== Creating Weighted Ensemble ====\")\n",
    "\n",
    "    base_scores = np.array([0.8189, 0.8246, 0.7993, 0.8051, 0.7982])\n",
    "\n",
    "    temperature = 5.0  # Higher = more focused on best models\n",
    "    weights = np.exp(temperature * (base_scores - np.max(base_scores)))\n",
    "    weights = weights / np.sum(weights)\n",
    "\n",
    "    print(f\"Model weights: {weights}\")\n",
    "\n",
    "    class WeightedEnsemble:\n",
    "        def __init__(self, weights, threshold=0.5):\n",
    "            self.weights = weights\n",
    "            self.threshold = threshold\n",
    "\n",
    "        def predict_proba(self, X):\n",
    "            weighted_avg = np.average(X, axis=1, weights=self.weights)\n",
    "            return np.column_stack([1 - weighted_avg, weighted_avg])\n",
    "\n",
    "        def predict(self, X):\n",
    "            probs = self.predict_proba(X)[:, 1]\n",
    "            return (probs > self.threshold).astype(int)\n",
    "\n",
    "    weighted_val_preds = np.average(meta_preds_val, axis=1, weights=weights)\n",
    "\n",
    "    best_threshold = 0.5\n",
    "    best_acc = 0\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    for threshold in np.linspace(0.3, 0.7, 41):\n",
    "        acc = accuracy_score(y_val, (weighted_val_preds > threshold).astype(int))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"Best threshold: {best_threshold}, Weighted Ensemble Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "    ensemble = {\n",
    "        'base_models': base_models,\n",
    "        'meta_learner': WeightedEnsemble(weights=weights, threshold=best_threshold)\n",
    "    }\n",
    "\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877701a9-50c9-4880-a169-c096b7ecbd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_xgboost_focused(data_dict, n_trials=200, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Focused Optuna tuning just for XGBoost with more trials and wider search space\n",
    "    \"\"\"\n",
    "    print(\"\\n==== Enhanced XGBoost Tuning ====\")\n",
    "\n",
    "    X_train = data_dict['X_train'].copy()\n",
    "    y_train = data_dict['y_train']\n",
    "    X_val = data_dict['X_val'].copy()\n",
    "    y_val = data_dict['y_val']\n",
    "\n",
    "    cat_cols = [col for col in X_train.columns if\n",
    "                X_train[col].dtype == 'object' or\n",
    "                col.startswith('cat_') or\n",
    "                isinstance(X_train[col].dtype, pd.CategoricalDtype)]\n",
    "\n",
    "    for col in cat_cols:\n",
    "        X_train[col] = X_train[col].astype('category')\n",
    "        X_val[col] = X_val[col].astype('category')\n",
    "\n",
    "    print(f\"Converted {len(cat_cols)} columns to category type\")\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0.01, 2.0, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 2.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 2.0, log=True),\n",
    "            'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.8, 1.2),\n",
    "            'tree_method': 'hist'\n",
    "        }\n",
    "\n",
    "        early_stopping_rounds = 50\n",
    "\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss')\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        if hasattr(model, 'best_iteration'):\n",
    "            preds = model.predict_proba(X_val, iteration_range=(0, model.best_iteration + 1))[:, 1]\n",
    "        else:\n",
    "            preds = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        thresholds = np.linspace(0.3, 0.7, 41)\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            scores.append(accuracy_score(y_val, (preds > threshold).astype(int)))\n",
    "\n",
    "        best_idx = np.argmax(scores)\n",
    "        best_threshold = thresholds[best_idx]\n",
    "        best_score = scores[best_idx]\n",
    "\n",
    "        trial.set_user_attr('threshold', float(best_threshold))\n",
    "        trial.set_user_attr('best_iteration', int(model.best_iteration) if hasattr(model, 'best_iteration') else None)\n",
    "\n",
    "        return best_score\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=n_jobs, show_progress_bar=True)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_threshold = study.best_trial.user_attrs['threshold']\n",
    "    best_iteration = study.best_trial.user_attrs.get('best_iteration')\n",
    "\n",
    "    print(f\"Best XGBoost parameters: {best_params}\")\n",
    "    if best_iteration:\n",
    "        print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "    final_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
    "    final_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    final_model.threshold = best_threshold\n",
    "\n",
    "    if hasattr(final_model, 'best_iteration'):\n",
    "        val_preds = final_model.predict_proba(X_val, iteration_range=(0, final_model.best_iteration + 1))[:, 1]\n",
    "    else:\n",
    "        val_preds = final_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_val, (val_preds > best_threshold).astype(int))\n",
    "    print(f\"Best accuracy: {accuracy:.4f} with threshold: {best_threshold:.4f}\")\n",
    "\n",
    "    X_test = data_dict['X_test'].copy()\n",
    "    for col in cat_cols:\n",
    "        if col in X_test.columns:\n",
    "            X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "    return final_model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8da36244-8504-44d8-8c74-9f22cfe94b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgboost_optimized_solution(n_jobs=-1, n_trials=200):\n",
    "    \"\"\"\n",
    "    Run an optimized XGBoost solution using the same approach that works well in ensemble\n",
    "    \"\"\"\n",
    "    print(\"===== DATA PREPARATION =====\")\n",
    "    data_dict = prepare_spaceship_data(train_data, test_data)\n",
    "\n",
    "    print(\"Applying enhanced feature engineering...\")\n",
    "    dfs = [\n",
    "        (data_dict['X_train'], 'train'),\n",
    "        (data_dict['X_val'], 'val'),\n",
    "        (data_dict['X_test'], 'test')\n",
    "    ]\n",
    "    combined = pd.concat([df.assign(source=source) for df, source in dfs], axis=0)\n",
    "\n",
    "    combined = enhanced_feature_engineering(combined)\n",
    "\n",
    "    data_dict['X_train'] = combined[combined['source'] == 'train'].drop('source', axis=1)\n",
    "    data_dict['X_val'] = combined[combined['source'] == 'val'].drop('source', axis=1)\n",
    "    data_dict['X_test'] = combined[combined['source'] == 'test'].drop('source', axis=1)\n",
    "\n",
    "    print(\"Removing individual name features to prevent dimensionality explosion...\")\n",
    "    name_columns = [col for col in data_dict['X_train'].columns if col.startswith(('FirstName_', 'LastName_'))]\n",
    "    print(f\"Removing {len(name_columns)} name-based features\")\n",
    "\n",
    "    for dataset_name in ['X_train', 'X_val', 'X_test']:\n",
    "        data_dict[dataset_name] = data_dict[dataset_name].drop(columns=name_columns)\n",
    "\n",
    "    print(f\"Feature count after name removal: {data_dict['X_train'].shape[1]}\")\n",
    "\n",
    "    print(\"\\n===== CATEGORICAL FEATURE IDENTIFICATION =====\")\n",
    "    preserved_cat_cols = []\n",
    "    if 'preserved_categorical_cols' in data_dict:\n",
    "        preserved_cat_cols = data_dict['preserved_categorical_cols']\n",
    "        print(f\"Found {len(preserved_cat_cols)} preserved categorical features\")\n",
    "    else:\n",
    "        preserved_cat_cols = [col for col in data_dict['X_train'].columns if col.startswith('cat_')]\n",
    "        print(f\"Identified {len(preserved_cat_cols)} preserved categorical features by prefix\")\n",
    "\n",
    "    binary_cat_cols = []\n",
    "    strict_binary_patterns = [\n",
    "        'CryoSleep',\n",
    "        'VIP',\n",
    "        'PassengerGroup',\n",
    "        'TravelingAlone',\n",
    "        'HasFamily',\n",
    "        'HomePlanet_',\n",
    "        'Destination_',\n",
    "        'CabinDeck_',\n",
    "        'CabinSide_',\n",
    "        'Route_'\n",
    "    ]\n",
    "\n",
    "    for col in data_dict['X_train'].columns:\n",
    "        if any(pattern in col for pattern in strict_binary_patterns):\n",
    "            binary_cat_cols.append(col)\n",
    "\n",
    "    if len(binary_cat_cols) > 50:\n",
    "        print(f\"WARNING: Too many binary categorical features ({len(binary_cat_cols)}), limiting to 50 most important\")\n",
    "        binary_cat_cols = binary_cat_cols[:50]\n",
    "\n",
    "    print(f\"Selected {len(binary_cat_cols)} additional binary categorical features\")\n",
    "\n",
    "    categorical_cols = preserved_cat_cols + binary_cat_cols\n",
    "    print(f\"Using total of {len(categorical_cols)} categorical features\")\n",
    "\n",
    "    numerical_cols = [col for col in data_dict['X_train'].columns if col not in categorical_cols]\n",
    "    print(f\"Identified {len(numerical_cols)} numerical features\")\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    if numerical_cols:\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        num_imputer.fit(data_dict['X_train'][numerical_cols])\n",
    "\n",
    "        for dataset_name in ['X_train', 'X_val', 'X_test']:\n",
    "            numerical_data = data_dict[dataset_name][numerical_cols]\n",
    "            imputed_data = pd.DataFrame(\n",
    "                num_imputer.transform(numerical_data),\n",
    "                columns=numerical_cols,\n",
    "                index=data_dict[dataset_name].index\n",
    "            )\n",
    "\n",
    "            for col in numerical_cols:\n",
    "                data_dict[dataset_name][col] = imputed_data[col]\n",
    "\n",
    "    if categorical_cols:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        cat_imputer.fit(data_dict['X_train'][categorical_cols])\n",
    "\n",
    "        for dataset_name in ['X_train', 'X_val', 'X_test']:\n",
    "            categorical_data = data_dict[dataset_name][categorical_cols]\n",
    "            imputed_data = pd.DataFrame(\n",
    "                cat_imputer.transform(categorical_data),\n",
    "                columns=categorical_cols,\n",
    "                index=data_dict[dataset_name].index\n",
    "            )\n",
    "\n",
    "            for col in categorical_cols:\n",
    "                data_dict[dataset_name][col] = imputed_data[col]\n",
    "\n",
    "    print(\"\\n===== PREPARING XGBOOST-SPECIFIC DATASET =====\")\n",
    "    X_train_xgb = data_dict['X_train'].copy()\n",
    "    X_val_xgb = data_dict['X_val'].copy()\n",
    "    X_test_xgb = data_dict['X_test'].copy()\n",
    "\n",
    "    print(\"Converting categorical features to category type...\")\n",
    "    for col in categorical_cols:\n",
    "        X_train_xgb[col] = X_train_xgb[col].astype('category')\n",
    "        X_val_xgb[col] = X_val_xgb[col].astype('category')\n",
    "        X_test_xgb[col] = X_test_xgb[col].astype('category')\n",
    "\n",
    "    print(f\"Converted {len(categorical_cols)} columns to category type\")\n",
    "\n",
    "    print(\"\\n===== OPTUNA HYPERPARAMETER OPTIMIZATION FOR XGBOOST =====\")\n",
    "    import multiprocessing\n",
    "    import optuna\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    print(f\"System has {cpu_count} CPUs available\")\n",
    "\n",
    "    if n_jobs == -1:\n",
    "        n_jobs = cpu_count\n",
    "\n",
    "    print(f\"Using {n_jobs} parallel jobs for optimization\")\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        params = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0.01, 1.0, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0, log=True),\n",
    "            'n_jobs': n_jobs,\n",
    "            'enable_categorical': True\n",
    "        }\n",
    "\n",
    "        model = xgb.XGBClassifier(**params, random_state=42)\n",
    "\n",
    "        try:\n",
    "\n",
    "            callbacks = [xgb.callback.EarlyStopping(rounds=50, verbose=False)]\n",
    "            model.fit(X_train_xgb, data_dict['y_train'],\n",
    "                      eval_set=[(X_val_xgb, data_dict['y_val'])],\n",
    "                      callbacks=callbacks, verbose=False)\n",
    "        except:\n",
    "            try:\n",
    "\n",
    "                model.fit(X_train_xgb, data_dict['y_train'],\n",
    "                          eval_set=[(X_val_xgb, data_dict['y_val'])],\n",
    "                          early_stopping_rounds=50, verbose=False)\n",
    "            except:\n",
    "\n",
    "                model.fit(X_train_xgb, data_dict['y_train'])\n",
    "\n",
    "        preds = model.predict_proba(X_val_xgb)[:, 1]\n",
    "        thresholds = np.linspace(0.4, 0.6, 20)\n",
    "        best_acc = 0\n",
    "        best_thresh = 0.5\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            binary_preds = (preds > threshold).astype(int)\n",
    "            acc = accuracy_score(data_dict['y_val'], binary_preds)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_thresh = threshold\n",
    "\n",
    "        trial.set_user_attr('threshold', float(best_thresh))\n",
    "\n",
    "        return best_acc\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=n_jobs)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_threshold = study.best_trial.user_attrs['threshold']\n",
    "\n",
    "    print(f\"Best XGBoost parameters: {best_params}\")\n",
    "    print(f\"Best threshold: {best_threshold:.4f}\")\n",
    "\n",
    "    print(\"\\n===== TRAINING FINAL MODEL =====\")\n",
    "    best_params['n_jobs'] = n_jobs\n",
    "    best_params['enable_categorical'] = True\n",
    "\n",
    "    final_model = xgb.XGBClassifier(**best_params, random_state=42)\n",
    "\n",
    "    try:\n",
    "        callbacks = [xgb.callback.EarlyStopping(rounds=50, verbose=False)]\n",
    "        final_model.fit(X_train_xgb, data_dict['y_train'],\n",
    "                        eval_set=[(X_val_xgb, data_dict['y_val'])],\n",
    "                        callbacks=callbacks, verbose=False)\n",
    "    except:\n",
    "        try:\n",
    "\n",
    "            final_model.fit(X_train_xgb, data_dict['y_train'],\n",
    "                            eval_set=[(X_val_xgb, data_dict['y_val'])],\n",
    "                            early_stopping_rounds=50, verbose=False)\n",
    "        except:\n",
    "\n",
    "            final_model.fit(X_train_xgb, data_dict['y_train'])\n",
    "\n",
    "    final_model.threshold = best_threshold\n",
    "\n",
    "    val_preds = final_model.predict_proba(X_val_xgb)[:, 1]\n",
    "    val_accuracy = accuracy_score(data_dict['y_val'], (val_preds > best_threshold).astype(int))\n",
    "    print(f\"Validation accuracy: {val_accuracy:.4f} with threshold: {best_threshold:.4f}\")\n",
    "\n",
    "    print(\"\\n===== FINAL PREDICTION =====\")\n",
    "    test_preds = final_model.predict_proba(X_test_xgb)[:, 1]\n",
    "\n",
    "    final_preds = (test_preds > best_threshold).astype(bool)\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': data_dict['test_ids'],\n",
    "        'Transported': final_preds\n",
    "    })\n",
    "\n",
    "    submission_path = 'xgboost_optimized_submission.csv'\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\"XGBoost submission file created: {submission_path}\")\n",
    "    print(f\"Positive predictions: {submission['Transported'].sum()} ({submission['Transported'].mean() * 100:.2f}%)\")\n",
    "\n",
    "    return {\n",
    "        'model': final_model,\n",
    "        'submission': submission,\n",
    "        'data_dict': data_dict,\n",
    "        'validation_accuracy': val_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0c54fe6c-508c-4bba-b697-261d60779177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xgboost_submission(xgb_model, data_dict):\n",
    "    \"\"\"\n",
    "    Create a submission file using the trained XGBoost model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    xgb_model : XGBClassifier\n",
    "        Trained XGBoost model with threshold attribute\n",
    "    data_dict : dict\n",
    "        Dictionary containing data, including test set and passenger IDs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Submission dataframe with PassengerId and Transported columns\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    X_test = data_dict['X_test'].copy()\n",
    "\n",
    "    passenger_ids = data_dict['test_passenger_ids']\n",
    "\n",
    "    cat_cols = [col for col in X_test.columns if\n",
    "                X_test[col].dtype == 'object' or\n",
    "                col.startswith('cat_') or\n",
    "                isinstance(X_test[col].dtype, pd.CategoricalDtype)]\n",
    "\n",
    "    for col in cat_cols:\n",
    "        X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "    if hasattr(xgb_model, 'best_iteration') and xgb_model.best_iteration is not None:\n",
    "        test_preds = xgb_model.predict_proba(X_test, iteration_range=(0, xgb_model.best_iteration + 1))[:, 1]\n",
    "    else:\n",
    "        test_preds = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    threshold = xgb_model.threshold if hasattr(xgb_model, 'threshold') else 0.5\n",
    "    predicted_labels = (test_preds > threshold).astype(bool)\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': passenger_ids,\n",
    "        'Transported': predicted_labels\n",
    "    })\n",
    "\n",
    "    print(f\"Created submission with {len(submission)} rows\")\n",
    "    print(f\"Positive predictions: {submission['Transported'].sum()} ({submission['Transported'].mean() * 100:.2f}%)\")\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1890654e-7164-4db5-bd19-8e59dc18f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_data_for_catboost(X_train, y_train, X_val, y_val, X_test, test_ids):\n",
    "    \"\"\"\n",
    "    Creates a CatBoost-friendly version of the data while preserving the original processed data\n",
    "    for other models in the ensemble.\n",
    "    \n",
    "    This function works with your existing processed data and recovers categorical features.\n",
    "    \"\"\"\n",
    "    print(\"\\n===== ADAPTING DATA FOR CATBOOST =====\")\n",
    "\n",
    "    categorical_groups = {}\n",
    "\n",
    "    categorical_prefixes = [\n",
    "        'HomePlanet_', 'Destination_', 'CabinDeck_', 'CabinSide_',\n",
    "        'AgeGroup_', 'Route_', 'LastName_', 'FirstName_'\n",
    "    ]\n",
    "\n",
    "    standard_categorical = ['CryoSleep', 'VIP', 'PassengerGroup']\n",
    "\n",
    "    all_columns = list(X_train.columns)\n",
    "    for prefix in categorical_prefixes:\n",
    "        matching_cols = [col for col in all_columns if col.startswith(prefix)]\n",
    "        if matching_cols:\n",
    "            original_feature = prefix.rstrip('_')\n",
    "            categorical_groups[original_feature] = matching_cols\n",
    "\n",
    "    for col in standard_categorical:\n",
    "        if col in all_columns:\n",
    "            categorical_groups[col] = [col]\n",
    "\n",
    "    print(f\"Identified {len(categorical_groups)} categorical feature groups\")\n",
    "\n",
    "    cb_X_train = X_train.copy()\n",
    "    cb_X_val = X_val.copy()\n",
    "    cb_X_test = X_test.copy()\n",
    "\n",
    "    all_categorical_columns = []\n",
    "    for original_feature, cols in categorical_groups.items():\n",
    "        if len(cols) > 1:\n",
    "\n",
    "            for df_name, df in [('train', cb_X_train), ('val', cb_X_val), ('test', cb_X_test)]:\n",
    "                df[original_feature] = \"Other\"\n",
    "\n",
    "                for col in cols:\n",
    "                    category = col[len(original_feature) + 1:]\n",
    "\n",
    "                    highest_value_mask = df[col] > df[cols].mean(axis=1)\n",
    "                    df.loc[highest_value_mask, original_feature] = category\n",
    "\n",
    "                df.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "            all_categorical_columns.append(original_feature)\n",
    "        else:\n",
    "\n",
    "            all_categorical_columns.append(cols[0])\n",
    "\n",
    "    for col in all_categorical_columns:\n",
    "        if col in cb_X_train.columns:\n",
    "            for df in [cb_X_train, cb_X_val, cb_X_test]:\n",
    "                df[col] = df[col].astype(str)\n",
    "\n",
    "    print(f\"Created {len(all_categorical_columns)} categorical columns for CatBoost\")\n",
    "\n",
    "    return {\n",
    "        'cb_X_train': cb_X_train,\n",
    "        'cb_X_val': cb_X_val,\n",
    "        'cb_X_test': cb_X_test,\n",
    "        'categorical_features': all_categorical_columns,\n",
    "        'y_train': y_train,\n",
    "        'y_val': y_val,\n",
    "        'test_ids': test_ids\n",
    "    }\n",
    "\n",
    "\n",
    "def prepare_hybrid_catboost_data(data_dict):\n",
    "    \"\"\"\n",
    "    Create a hybrid version with both preserved categorical features and original binary features\n",
    "    \"\"\"\n",
    "    print(\"Creating hybrid CatBoost data with both preserved and binary features\")\n",
    "\n",
    "    X_train_hybrid = data_dict['X_train'].copy()\n",
    "    X_val_hybrid = data_dict['X_val'].copy()\n",
    "    X_test_hybrid = data_dict['X_test'].copy()\n",
    "\n",
    "    binary_cat_cols = [\n",
    "        col for col in data_dict['X_train'].columns\n",
    "        if col.startswith(('FirstName_', 'LastName_', 'CryoSleep', 'VIP', 'PassengerGroup'))\n",
    "    ]\n",
    "\n",
    "    preserved_cat_cols = []\n",
    "    if 'preserved_categorical_cols' in data_dict:\n",
    "        preserved_cat_cols = data_dict['preserved_categorical_cols']\n",
    "\n",
    "    all_cat_cols = binary_cat_cols + preserved_cat_cols\n",
    "    print(f\"Using {len(preserved_cat_cols)} preserved and {len(binary_cat_cols)} binary categorical features\")\n",
    "\n",
    "    return {\n",
    "        'X_train': X_train_hybrid,\n",
    "        'X_val': X_val_hybrid,\n",
    "        'X_test': X_test_hybrid,\n",
    "        'categorical_features': all_cat_cols\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "43f5aed0-cc7c-4500-a89d-5970dfb86345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DATA PREPARATION =====\n",
      "Loading and preparing Spaceship Titanic data with preserved categorical features...\n",
      "Training data: 8693 rows, 14 columns\n",
      "Test data: 4277 rows, 13 columns\n",
      "Converted boolean target to integer (0/1)\n",
      "Split into 6954 training samples and 1739 validation samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/r28hjx957zd3v1xzgv0q81lr0000gn/T/ipykernel_47402/3400320643.py:96: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "\n",
      "/var/folders/4k/r28hjx957zd3v1xzgv0q81lr0000gn/T/ipykernel_47402/3400320643.py:96: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.         0.2699005  0.99688958 ... 0.99654378 0.83202358 0.83671558]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "\n",
      "/var/folders/4k/r28hjx957zd3v1xzgv0q81lr0000gn/T/ipykernel_47402/3400320643.py:96: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.01152074 0.         0.         ... 0.         0.01669941 0.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "\n",
      "/var/folders/4k/r28hjx957zd3v1xzgv0q81lr0000gn/T/ipykernel_47402/3400320643.py:96: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.00019201 0.09577114 0.00311042 ... 0.00345622 0.00982318 0.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "\n",
      "/var/folders/4k/r28hjx957zd3v1xzgv0q81lr0000gn/T/ipykernel_47402/3400320643.py:96: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.98828725 0.63432836 0.         ... 0.         0.14145383 0.16328442]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "\n",
      "/var/folders/4k/r28hjx957zd3v1xzgv0q81lr0000gn/T/ipykernel_47402/3400320643.py:110: FutureWarning:\n",
      "\n",
      "Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "\n",
      "/var/folders/4k/r28hjx957zd3v1xzgv0q81lr0000gn/T/ipykernel_47402/3400320643.py:110: FutureWarning:\n",
      "\n",
      "Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preserving categorical feature: HomePlanet\n",
      "Preserving categorical feature: Destination\n",
      "Preserving categorical feature: CabinDeck\n",
      "Preserving categorical feature: CabinSide\n",
      "Preserving categorical feature: AgeGroup\n",
      "Preserving categorical feature: Route\n",
      "After preprocessing: 5350 features created\n",
      "Added 6 preserved categorical features\n",
      "Found NaN values in X_train_proc for columns: ['CabinNum', 'FamilySize', 'cat_AgeGroup']\n",
      "Filling remaining NaNs with appropriate values...\n",
      "  - CabinNum: filled with median (429.0)\n",
      "  - FamilySize: filled with median (6.0)\n",
      "  - cat_AgeGroup: filled with mode (Adult)\n",
      "Found NaN values in X_val_proc for columns: ['CabinNum', 'FamilySize', 'cat_AgeGroup']\n",
      "Filling remaining NaNs with appropriate values...\n",
      "  - CabinNum: filled with median (420.0)\n",
      "  - FamilySize: filled with median (6.0)\n",
      "  - cat_AgeGroup: filled with mode (Adult)\n",
      "Found NaN values in X_test_proc for columns: ['CabinNum', 'FamilySize', 'cat_AgeGroup']\n",
      "Filling remaining NaNs with appropriate values...\n",
      "  - CabinNum: filled with median (442.0)\n",
      "  - FamilySize: filled with median (6.0)\n",
      "  - cat_AgeGroup: filled with mode (Adult)\n",
      "All datasets are now free of NaN values!\n",
      "Data scaling completed with StandardScaler (preserved categorical features were NOT scaled)\n",
      "Processed training features: (6954, 5356)\n",
      "Processed validation features: (1739, 5356)\n",
      "Processed test features: (4277, 5356)\n",
      "Applying enhanced feature engineering...\n",
      "Adding enhanced features...\n",
      "Removing individual name features to prevent dimensionality explosion...\n",
      "Removing 5287 name-based features\n",
      "Feature count after name removal: 79\n",
      "\n",
      "===== STRICT CATEGORICAL FEATURE SELECTION =====\n",
      "Found 6 preserved categorical features\n",
      "Selected 28 additional binary categorical features\n",
      "Using total of 34 categorical features for CatBoost\n",
      "Sample preserved features: ['cat_HomePlanet', 'cat_Destination', 'cat_CabinDeck', 'cat_CabinSide', 'cat_AgeGroup']\n",
      "Sample binary features: ['CabinDeck_B', 'CabinDeck_C', 'CabinDeck_D', 'CabinDeck_E', 'CabinDeck_F']\n",
      "Identified 45 numerical features\n",
      "\n",
      "===== FEATURE COUNT DIAGNOSTICS =====\n",
      "Total features before selection: 79\n",
      "Number of preserved categorical features: 6\n",
      "Number of binary categorical features: 28\n",
      "Number of numerical features: 45\n",
      "\n",
      "===== CREATING MODEL-SPECIFIC DATASETS =====\n",
      "Creating CatBoost dataset with string categorical features...\n",
      "Creating XGBoost dataset with pandas category features...\n",
      "Creating sklearn dataset with numerical features only...\n",
      "Encoding 34 categorical features for sklearn models\n",
      "\n",
      "===== OPTUNA HYPERPARAMETER OPTIMIZATION =====\n",
      "System has 11 CPUs available\n",
      "Using 11 parallel jobs for optimization\n",
      "Starting comprehensive Optuna tuning with model-specific data formats...\n",
      "Creating model-specific datasets...\n",
      "Created specialized datasets for each model type\n",
      "First 5 categorical features: ['cat_HomePlanet', 'cat_Destination', 'cat_CabinDeck', 'cat_CabinSide', 'cat_AgeGroup']\n",
      "Tuning CatBoost with 34 categorical features\n",
      "First 5 categorical features: ['cat_HomePlanet', 'cat_Destination', 'cat_CabinDeck', 'cat_CabinSide', 'cat_AgeGroup']\n",
      "Best CatBoost parameters: {'iterations': 1557, 'depth': 9, 'learning_rate': 0.07997487526152158, 'l2_leaf_reg': 8.077274915665834, 'random_strength': 3.583257220765366, 'bagging_temperature': 1.0377739327185784, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 14, 'max_ctr_complexity': 4, 'one_hot_max_size': 80}\n",
      "0:\tlearn: 0.6584332\ttest: 0.6581923\tbest: 0.6581923 (0)\ttotal: 35.7ms\tremaining: 55.5s\n",
      "100:\tlearn: 0.3251442\ttest: 0.3908983\tbest: 0.3907366 (97)\ttotal: 1.98s\tremaining: 28.6s\n",
      "200:\tlearn: 0.2104165\ttest: 0.3778230\tbest: 0.3738739 (158)\ttotal: 2.83s\tremaining: 19.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3738739474\n",
      "bestIteration = 158\n",
      "\n",
      "Shrink model to first 159 iterations.\n",
      "Best accuracy: 0.8160 with threshold: 0.4231\n",
      "Best CatBoost validation accuracy: 0.8160\n",
      "\n",
      "==== Tuning XGBoost (11 parallel jobs) ====\n",
      "Tuning XGBoost with 11 threads\n",
      "Tuning XGBoost with 11 threads\n",
      "Converted 34 columns to category type\n",
      "Best XGBoost parameters: {'max_depth': 6, 'learning_rate': 0.028277968827625385, 'n_estimators': 794, 'min_child_weight': 8, 'gamma': 0.23511026951869188, 'subsample': 0.8990413796045202, 'colsample_bytree': 0.9651850149911293, 'reg_alpha': 0.019737782453438008, 'reg_lambda': 2.9178352600844506}\n",
      "Best accuracy: 0.8252 with threshold: 0.4436\n",
      "Best XGBoost validation accuracy: 0.8252\n",
      "\n",
      "==== Tuning RandomForest (11 parallel jobs) ====\n",
      "Best RandomForest parameters: {'n_estimators': 418, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 14, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}\n",
      "Best accuracy: 0.7982\n",
      "Best RandomForest validation accuracy: 0.7982\n",
      "\n",
      "==== Tuning GradientBoosting (11 parallel jobs) ====\n",
      "Best GradientBoosting parameters: {'n_estimators': 800, 'learning_rate': 0.0541598647584957, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 7, 'subsample': 0.5453212103135678, 'max_features': None}\n",
      "Best iteration for GradientBoosting: 220/800\n",
      "Pruning model to 220 trees (early stopping)\n",
      "Best accuracy: 0.8039\n",
      "Best GradientBoosting validation accuracy: 0.8039\n",
      "\n",
      "==== Tuning ExtraTrees (11 parallel jobs) ====\n",
      "Best ExtraTrees parameters: {'n_estimators': 188, 'max_depth': 22, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}\n",
      "Best accuracy: 0.7999\n",
      "Best ExtraTrees validation accuracy: 0.7999\n",
      "\n",
      "==== Generating Meta Features with Model-Specific Data ====\n",
      "Generating meta-features for catboost\n",
      "Generating meta-features for xgboost\n",
      "Generating meta-features for random_forest\n",
      "Generating meta-features for gradient_boosting\n",
      "Generating meta-features for extra_trees\n",
      "\n",
      "==== Tuning Meta-Learner (11 parallel jobs) ====\n",
      "Best meta-learner parameters: {'model_type': 'xgboost', 'n_estimators': 160, 'max_depth': 2, 'learning_rate': 0.18705121250307963, 'subsample': 0.8032242209820655, 'colsample_bytree': 0.5363240270928743}\n",
      "Best threshold: 0.5256\n",
      "Best meta-learner accuracy: 0.8200\n",
      "Best meta-learner validation accuracy: 0.8200\n",
      "\n",
      "==== Creating Weighted Ensemble ====\n",
      "Model weights: [0.20961893 0.21567901 0.19005077 0.19564294 0.18900836]\n",
      "Best threshold: 0.52, Weighted Ensemble Accuracy: 0.8148\n",
      "\n",
      "===== FINAL PREDICTION =====\n",
      "Optimized submission file created: optimized_submission.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ensemble': {'base_models': {'catboost': <catboost.core.CatBoostClassifier at 0x6b9cfbd60>,\n",
       "   'xgboost': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bynode=None,\n",
       "                 colsample_bytree=0.9651850149911293, device=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=True,\n",
       "                 eval_metric=None, feature_types=None, gamma=0.23511026951869188,\n",
       "                 grow_policy=None, importance_type=None,\n",
       "                 interaction_constraints=None, learning_rate=0.028277968827625385,\n",
       "                 max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                 max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "                 min_child_weight=8, missing=nan, monotone_constraints=None,\n",
       "                 multi_strategy=None, n_estimators=794, n_jobs=11,\n",
       "                 num_parallel_tree=None, random_state=42, ...),\n",
       "   'random_forest': RandomForestClassifier(max_depth=30, max_features='log2', min_samples_leaf=14,\n",
       "                          min_samples_split=9, n_estimators=418, n_jobs=11),\n",
       "   'gradient_boosting': GradientBoostingClassifier(learning_rate=0.0541598647584957, max_depth=8,\n",
       "                              min_samples_leaf=7, min_samples_split=13,\n",
       "                              n_estimators=220, random_state=42,\n",
       "                              subsample=0.5453212103135678),\n",
       "   'extra_trees': ExtraTreesClassifier(bootstrap=True, max_depth=22, min_samples_leaf=2,\n",
       "                        min_samples_split=18, n_estimators=188, n_jobs=11)},\n",
       "  'meta_learner': <__main__.create_weighted_ensemble.<locals>.WeightedEnsemble at 0x325d3adc0>,\n",
       "  'model_data_map': {'catboost': (      ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "    1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "    8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "    5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "    4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "    4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "    7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "    426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "    7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  \\\n",
       "    3600        -0.161141      -0.376161            -0.564175   \n",
       "    1262        -0.161141       2.658437            -0.564175   \n",
       "    8612        -0.161141      -0.376161            -0.564175   \n",
       "    5075        -0.161141      -0.376161            -0.564175   \n",
       "    4758        -0.161141       2.658437            -0.564175   \n",
       "    ...               ...            ...                  ...   \n",
       "    4087        -0.161141      -0.376161            -0.564175   \n",
       "    4406        -0.161141      -0.376161            -0.564175   \n",
       "    7111        -0.161141      -0.376161            -0.564175   \n",
       "    426         -0.161141      -0.376161             1.772499   \n",
       "    7925        -0.161141      -0.376161             1.772499   \n",
       "    \n",
       "                  CabinDeck_B           CabinDeck_C          CabinDeck_D  ...  \\\n",
       "    3600  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    1262  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    8612  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    5075  -0.3156271429370956  -0.30278663910847514    4.124990186830846  ...   \n",
       "    4758  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    ...                   ...                   ...                  ...  ...   \n",
       "    4087    3.168295320530464  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    4406  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    7111  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    426   -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    7925  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    \n",
       "         Age_TotalSpend Age_TotalSpendRatio   Age_log  Age_sqrt  \\\n",
       "    3600       1.032894           -4.138413  0.542236  0.848438   \n",
       "    1262       0.419391           -1.680341  0.542236  0.848438   \n",
       "    8612      -0.230200            0.922323  0.366320  0.665144   \n",
       "    5075       0.094596           -0.379009  0.542236  0.848438   \n",
       "    4758      -1.476003           -0.458639  0.542236  0.848438   \n",
       "    ...             ...                 ...       ...       ...   \n",
       "    4087       0.778193            0.560169  0.691785  0.998638   \n",
       "    4406      -0.133888            0.819078  0.501072  0.806529   \n",
       "    7111      -0.313074            1.568173  0.758932  1.065830   \n",
       "    426        0.166773           -0.668194  0.542236  0.848438   \n",
       "    7925       0.146632           -0.731514  0.542236  0.848438   \n",
       "    \n",
       "         GroupSpendDeviation  RoomService_Dominance FoodCourt_Dominance  \\\n",
       "    3600           -0.101809               2.769710            1.560940   \n",
       "    1262            0.000000               2.769710            1.560940   \n",
       "    8612            0.000000               2.769710            1.560940   \n",
       "    5075            0.000000               2.769710            1.560940   \n",
       "    4758            0.000000              -0.073199           -0.061492   \n",
       "    ...                  ...                    ...                 ...   \n",
       "    4087            0.000000              -0.130693            0.722746   \n",
       "    4406            0.000000              -0.150704           -0.290791   \n",
       "    7111            0.000000              -0.639943           -0.593120   \n",
       "    426             0.000000               2.769710            1.560940   \n",
       "    7925            0.000000              -1.036715           -0.922128   \n",
       "    \n",
       "         ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "    3600               1.990724      1.401816         1.357870  \n",
       "    1262               1.990724      1.401816         1.357870  \n",
       "    8612               1.990724      1.401816         1.357870  \n",
       "    5075               1.990724      1.401816         1.357870  \n",
       "    4758              -0.043779     -0.058854       -51.983508  \n",
       "    ...                     ...           ...              ...  \n",
       "    4087              -0.119876     -0.106686         1.185937  \n",
       "    4406              -0.451021     -0.315128         0.236911  \n",
       "    7111              -0.517760     -3.288903        -0.583203  \n",
       "    426                1.990724      1.401816         1.357870  \n",
       "    7925              -1.034761     -1.039838        -1.040397  \n",
       "    \n",
       "    [6954 rows x 79 columns],\n",
       "          ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "    7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "    8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "    6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "    7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "    1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "    5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "    5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "    4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  \\\n",
       "    3586        -0.161141      -0.376161            -0.564175   \n",
       "    7173        -0.161141      -0.376161            -0.564175   \n",
       "    8559        -0.161141      -0.376161             1.772499   \n",
       "    6528        -0.161141      -0.376161            -0.564175   \n",
       "    7934         6.205752      -0.376161            -0.564175   \n",
       "    ...               ...            ...                  ...   \n",
       "    3749        -0.161141      -0.376161            -0.564175   \n",
       "    1637        -0.161141       2.658437            -0.564175   \n",
       "    5820        -0.161141       2.658437            -0.564175   \n",
       "    5757        -0.161141      -0.376161            -0.564175   \n",
       "    4135        -0.161141      -0.376161            -0.564175   \n",
       "    \n",
       "                  CabinDeck_B           CabinDeck_C          CabinDeck_D  ...  \\\n",
       "    3586  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    7173  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    8559  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    6528  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    7934  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    ...                   ...                   ...                  ...  ...   \n",
       "    3749  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    1637  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    5820  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    5757  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    4135  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    \n",
       "         Age_TotalSpend Age_TotalSpendRatio   Age_log  Age_sqrt  \\\n",
       "    3586      -0.194111            0.777730  0.317041  0.610786   \n",
       "    7173       0.888540           -3.560043  0.542236  0.848438   \n",
       "    8559      -0.024116           -0.229157  0.542236  0.848438   \n",
       "    6528       0.599833           -2.403304  0.542236  0.848438   \n",
       "    7934       2.162613            1.413441  1.278849  1.610125   \n",
       "    ...             ...                 ...       ...       ...   \n",
       "    3749      -0.158023            0.633138  0.265208  0.551091   \n",
       "    1637      -0.001576           -0.943163  0.542236  0.848438   \n",
       "    5820       0.527657           -2.114119  0.542236  0.848438   \n",
       "    5757       0.055164           -0.260996  0.542236  0.848438   \n",
       "    4135      -0.140830            0.767007  0.458141  0.762320   \n",
       "    \n",
       "         GroupSpendDeviation  RoomService_Dominance FoodCourt_Dominance  \\\n",
       "    3586            0.000000               2.769710            1.560940   \n",
       "    7173           -0.051555               2.769710            1.560940   \n",
       "    8559            0.000000               0.264382           -0.167200   \n",
       "    6528            0.000000               2.769710            1.560940   \n",
       "    7934            0.000000              -0.124232            0.573468   \n",
       "    ...                  ...                    ...                 ...   \n",
       "    3749            0.000000               2.769710            1.560940   \n",
       "    1637            0.000000             -30.404201           -0.117736   \n",
       "    5820            0.000000               2.769710            1.560940   \n",
       "    5757            0.000000              -0.575032           -0.674018   \n",
       "    4135            0.000000             -31.792846           -0.285593   \n",
       "    \n",
       "         ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "    3586               1.990724      1.401816         1.357870  \n",
       "    7173               1.990724      1.401816         1.357870  \n",
       "    8559              -0.177864      1.744477        -0.164865  \n",
       "    6528               1.990724      1.401816         1.357870  \n",
       "    7934              -0.113273      1.383730        -0.086094  \n",
       "    ...                     ...           ...              ...  \n",
       "    3749               1.990724      1.401816         1.357870  \n",
       "    1637              -0.161268     -0.144270        -0.142626  \n",
       "    5820               1.990724      1.401816         1.357870  \n",
       "    5757              -0.693065     -0.137336        -0.342659  \n",
       "    4135              -0.227834     -0.276827        -0.274156  \n",
       "    \n",
       "    [1739 rows x 79 columns]),\n",
       "   'xgboost': (      ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "    1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "    8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "    5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "    4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "    4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "    7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "    426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "    7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "    3600        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    1262        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "    8612        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    5075        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    4758        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "    ...               ...            ...                  ...         ...   \n",
       "    4087        -0.161141      -0.376161            -0.564175    3.168295   \n",
       "    4406        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    7111        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    426         -0.161141      -0.376161             1.772499   -0.315627   \n",
       "    7925        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "    \n",
       "         CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "    3600   -0.302787   -0.242425  ...       1.032894           -4.138413   \n",
       "    1262   -0.302787   -0.242425  ...       0.419391           -1.680341   \n",
       "    8612   -0.302787   -0.242425  ...      -0.230200            0.922323   \n",
       "    5075   -0.302787    4.124990  ...       0.094596           -0.379009   \n",
       "    4758   -0.302787   -0.242425  ...      -1.476003           -0.458639   \n",
       "    ...          ...         ...  ...            ...                 ...   \n",
       "    4087   -0.302787   -0.242425  ...       0.778193            0.560169   \n",
       "    4406   -0.302787   -0.242425  ...      -0.133888            0.819078   \n",
       "    7111   -0.302787   -0.242425  ...      -0.313074            1.568173   \n",
       "    426    -0.302787   -0.242425  ...       0.166773           -0.668194   \n",
       "    7925   -0.302787   -0.242425  ...       0.146632           -0.731514   \n",
       "    \n",
       "           Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3600  0.542236  0.848438           -0.101809               2.769710   \n",
       "    1262  0.542236  0.848438            0.000000               2.769710   \n",
       "    8612  0.366320  0.665144            0.000000               2.769710   \n",
       "    5075  0.542236  0.848438            0.000000               2.769710   \n",
       "    4758  0.542236  0.848438            0.000000              -0.073199   \n",
       "    ...        ...       ...                 ...                    ...   \n",
       "    4087  0.691785  0.998638            0.000000              -0.130693   \n",
       "    4406  0.501072  0.806529            0.000000              -0.150704   \n",
       "    7111  0.758932  1.065830            0.000000              -0.639943   \n",
       "    426   0.542236  0.848438            0.000000               2.769710   \n",
       "    7925  0.542236  0.848438            0.000000              -1.036715   \n",
       "    \n",
       "         FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "    3600            1.560940               1.990724      1.401816         1.357870  \n",
       "    1262            1.560940               1.990724      1.401816         1.357870  \n",
       "    8612            1.560940               1.990724      1.401816         1.357870  \n",
       "    5075            1.560940               1.990724      1.401816         1.357870  \n",
       "    4758           -0.061492              -0.043779     -0.058854       -51.983508  \n",
       "    ...                  ...                    ...           ...              ...  \n",
       "    4087            0.722746              -0.119876     -0.106686         1.185937  \n",
       "    4406           -0.290791              -0.451021     -0.315128         0.236911  \n",
       "    7111           -0.593120              -0.517760     -3.288903        -0.583203  \n",
       "    426             1.560940               1.990724      1.401816         1.357870  \n",
       "    7925           -0.922128              -1.034761     -1.039838        -1.040397  \n",
       "    \n",
       "    [6954 rows x 79 columns],\n",
       "          ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "    7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "    8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "    6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "    7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "    1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "    5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "    5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "    4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "    3586        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    7173        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    8559        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "    6528        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    7934         6.205752      -0.376161            -0.564175   -0.315627   \n",
       "    ...               ...            ...                  ...         ...   \n",
       "    3749        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    1637        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "    5820        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "    5757        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    4135        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    \n",
       "         CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "    3586   -0.302787   -0.242425  ...      -0.194111            0.777730   \n",
       "    7173   -0.302787   -0.242425  ...       0.888540           -3.560043   \n",
       "    8559   -0.302787   -0.242425  ...      -0.024116           -0.229157   \n",
       "    6528   -0.302787   -0.242425  ...       0.599833           -2.403304   \n",
       "    7934   -0.302787   -0.242425  ...       2.162613            1.413441   \n",
       "    ...          ...         ...  ...            ...                 ...   \n",
       "    3749   -0.302787   -0.242425  ...      -0.158023            0.633138   \n",
       "    1637   -0.302787   -0.242425  ...      -0.001576           -0.943163   \n",
       "    5820   -0.302787   -0.242425  ...       0.527657           -2.114119   \n",
       "    5757   -0.302787   -0.242425  ...       0.055164           -0.260996   \n",
       "    4135   -0.302787   -0.242425  ...      -0.140830            0.767007   \n",
       "    \n",
       "           Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3586  0.317041  0.610786            0.000000               2.769710   \n",
       "    7173  0.542236  0.848438           -0.051555               2.769710   \n",
       "    8559  0.542236  0.848438            0.000000               0.264382   \n",
       "    6528  0.542236  0.848438            0.000000               2.769710   \n",
       "    7934  1.278849  1.610125            0.000000              -0.124232   \n",
       "    ...        ...       ...                 ...                    ...   \n",
       "    3749  0.265208  0.551091            0.000000               2.769710   \n",
       "    1637  0.542236  0.848438            0.000000             -30.404201   \n",
       "    5820  0.542236  0.848438            0.000000               2.769710   \n",
       "    5757  0.542236  0.848438            0.000000              -0.575032   \n",
       "    4135  0.458141  0.762320            0.000000             -31.792846   \n",
       "    \n",
       "         FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "    3586            1.560940               1.990724      1.401816         1.357870  \n",
       "    7173            1.560940               1.990724      1.401816         1.357870  \n",
       "    8559           -0.167200              -0.177864      1.744477        -0.164865  \n",
       "    6528            1.560940               1.990724      1.401816         1.357870  \n",
       "    7934            0.573468              -0.113273      1.383730        -0.086094  \n",
       "    ...                  ...                    ...           ...              ...  \n",
       "    3749            1.560940               1.990724      1.401816         1.357870  \n",
       "    1637           -0.117736              -0.161268     -0.144270        -0.142626  \n",
       "    5820            1.560940               1.990724      1.401816         1.357870  \n",
       "    5757           -0.674018              -0.693065     -0.137336        -0.342659  \n",
       "    4135           -0.285593              -0.227834     -0.276827        -0.274156  \n",
       "    \n",
       "    [1739 rows x 79 columns]),\n",
       "   'random_forest': (      ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "    1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "    8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "    5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "    4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "    4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "    7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "    426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "    7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3600        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1262        -0.161141       2.658437            -0.564175          0.0   \n",
       "    8612        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    5075        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4758        -0.161141       2.658437            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    4087        -0.161141      -0.376161            -0.564175          1.0   \n",
       "    4406        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7111        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    426         -0.161141      -0.376161             1.772499          0.0   \n",
       "    7925        -0.161141      -0.376161             1.772499          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3600          0.0          0.0  ...        1.032894            -4.138413   \n",
       "    1262          0.0          0.0  ...        0.419391            -1.680341   \n",
       "    8612          0.0          0.0  ...       -0.230200             0.922323   \n",
       "    5075          0.0          1.0  ...        0.094596            -0.379009   \n",
       "    4758          0.0          0.0  ...       -1.476003            -0.458639   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    4087          0.0          0.0  ...        0.778193             0.560169   \n",
       "    4406          0.0          0.0  ...       -0.133888             0.819078   \n",
       "    7111          0.0          0.0  ...       -0.313074             1.568173   \n",
       "    426           0.0          0.0  ...        0.166773            -0.668194   \n",
       "    7925          0.0          0.0  ...        0.146632            -0.731514   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3600  0.542236  0.848438            -0.101809               2.769710   \n",
       "    1262  0.542236  0.848438             0.000000               2.769710   \n",
       "    8612  0.366320  0.665144             0.000000               2.769710   \n",
       "    5075  0.542236  0.848438             0.000000               2.769710   \n",
       "    4758  0.542236  0.848438             0.000000              -0.073199   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    4087  0.691785  0.998638             0.000000              -0.130693   \n",
       "    4406  0.501072  0.806529             0.000000              -0.150704   \n",
       "    7111  0.758932  1.065830             0.000000              -0.639943   \n",
       "    426   0.542236  0.848438             0.000000               2.769710   \n",
       "    7925  0.542236  0.848438             0.000000              -1.036715   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3600             1.560940                1.990724       1.401816   \n",
       "    1262             1.560940                1.990724       1.401816   \n",
       "    8612             1.560940                1.990724       1.401816   \n",
       "    5075             1.560940                1.990724       1.401816   \n",
       "    4758            -0.061492               -0.043779      -0.058854   \n",
       "    ...                   ...                     ...            ...   \n",
       "    4087             0.722746               -0.119876      -0.106686   \n",
       "    4406            -0.290791               -0.451021      -0.315128   \n",
       "    7111            -0.593120               -0.517760      -3.288903   \n",
       "    426              1.560940                1.990724       1.401816   \n",
       "    7925            -0.922128               -1.034761      -1.039838   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3600          1.357870  \n",
       "    1262          1.357870  \n",
       "    8612          1.357870  \n",
       "    5075          1.357870  \n",
       "    4758        -51.983508  \n",
       "    ...                ...  \n",
       "    4087          1.185937  \n",
       "    4406          0.236911  \n",
       "    7111         -0.583203  \n",
       "    426           1.357870  \n",
       "    7925         -1.040397  \n",
       "    \n",
       "    [6954 rows x 79 columns],\n",
       "          ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "    7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "    8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "    6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "    7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "    1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "    5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "    5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "    4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3586        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7173        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    8559        -0.161141      -0.376161             1.772499          0.0   \n",
       "    6528        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7934         6.205752      -0.376161            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    3749        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1637        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5820        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5757        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4135        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3586          0.0          0.0  ...       -0.194111             0.777730   \n",
       "    7173          0.0          0.0  ...        0.888540            -3.560043   \n",
       "    8559          0.0          0.0  ...       -0.024116            -0.229157   \n",
       "    6528          0.0          0.0  ...        0.599833            -2.403304   \n",
       "    7934          0.0          0.0  ...        2.162613             1.413441   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    3749          0.0          0.0  ...       -0.158023             0.633138   \n",
       "    1637          0.0          0.0  ...       -0.001576            -0.943163   \n",
       "    5820          0.0          0.0  ...        0.527657            -2.114119   \n",
       "    5757          0.0          0.0  ...        0.055164            -0.260996   \n",
       "    4135          0.0          0.0  ...       -0.140830             0.767007   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3586  0.317041  0.610786             0.000000               2.769710   \n",
       "    7173  0.542236  0.848438            -0.051555               2.769710   \n",
       "    8559  0.542236  0.848438             0.000000               0.264382   \n",
       "    6528  0.542236  0.848438             0.000000               2.769710   \n",
       "    7934  1.278849  1.610125             0.000000              -0.124232   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    3749  0.265208  0.551091             0.000000               2.769710   \n",
       "    1637  0.542236  0.848438             0.000000             -30.404201   \n",
       "    5820  0.542236  0.848438             0.000000               2.769710   \n",
       "    5757  0.542236  0.848438             0.000000              -0.575032   \n",
       "    4135  0.458141  0.762320             0.000000             -31.792846   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3586             1.560940                1.990724       1.401816   \n",
       "    7173             1.560940                1.990724       1.401816   \n",
       "    8559            -0.167200               -0.177864       1.744477   \n",
       "    6528             1.560940                1.990724       1.401816   \n",
       "    7934             0.573468               -0.113273       1.383730   \n",
       "    ...                   ...                     ...            ...   \n",
       "    3749             1.560940                1.990724       1.401816   \n",
       "    1637            -0.117736               -0.161268      -0.144270   \n",
       "    5820             1.560940                1.990724       1.401816   \n",
       "    5757            -0.674018               -0.693065      -0.137336   \n",
       "    4135            -0.285593               -0.227834      -0.276827   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3586          1.357870  \n",
       "    7173          1.357870  \n",
       "    8559         -0.164865  \n",
       "    6528          1.357870  \n",
       "    7934         -0.086094  \n",
       "    ...                ...  \n",
       "    3749          1.357870  \n",
       "    1637         -0.142626  \n",
       "    5820          1.357870  \n",
       "    5757         -0.342659  \n",
       "    4135         -0.274156  \n",
       "    \n",
       "    [1739 rows x 79 columns]),\n",
       "   'gradient_boosting': (      ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "    1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "    8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "    5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "    4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "    4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "    7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "    426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "    7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3600        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1262        -0.161141       2.658437            -0.564175          0.0   \n",
       "    8612        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    5075        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4758        -0.161141       2.658437            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    4087        -0.161141      -0.376161            -0.564175          1.0   \n",
       "    4406        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7111        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    426         -0.161141      -0.376161             1.772499          0.0   \n",
       "    7925        -0.161141      -0.376161             1.772499          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3600          0.0          0.0  ...        1.032894            -4.138413   \n",
       "    1262          0.0          0.0  ...        0.419391            -1.680341   \n",
       "    8612          0.0          0.0  ...       -0.230200             0.922323   \n",
       "    5075          0.0          1.0  ...        0.094596            -0.379009   \n",
       "    4758          0.0          0.0  ...       -1.476003            -0.458639   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    4087          0.0          0.0  ...        0.778193             0.560169   \n",
       "    4406          0.0          0.0  ...       -0.133888             0.819078   \n",
       "    7111          0.0          0.0  ...       -0.313074             1.568173   \n",
       "    426           0.0          0.0  ...        0.166773            -0.668194   \n",
       "    7925          0.0          0.0  ...        0.146632            -0.731514   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3600  0.542236  0.848438            -0.101809               2.769710   \n",
       "    1262  0.542236  0.848438             0.000000               2.769710   \n",
       "    8612  0.366320  0.665144             0.000000               2.769710   \n",
       "    5075  0.542236  0.848438             0.000000               2.769710   \n",
       "    4758  0.542236  0.848438             0.000000              -0.073199   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    4087  0.691785  0.998638             0.000000              -0.130693   \n",
       "    4406  0.501072  0.806529             0.000000              -0.150704   \n",
       "    7111  0.758932  1.065830             0.000000              -0.639943   \n",
       "    426   0.542236  0.848438             0.000000               2.769710   \n",
       "    7925  0.542236  0.848438             0.000000              -1.036715   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3600             1.560940                1.990724       1.401816   \n",
       "    1262             1.560940                1.990724       1.401816   \n",
       "    8612             1.560940                1.990724       1.401816   \n",
       "    5075             1.560940                1.990724       1.401816   \n",
       "    4758            -0.061492               -0.043779      -0.058854   \n",
       "    ...                   ...                     ...            ...   \n",
       "    4087             0.722746               -0.119876      -0.106686   \n",
       "    4406            -0.290791               -0.451021      -0.315128   \n",
       "    7111            -0.593120               -0.517760      -3.288903   \n",
       "    426              1.560940                1.990724       1.401816   \n",
       "    7925            -0.922128               -1.034761      -1.039838   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3600          1.357870  \n",
       "    1262          1.357870  \n",
       "    8612          1.357870  \n",
       "    5075          1.357870  \n",
       "    4758        -51.983508  \n",
       "    ...                ...  \n",
       "    4087          1.185937  \n",
       "    4406          0.236911  \n",
       "    7111         -0.583203  \n",
       "    426           1.357870  \n",
       "    7925         -1.040397  \n",
       "    \n",
       "    [6954 rows x 79 columns],\n",
       "          ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "    7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "    8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "    6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "    7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "    1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "    5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "    5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "    4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3586        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7173        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    8559        -0.161141      -0.376161             1.772499          0.0   \n",
       "    6528        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7934         6.205752      -0.376161            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    3749        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1637        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5820        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5757        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4135        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3586          0.0          0.0  ...       -0.194111             0.777730   \n",
       "    7173          0.0          0.0  ...        0.888540            -3.560043   \n",
       "    8559          0.0          0.0  ...       -0.024116            -0.229157   \n",
       "    6528          0.0          0.0  ...        0.599833            -2.403304   \n",
       "    7934          0.0          0.0  ...        2.162613             1.413441   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    3749          0.0          0.0  ...       -0.158023             0.633138   \n",
       "    1637          0.0          0.0  ...       -0.001576            -0.943163   \n",
       "    5820          0.0          0.0  ...        0.527657            -2.114119   \n",
       "    5757          0.0          0.0  ...        0.055164            -0.260996   \n",
       "    4135          0.0          0.0  ...       -0.140830             0.767007   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3586  0.317041  0.610786             0.000000               2.769710   \n",
       "    7173  0.542236  0.848438            -0.051555               2.769710   \n",
       "    8559  0.542236  0.848438             0.000000               0.264382   \n",
       "    6528  0.542236  0.848438             0.000000               2.769710   \n",
       "    7934  1.278849  1.610125             0.000000              -0.124232   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    3749  0.265208  0.551091             0.000000               2.769710   \n",
       "    1637  0.542236  0.848438             0.000000             -30.404201   \n",
       "    5820  0.542236  0.848438             0.000000               2.769710   \n",
       "    5757  0.542236  0.848438             0.000000              -0.575032   \n",
       "    4135  0.458141  0.762320             0.000000             -31.792846   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3586             1.560940                1.990724       1.401816   \n",
       "    7173             1.560940                1.990724       1.401816   \n",
       "    8559            -0.167200               -0.177864       1.744477   \n",
       "    6528             1.560940                1.990724       1.401816   \n",
       "    7934             0.573468               -0.113273       1.383730   \n",
       "    ...                   ...                     ...            ...   \n",
       "    3749             1.560940                1.990724       1.401816   \n",
       "    1637            -0.117736               -0.161268      -0.144270   \n",
       "    5820             1.560940                1.990724       1.401816   \n",
       "    5757            -0.674018               -0.693065      -0.137336   \n",
       "    4135            -0.285593               -0.227834      -0.276827   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3586          1.357870  \n",
       "    7173          1.357870  \n",
       "    8559         -0.164865  \n",
       "    6528          1.357870  \n",
       "    7934         -0.086094  \n",
       "    ...                ...  \n",
       "    3749          1.357870  \n",
       "    1637         -0.142626  \n",
       "    5820          1.357870  \n",
       "    5757         -0.342659  \n",
       "    4135         -0.274156  \n",
       "    \n",
       "    [1739 rows x 79 columns]),\n",
       "   'extra_trees': (      ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "    1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "    8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "    5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "    4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "    4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "    7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "    426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "    7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3600        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1262        -0.161141       2.658437            -0.564175          0.0   \n",
       "    8612        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    5075        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4758        -0.161141       2.658437            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    4087        -0.161141      -0.376161            -0.564175          1.0   \n",
       "    4406        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7111        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    426         -0.161141      -0.376161             1.772499          0.0   \n",
       "    7925        -0.161141      -0.376161             1.772499          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3600          0.0          0.0  ...        1.032894            -4.138413   \n",
       "    1262          0.0          0.0  ...        0.419391            -1.680341   \n",
       "    8612          0.0          0.0  ...       -0.230200             0.922323   \n",
       "    5075          0.0          1.0  ...        0.094596            -0.379009   \n",
       "    4758          0.0          0.0  ...       -1.476003            -0.458639   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    4087          0.0          0.0  ...        0.778193             0.560169   \n",
       "    4406          0.0          0.0  ...       -0.133888             0.819078   \n",
       "    7111          0.0          0.0  ...       -0.313074             1.568173   \n",
       "    426           0.0          0.0  ...        0.166773            -0.668194   \n",
       "    7925          0.0          0.0  ...        0.146632            -0.731514   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3600  0.542236  0.848438            -0.101809               2.769710   \n",
       "    1262  0.542236  0.848438             0.000000               2.769710   \n",
       "    8612  0.366320  0.665144             0.000000               2.769710   \n",
       "    5075  0.542236  0.848438             0.000000               2.769710   \n",
       "    4758  0.542236  0.848438             0.000000              -0.073199   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    4087  0.691785  0.998638             0.000000              -0.130693   \n",
       "    4406  0.501072  0.806529             0.000000              -0.150704   \n",
       "    7111  0.758932  1.065830             0.000000              -0.639943   \n",
       "    426   0.542236  0.848438             0.000000               2.769710   \n",
       "    7925  0.542236  0.848438             0.000000              -1.036715   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3600             1.560940                1.990724       1.401816   \n",
       "    1262             1.560940                1.990724       1.401816   \n",
       "    8612             1.560940                1.990724       1.401816   \n",
       "    5075             1.560940                1.990724       1.401816   \n",
       "    4758            -0.061492               -0.043779      -0.058854   \n",
       "    ...                   ...                     ...            ...   \n",
       "    4087             0.722746               -0.119876      -0.106686   \n",
       "    4406            -0.290791               -0.451021      -0.315128   \n",
       "    7111            -0.593120               -0.517760      -3.288903   \n",
       "    426              1.560940                1.990724       1.401816   \n",
       "    7925            -0.922128               -1.034761      -1.039838   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3600          1.357870  \n",
       "    1262          1.357870  \n",
       "    8612          1.357870  \n",
       "    5075          1.357870  \n",
       "    4758        -51.983508  \n",
       "    ...                ...  \n",
       "    4087          1.185937  \n",
       "    4406          0.236911  \n",
       "    7111         -0.583203  \n",
       "    426           1.357870  \n",
       "    7925         -1.040397  \n",
       "    \n",
       "    [6954 rows x 79 columns],\n",
       "          ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "    7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "    8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "    6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "    7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "    1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "    5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "    5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "    4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3586        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7173        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    8559        -0.161141      -0.376161             1.772499          0.0   \n",
       "    6528        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7934         6.205752      -0.376161            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    3749        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1637        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5820        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5757        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4135        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3586          0.0          0.0  ...       -0.194111             0.777730   \n",
       "    7173          0.0          0.0  ...        0.888540            -3.560043   \n",
       "    8559          0.0          0.0  ...       -0.024116            -0.229157   \n",
       "    6528          0.0          0.0  ...        0.599833            -2.403304   \n",
       "    7934          0.0          0.0  ...        2.162613             1.413441   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    3749          0.0          0.0  ...       -0.158023             0.633138   \n",
       "    1637          0.0          0.0  ...       -0.001576            -0.943163   \n",
       "    5820          0.0          0.0  ...        0.527657            -2.114119   \n",
       "    5757          0.0          0.0  ...        0.055164            -0.260996   \n",
       "    4135          0.0          0.0  ...       -0.140830             0.767007   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3586  0.317041  0.610786             0.000000               2.769710   \n",
       "    7173  0.542236  0.848438            -0.051555               2.769710   \n",
       "    8559  0.542236  0.848438             0.000000               0.264382   \n",
       "    6528  0.542236  0.848438             0.000000               2.769710   \n",
       "    7934  1.278849  1.610125             0.000000              -0.124232   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    3749  0.265208  0.551091             0.000000               2.769710   \n",
       "    1637  0.542236  0.848438             0.000000             -30.404201   \n",
       "    5820  0.542236  0.848438             0.000000               2.769710   \n",
       "    5757  0.542236  0.848438             0.000000              -0.575032   \n",
       "    4135  0.458141  0.762320             0.000000             -31.792846   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3586             1.560940                1.990724       1.401816   \n",
       "    7173             1.560940                1.990724       1.401816   \n",
       "    8559            -0.167200               -0.177864       1.744477   \n",
       "    6528             1.560940                1.990724       1.401816   \n",
       "    7934             0.573468               -0.113273       1.383730   \n",
       "    ...                   ...                     ...            ...   \n",
       "    3749             1.560940                1.990724       1.401816   \n",
       "    1637            -0.117736               -0.161268      -0.144270   \n",
       "    5820             1.560940                1.990724       1.401816   \n",
       "    5757            -0.674018               -0.693065      -0.137336   \n",
       "    4135            -0.285593               -0.227834      -0.276827   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3586          1.357870  \n",
       "    7173          1.357870  \n",
       "    8559         -0.164865  \n",
       "    6528          1.357870  \n",
       "    7934         -0.086094  \n",
       "    ...                ...  \n",
       "    3749          1.357870  \n",
       "    1637         -0.142626  \n",
       "    5820          1.357870  \n",
       "    5757         -0.342659  \n",
       "    4135         -0.274156  \n",
       "    \n",
       "    [1739 rows x 79 columns])}},\n",
       " 'submission':      PassengerId  Transported\n",
       " 0        0013_01         True\n",
       " 1        0018_01        False\n",
       " 2        0019_01         True\n",
       " 3        0021_01         True\n",
       " 4        0023_01        False\n",
       " ...          ...          ...\n",
       " 4272     9266_02         True\n",
       " 4273     9269_01        False\n",
       " 4274     9271_01         True\n",
       " 4275     9273_01         True\n",
       " 4276     9277_01         True\n",
       " \n",
       " [4277 rows x 2 columns],\n",
       " 'data_dict': {'X_train':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "  1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "  8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "  5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "  4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "  4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "  7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "  426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "  7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  3600        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1262        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  8612        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  5075        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4758        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  4087        -0.161141      -0.376161            -0.564175    3.168295   \n",
       "  4406        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7111        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  426         -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  7925        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  3600   -0.302787   -0.242425  ...       1.032894           -4.138413   \n",
       "  1262   -0.302787   -0.242425  ...       0.419391           -1.680341   \n",
       "  8612   -0.302787   -0.242425  ...      -0.230200            0.922323   \n",
       "  5075   -0.302787     4.12499  ...       0.094596           -0.379009   \n",
       "  4758   -0.302787   -0.242425  ...      -1.476003           -0.458639   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  4087   -0.302787   -0.242425  ...       0.778193            0.560169   \n",
       "  4406   -0.302787   -0.242425  ...      -0.133888            0.819078   \n",
       "  7111   -0.302787   -0.242425  ...      -0.313074            1.568173   \n",
       "  426    -0.302787   -0.242425  ...       0.166773           -0.668194   \n",
       "  7925   -0.302787   -0.242425  ...       0.146632           -0.731514   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3600  0.542236  0.848438           -0.101809               2.769710   \n",
       "  1262  0.542236  0.848438            0.000000               2.769710   \n",
       "  8612  0.366320  0.665144            0.000000               2.769710   \n",
       "  5075  0.542236  0.848438            0.000000               2.769710   \n",
       "  4758  0.542236  0.848438            0.000000              -0.073199   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  4087  0.691785  0.998638            0.000000              -0.130693   \n",
       "  4406  0.501072  0.806529            0.000000              -0.150704   \n",
       "  7111  0.758932  1.065830            0.000000              -0.639943   \n",
       "  426   0.542236  0.848438            0.000000               2.769710   \n",
       "  7925  0.542236  0.848438            0.000000              -1.036715   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3600            1.560940               1.990724      1.401816         1.357870  \n",
       "  1262            1.560940               1.990724      1.401816         1.357870  \n",
       "  8612            1.560940               1.990724      1.401816         1.357870  \n",
       "  5075            1.560940               1.990724      1.401816         1.357870  \n",
       "  4758           -0.061492              -0.043779     -0.058854       -51.983508  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  4087            0.722746              -0.119876     -0.106686         1.185937  \n",
       "  4406           -0.290791              -0.451021     -0.315128         0.236911  \n",
       "  7111           -0.593120              -0.517760     -3.288903        -0.583203  \n",
       "  426             1.560940               1.990724      1.401816         1.357870  \n",
       "  7925           -0.922128              -1.034761     -1.039838        -1.040397  \n",
       "  \n",
       "  [6954 rows x 79 columns],\n",
       "  'X_val':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "  8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "  6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "  7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "  1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "  5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "  5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "  4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  3586        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7173        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  8559        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  6528        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7934         6.205752      -0.376161            -0.564175   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  3749        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1637        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  5820        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  5757        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4135        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  3586   -0.302787   -0.242425  ...      -0.194111            0.777730   \n",
       "  7173   -0.302787   -0.242425  ...       0.888540           -3.560043   \n",
       "  8559   -0.302787   -0.242425  ...      -0.024116           -0.229157   \n",
       "  6528   -0.302787   -0.242425  ...       0.599833           -2.403304   \n",
       "  7934   -0.302787   -0.242425  ...       2.162613            1.413441   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  3749   -0.302787   -0.242425  ...      -0.158023            0.633138   \n",
       "  1637   -0.302787   -0.242425  ...      -0.001576           -0.943163   \n",
       "  5820   -0.302787   -0.242425  ...       0.527657           -2.114119   \n",
       "  5757   -0.302787   -0.242425  ...       0.055164           -0.260996   \n",
       "  4135   -0.302787   -0.242425  ...      -0.140830            0.767007   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3586  0.317041  0.610786            0.000000               2.769710   \n",
       "  7173  0.542236  0.848438           -0.051555               2.769710   \n",
       "  8559  0.542236  0.848438            0.000000               0.264382   \n",
       "  6528  0.542236  0.848438            0.000000               2.769710   \n",
       "  7934  1.278849  1.610125            0.000000              -0.124232   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  3749  0.265208  0.551091            0.000000               2.769710   \n",
       "  1637  0.542236  0.848438            0.000000             -30.404201   \n",
       "  5820  0.542236  0.848438            0.000000               2.769710   \n",
       "  5757  0.542236  0.848438            0.000000              -0.575032   \n",
       "  4135  0.458141  0.762320            0.000000             -31.792846   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3586            1.560940               1.990724      1.401816         1.357870  \n",
       "  7173            1.560940               1.990724      1.401816         1.357870  \n",
       "  8559           -0.167200              -0.177864      1.744477        -0.164865  \n",
       "  6528            1.560940               1.990724      1.401816         1.357870  \n",
       "  7934            0.573468              -0.113273      1.383730        -0.086094  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  3749            1.560940               1.990724      1.401816         1.357870  \n",
       "  1637           -0.117736              -0.161268     -0.144270        -0.142626  \n",
       "  5820            1.560940               1.990724      1.401816         1.357870  \n",
       "  5757           -0.674018              -0.693065     -0.137336        -0.342659  \n",
       "  4135           -0.285593              -0.227834     -0.276827        -0.274156  \n",
       "  \n",
       "  [1739 rows x 79 columns],\n",
       "  'X_test':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  0         -1.165370 -0.112444        1.398797           -0.458742   \n",
       "  1          0.858096 -0.667306       -0.714900           -0.458742   \n",
       "  2         -1.165370  0.164986        1.398797           -0.458742   \n",
       "  3          0.858096  0.650490        1.398797           -0.458742   \n",
       "  4          0.858096 -0.597948       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4272      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  4273       0.858096  0.927920       -0.714900            2.179876   \n",
       "  4274      -1.165370 -0.043087        1.398797           -0.458742   \n",
       "  4275       0.858096  0.234344        1.398797           -0.458742   \n",
       "  4276      -1.165370  0.997278       -0.714900            2.179876   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  0           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1           -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  2           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  3           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4           -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  4272        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4273        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4274        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4275        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4276        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  0      -0.302787   -0.242425  ...       0.058507           -0.234417   \n",
       "  1      -0.302787   -0.242425  ...      -0.335932           -0.443860   \n",
       "  2       3.302656   -0.242425  ...      -0.085846            0.343953   \n",
       "  3       3.302656   -0.242425  ...       1.405844            0.205772   \n",
       "  4      -0.302787   -0.242425  ...       0.171708           -0.838827   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  4272   -0.302787   -0.242425  ...      -0.194111            0.777730   \n",
       "  4273   -0.302787   -0.242425  ...      -0.141347            1.094667   \n",
       "  4274   -0.302787     4.12499  ...       0.022419           -0.089824   \n",
       "  4275   -0.302787     4.12499  ...       0.149401            0.143108   \n",
       "  4276   -0.302787   -0.242425  ...      -0.518907            2.079062   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  0     0.542236  0.848438            0.000000               2.769710   \n",
       "  1     0.542236  0.848438            0.000000              -0.142436   \n",
       "  2     0.152709  0.406185            0.000000               2.769710   \n",
       "  3     0.501072  0.806529            0.000000              -0.071246   \n",
       "  4     0.542236  0.848438            0.000000              -0.309187   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  4272  0.317041  0.610786           -0.128399               2.769710   \n",
       "  4273  0.656442  0.963286            0.000000              -0.582939   \n",
       "  4274  0.542236  0.848438            0.000000               2.769710   \n",
       "  4275  0.210540  0.484091            0.000000              -0.166296   \n",
       "  4276  0.691785  0.998638            0.000000               2.769710   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  0               1.560940               1.990724      1.401816         1.357870  \n",
       "  1              -0.118950              -0.130793    -11.947877        -0.115190  \n",
       "  2               1.560940               1.990724      1.401816         1.357870  \n",
       "  3               7.707147              -0.064982     -0.024117         0.062999  \n",
       "  4              -0.279729              -6.195552     -0.271075        -0.268438  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  4272            1.560940               1.990724      1.401816         1.357870  \n",
       "  4273          -24.993834              -0.532069     -0.517806        -0.359005  \n",
       "  4274            1.560940               1.990724      1.401816         1.357870  \n",
       "  4275            4.829713              -0.153051     -0.136778         0.137916  \n",
       "  4276            1.560940               1.990724      1.401816         1.357870  \n",
       "  \n",
       "  [4277 rows x 79 columns],\n",
       "  'y_train': 3600    1\n",
       "  1262    1\n",
       "  8612    0\n",
       "  5075    1\n",
       "  4758    0\n",
       "         ..\n",
       "  4087    1\n",
       "  4406    0\n",
       "  7111    1\n",
       "  426     1\n",
       "  7925    1\n",
       "  Name: Transported, Length: 6954, dtype: int64,\n",
       "  'y_val': 3586    1\n",
       "  7173    0\n",
       "  8559    0\n",
       "  6528    1\n",
       "  7934    0\n",
       "         ..\n",
       "  3749    1\n",
       "  1637    0\n",
       "  5820    1\n",
       "  5757    0\n",
       "  4135    1\n",
       "  Name: Transported, Length: 1739, dtype: int64,\n",
       "  'train_ids': 0       0001_01\n",
       "  1       0002_01\n",
       "  2       0003_01\n",
       "  3       0003_02\n",
       "  4       0004_01\n",
       "           ...   \n",
       "  8688    9276_01\n",
       "  8689    9278_01\n",
       "  8690    9279_01\n",
       "  8691    9280_01\n",
       "  8692    9280_02\n",
       "  Name: PassengerId, Length: 8693, dtype: object,\n",
       "  'test_ids': 0       0013_01\n",
       "  1       0018_01\n",
       "  2       0019_01\n",
       "  3       0021_01\n",
       "  4       0023_01\n",
       "           ...   \n",
       "  4272    9266_02\n",
       "  4273    9269_01\n",
       "  4274    9271_01\n",
       "  4275    9273_01\n",
       "  4276    9277_01\n",
       "  Name: PassengerId, Length: 4277, dtype: object,\n",
       "  'preserved_categorical_cols': ['cat_HomePlanet',\n",
       "   'cat_Destination',\n",
       "   'cat_CabinDeck',\n",
       "   'cat_CabinSide',\n",
       "   'cat_AgeGroup',\n",
       "   'cat_Route'],\n",
       "  'X_train_catboost':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "  1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "  8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "  5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "  4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "  4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "  7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "  426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "  7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  \\\n",
       "  3600        -0.161141      -0.376161            -0.564175   \n",
       "  1262        -0.161141       2.658437            -0.564175   \n",
       "  8612        -0.161141      -0.376161            -0.564175   \n",
       "  5075        -0.161141      -0.376161            -0.564175   \n",
       "  4758        -0.161141       2.658437            -0.564175   \n",
       "  ...               ...            ...                  ...   \n",
       "  4087        -0.161141      -0.376161            -0.564175   \n",
       "  4406        -0.161141      -0.376161            -0.564175   \n",
       "  7111        -0.161141      -0.376161            -0.564175   \n",
       "  426         -0.161141      -0.376161             1.772499   \n",
       "  7925        -0.161141      -0.376161             1.772499   \n",
       "  \n",
       "                CabinDeck_B           CabinDeck_C          CabinDeck_D  ...  \\\n",
       "  3600  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  1262  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  8612  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  5075  -0.3156271429370956  -0.30278663910847514    4.124990186830846  ...   \n",
       "  4758  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  ...                   ...                   ...                  ...  ...   \n",
       "  4087    3.168295320530464  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  4406  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  7111  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  426   -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  7925  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  \n",
       "       Age_TotalSpend Age_TotalSpendRatio   Age_log  Age_sqrt  \\\n",
       "  3600       1.032894           -4.138413  0.542236  0.848438   \n",
       "  1262       0.419391           -1.680341  0.542236  0.848438   \n",
       "  8612      -0.230200            0.922323  0.366320  0.665144   \n",
       "  5075       0.094596           -0.379009  0.542236  0.848438   \n",
       "  4758      -1.476003           -0.458639  0.542236  0.848438   \n",
       "  ...             ...                 ...       ...       ...   \n",
       "  4087       0.778193            0.560169  0.691785  0.998638   \n",
       "  4406      -0.133888            0.819078  0.501072  0.806529   \n",
       "  7111      -0.313074            1.568173  0.758932  1.065830   \n",
       "  426        0.166773           -0.668194  0.542236  0.848438   \n",
       "  7925       0.146632           -0.731514  0.542236  0.848438   \n",
       "  \n",
       "       GroupSpendDeviation  RoomService_Dominance FoodCourt_Dominance  \\\n",
       "  3600           -0.101809               2.769710            1.560940   \n",
       "  1262            0.000000               2.769710            1.560940   \n",
       "  8612            0.000000               2.769710            1.560940   \n",
       "  5075            0.000000               2.769710            1.560940   \n",
       "  4758            0.000000              -0.073199           -0.061492   \n",
       "  ...                  ...                    ...                 ...   \n",
       "  4087            0.000000              -0.130693            0.722746   \n",
       "  4406            0.000000              -0.150704           -0.290791   \n",
       "  7111            0.000000              -0.639943           -0.593120   \n",
       "  426             0.000000               2.769710            1.560940   \n",
       "  7925            0.000000              -1.036715           -0.922128   \n",
       "  \n",
       "       ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3600               1.990724      1.401816         1.357870  \n",
       "  1262               1.990724      1.401816         1.357870  \n",
       "  8612               1.990724      1.401816         1.357870  \n",
       "  5075               1.990724      1.401816         1.357870  \n",
       "  4758              -0.043779     -0.058854       -51.983508  \n",
       "  ...                     ...           ...              ...  \n",
       "  4087              -0.119876     -0.106686         1.185937  \n",
       "  4406              -0.451021     -0.315128         0.236911  \n",
       "  7111              -0.517760     -3.288903        -0.583203  \n",
       "  426                1.990724      1.401816         1.357870  \n",
       "  7925              -1.034761     -1.039838        -1.040397  \n",
       "  \n",
       "  [6954 rows x 79 columns],\n",
       "  'X_val_catboost':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "  8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "  6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "  7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "  1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "  5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "  5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "  4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  \\\n",
       "  3586        -0.161141      -0.376161            -0.564175   \n",
       "  7173        -0.161141      -0.376161            -0.564175   \n",
       "  8559        -0.161141      -0.376161             1.772499   \n",
       "  6528        -0.161141      -0.376161            -0.564175   \n",
       "  7934         6.205752      -0.376161            -0.564175   \n",
       "  ...               ...            ...                  ...   \n",
       "  3749        -0.161141      -0.376161            -0.564175   \n",
       "  1637        -0.161141       2.658437            -0.564175   \n",
       "  5820        -0.161141       2.658437            -0.564175   \n",
       "  5757        -0.161141      -0.376161            -0.564175   \n",
       "  4135        -0.161141      -0.376161            -0.564175   \n",
       "  \n",
       "                CabinDeck_B           CabinDeck_C          CabinDeck_D  ...  \\\n",
       "  3586  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  7173  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  8559  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  6528  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  7934  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  ...                   ...                   ...                  ...  ...   \n",
       "  3749  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  1637  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  5820  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  5757  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  4135  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  \n",
       "       Age_TotalSpend Age_TotalSpendRatio   Age_log  Age_sqrt  \\\n",
       "  3586      -0.194111            0.777730  0.317041  0.610786   \n",
       "  7173       0.888540           -3.560043  0.542236  0.848438   \n",
       "  8559      -0.024116           -0.229157  0.542236  0.848438   \n",
       "  6528       0.599833           -2.403304  0.542236  0.848438   \n",
       "  7934       2.162613            1.413441  1.278849  1.610125   \n",
       "  ...             ...                 ...       ...       ...   \n",
       "  3749      -0.158023            0.633138  0.265208  0.551091   \n",
       "  1637      -0.001576           -0.943163  0.542236  0.848438   \n",
       "  5820       0.527657           -2.114119  0.542236  0.848438   \n",
       "  5757       0.055164           -0.260996  0.542236  0.848438   \n",
       "  4135      -0.140830            0.767007  0.458141  0.762320   \n",
       "  \n",
       "       GroupSpendDeviation  RoomService_Dominance FoodCourt_Dominance  \\\n",
       "  3586            0.000000               2.769710            1.560940   \n",
       "  7173           -0.051555               2.769710            1.560940   \n",
       "  8559            0.000000               0.264382           -0.167200   \n",
       "  6528            0.000000               2.769710            1.560940   \n",
       "  7934            0.000000              -0.124232            0.573468   \n",
       "  ...                  ...                    ...                 ...   \n",
       "  3749            0.000000               2.769710            1.560940   \n",
       "  1637            0.000000             -30.404201           -0.117736   \n",
       "  5820            0.000000               2.769710            1.560940   \n",
       "  5757            0.000000              -0.575032           -0.674018   \n",
       "  4135            0.000000             -31.792846           -0.285593   \n",
       "  \n",
       "       ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3586               1.990724      1.401816         1.357870  \n",
       "  7173               1.990724      1.401816         1.357870  \n",
       "  8559              -0.177864      1.744477        -0.164865  \n",
       "  6528               1.990724      1.401816         1.357870  \n",
       "  7934              -0.113273      1.383730        -0.086094  \n",
       "  ...                     ...           ...              ...  \n",
       "  3749               1.990724      1.401816         1.357870  \n",
       "  1637              -0.161268     -0.144270        -0.142626  \n",
       "  5820               1.990724      1.401816         1.357870  \n",
       "  5757              -0.693065     -0.137336        -0.342659  \n",
       "  4135              -0.227834     -0.276827        -0.274156  \n",
       "  \n",
       "  [1739 rows x 79 columns],\n",
       "  'X_test_catboost':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  0         -1.165370 -0.112444        1.398797           -0.458742   \n",
       "  1          0.858096 -0.667306       -0.714900           -0.458742   \n",
       "  2         -1.165370  0.164986        1.398797           -0.458742   \n",
       "  3          0.858096  0.650490        1.398797           -0.458742   \n",
       "  4          0.858096 -0.597948       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4272      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  4273       0.858096  0.927920       -0.714900            2.179876   \n",
       "  4274      -1.165370 -0.043087        1.398797           -0.458742   \n",
       "  4275       0.858096  0.234344        1.398797           -0.458742   \n",
       "  4276      -1.165370  0.997278       -0.714900            2.179876   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  \\\n",
       "  0           -0.161141      -0.376161            -0.564175   \n",
       "  1           -0.161141      -0.376161             1.772499   \n",
       "  2           -0.161141      -0.376161            -0.564175   \n",
       "  3           -0.161141      -0.376161            -0.564175   \n",
       "  4           -0.161141      -0.376161             1.772499   \n",
       "  ...               ...            ...                  ...   \n",
       "  4272        -0.161141      -0.376161            -0.564175   \n",
       "  4273        -0.161141      -0.376161            -0.564175   \n",
       "  4274        -0.161141      -0.376161            -0.564175   \n",
       "  4275        -0.161141      -0.376161            -0.564175   \n",
       "  4276        -0.161141      -0.376161            -0.564175   \n",
       "  \n",
       "                CabinDeck_B           CabinDeck_C          CabinDeck_D  ...  \\\n",
       "  0     -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  1     -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  2     -0.3156271429370956    3.3026556354811416  -0.2424248191407897  ...   \n",
       "  3     -0.3156271429370956    3.3026556354811416  -0.2424248191407897  ...   \n",
       "  4     -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  ...                   ...                   ...                  ...  ...   \n",
       "  4272  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  4273  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  4274  -0.3156271429370956  -0.30278663910847514    4.124990186830846  ...   \n",
       "  4275  -0.3156271429370956  -0.30278663910847514    4.124990186830846  ...   \n",
       "  4276  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  \n",
       "       Age_TotalSpend Age_TotalSpendRatio   Age_log  Age_sqrt  \\\n",
       "  0          0.058507           -0.234417  0.542236  0.848438   \n",
       "  1         -0.335932           -0.443860  0.542236  0.848438   \n",
       "  2         -0.085846            0.343953  0.152709  0.406185   \n",
       "  3          1.405844            0.205772  0.501072  0.806529   \n",
       "  4          0.171708           -0.838827  0.542236  0.848438   \n",
       "  ...             ...                 ...       ...       ...   \n",
       "  4272      -0.194111            0.777730  0.317041  0.610786   \n",
       "  4273      -0.141347            1.094667  0.656442  0.963286   \n",
       "  4274       0.022419           -0.089824  0.542236  0.848438   \n",
       "  4275       0.149401            0.143108  0.210540  0.484091   \n",
       "  4276      -0.518907            2.079062  0.691785  0.998638   \n",
       "  \n",
       "       GroupSpendDeviation  RoomService_Dominance FoodCourt_Dominance  \\\n",
       "  0               0.000000               2.769710            1.560940   \n",
       "  1               0.000000              -0.142436           -0.118950   \n",
       "  2               0.000000               2.769710            1.560940   \n",
       "  3               0.000000              -0.071246            7.707147   \n",
       "  4               0.000000              -0.309187           -0.279729   \n",
       "  ...                  ...                    ...                 ...   \n",
       "  4272           -0.128399               2.769710            1.560940   \n",
       "  4273            0.000000              -0.582939          -24.993834   \n",
       "  4274            0.000000               2.769710            1.560940   \n",
       "  4275            0.000000              -0.166296            4.829713   \n",
       "  4276            0.000000               2.769710            1.560940   \n",
       "  \n",
       "       ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  0                  1.990724      1.401816         1.357870  \n",
       "  1                 -0.130793    -11.947877        -0.115190  \n",
       "  2                  1.990724      1.401816         1.357870  \n",
       "  3                 -0.064982     -0.024117         0.062999  \n",
       "  4                 -6.195552     -0.271075        -0.268438  \n",
       "  ...                     ...           ...              ...  \n",
       "  4272               1.990724      1.401816         1.357870  \n",
       "  4273              -0.532069     -0.517806        -0.359005  \n",
       "  4274               1.990724      1.401816         1.357870  \n",
       "  4275              -0.153051     -0.136778         0.137916  \n",
       "  4276               1.990724      1.401816         1.357870  \n",
       "  \n",
       "  [4277 rows x 79 columns],\n",
       "  'X_train_xgb':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "  1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "  8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "  5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "  4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "  4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "  7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "  426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "  7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  3600        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1262        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  8612        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  5075        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4758        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  4087        -0.161141      -0.376161            -0.564175    3.168295   \n",
       "  4406        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7111        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  426         -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  7925        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  3600   -0.302787   -0.242425  ...       1.032894           -4.138413   \n",
       "  1262   -0.302787   -0.242425  ...       0.419391           -1.680341   \n",
       "  8612   -0.302787   -0.242425  ...      -0.230200            0.922323   \n",
       "  5075   -0.302787    4.124990  ...       0.094596           -0.379009   \n",
       "  4758   -0.302787   -0.242425  ...      -1.476003           -0.458639   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  4087   -0.302787   -0.242425  ...       0.778193            0.560169   \n",
       "  4406   -0.302787   -0.242425  ...      -0.133888            0.819078   \n",
       "  7111   -0.302787   -0.242425  ...      -0.313074            1.568173   \n",
       "  426    -0.302787   -0.242425  ...       0.166773           -0.668194   \n",
       "  7925   -0.302787   -0.242425  ...       0.146632           -0.731514   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3600  0.542236  0.848438           -0.101809               2.769710   \n",
       "  1262  0.542236  0.848438            0.000000               2.769710   \n",
       "  8612  0.366320  0.665144            0.000000               2.769710   \n",
       "  5075  0.542236  0.848438            0.000000               2.769710   \n",
       "  4758  0.542236  0.848438            0.000000              -0.073199   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  4087  0.691785  0.998638            0.000000              -0.130693   \n",
       "  4406  0.501072  0.806529            0.000000              -0.150704   \n",
       "  7111  0.758932  1.065830            0.000000              -0.639943   \n",
       "  426   0.542236  0.848438            0.000000               2.769710   \n",
       "  7925  0.542236  0.848438            0.000000              -1.036715   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3600            1.560940               1.990724      1.401816         1.357870  \n",
       "  1262            1.560940               1.990724      1.401816         1.357870  \n",
       "  8612            1.560940               1.990724      1.401816         1.357870  \n",
       "  5075            1.560940               1.990724      1.401816         1.357870  \n",
       "  4758           -0.061492              -0.043779     -0.058854       -51.983508  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  4087            0.722746              -0.119876     -0.106686         1.185937  \n",
       "  4406           -0.290791              -0.451021     -0.315128         0.236911  \n",
       "  7111           -0.593120              -0.517760     -3.288903        -0.583203  \n",
       "  426             1.560940               1.990724      1.401816         1.357870  \n",
       "  7925           -0.922128              -1.034761     -1.039838        -1.040397  \n",
       "  \n",
       "  [6954 rows x 79 columns],\n",
       "  'X_val_xgb':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "  8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "  6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "  7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "  1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "  5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "  5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "  4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  3586        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7173        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  8559        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  6528        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7934         6.205752      -0.376161            -0.564175   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  3749        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1637        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  5820        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  5757        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4135        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  3586   -0.302787   -0.242425  ...      -0.194111            0.777730   \n",
       "  7173   -0.302787   -0.242425  ...       0.888540           -3.560043   \n",
       "  8559   -0.302787   -0.242425  ...      -0.024116           -0.229157   \n",
       "  6528   -0.302787   -0.242425  ...       0.599833           -2.403304   \n",
       "  7934   -0.302787   -0.242425  ...       2.162613            1.413441   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  3749   -0.302787   -0.242425  ...      -0.158023            0.633138   \n",
       "  1637   -0.302787   -0.242425  ...      -0.001576           -0.943163   \n",
       "  5820   -0.302787   -0.242425  ...       0.527657           -2.114119   \n",
       "  5757   -0.302787   -0.242425  ...       0.055164           -0.260996   \n",
       "  4135   -0.302787   -0.242425  ...      -0.140830            0.767007   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3586  0.317041  0.610786            0.000000               2.769710   \n",
       "  7173  0.542236  0.848438           -0.051555               2.769710   \n",
       "  8559  0.542236  0.848438            0.000000               0.264382   \n",
       "  6528  0.542236  0.848438            0.000000               2.769710   \n",
       "  7934  1.278849  1.610125            0.000000              -0.124232   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  3749  0.265208  0.551091            0.000000               2.769710   \n",
       "  1637  0.542236  0.848438            0.000000             -30.404201   \n",
       "  5820  0.542236  0.848438            0.000000               2.769710   \n",
       "  5757  0.542236  0.848438            0.000000              -0.575032   \n",
       "  4135  0.458141  0.762320            0.000000             -31.792846   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3586            1.560940               1.990724      1.401816         1.357870  \n",
       "  7173            1.560940               1.990724      1.401816         1.357870  \n",
       "  8559           -0.167200              -0.177864      1.744477        -0.164865  \n",
       "  6528            1.560940               1.990724      1.401816         1.357870  \n",
       "  7934            0.573468              -0.113273      1.383730        -0.086094  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  3749            1.560940               1.990724      1.401816         1.357870  \n",
       "  1637           -0.117736              -0.161268     -0.144270        -0.142626  \n",
       "  5820            1.560940               1.990724      1.401816         1.357870  \n",
       "  5757           -0.674018              -0.693065     -0.137336        -0.342659  \n",
       "  4135           -0.285593              -0.227834     -0.276827        -0.274156  \n",
       "  \n",
       "  [1739 rows x 79 columns],\n",
       "  'X_test_xgb':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  0         -1.165370 -0.112444        1.398797           -0.458742   \n",
       "  1          0.858096 -0.667306       -0.714900           -0.458742   \n",
       "  2         -1.165370  0.164986        1.398797           -0.458742   \n",
       "  3          0.858096  0.650490        1.398797           -0.458742   \n",
       "  4          0.858096 -0.597948       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4272      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  4273       0.858096  0.927920       -0.714900            2.179876   \n",
       "  4274      -1.165370 -0.043087        1.398797           -0.458742   \n",
       "  4275       0.858096  0.234344        1.398797           -0.458742   \n",
       "  4276      -1.165370  0.997278       -0.714900            2.179876   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  0           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1           -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  2           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  3           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4           -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  4272        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4273        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4274        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4275        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4276        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  0      -0.302787   -0.242425  ...       0.058507           -0.234417   \n",
       "  1      -0.302787   -0.242425  ...      -0.335932           -0.443860   \n",
       "  2       3.302656   -0.242425  ...      -0.085846            0.343953   \n",
       "  3       3.302656   -0.242425  ...       1.405844            0.205772   \n",
       "  4      -0.302787   -0.242425  ...       0.171708           -0.838827   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  4272   -0.302787   -0.242425  ...      -0.194111            0.777730   \n",
       "  4273   -0.302787   -0.242425  ...      -0.141347            1.094667   \n",
       "  4274   -0.302787    4.124990  ...       0.022419           -0.089824   \n",
       "  4275   -0.302787    4.124990  ...       0.149401            0.143108   \n",
       "  4276   -0.302787   -0.242425  ...      -0.518907            2.079062   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  0     0.542236  0.848438            0.000000               2.769710   \n",
       "  1     0.542236  0.848438            0.000000              -0.142436   \n",
       "  2     0.152709  0.406185            0.000000               2.769710   \n",
       "  3     0.501072  0.806529            0.000000              -0.071246   \n",
       "  4     0.542236  0.848438            0.000000              -0.309187   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  4272  0.317041  0.610786           -0.128399               2.769710   \n",
       "  4273  0.656442  0.963286            0.000000              -0.582939   \n",
       "  4274  0.542236  0.848438            0.000000               2.769710   \n",
       "  4275  0.210540  0.484091            0.000000              -0.166296   \n",
       "  4276  0.691785  0.998638            0.000000               2.769710   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  0               1.560940               1.990724      1.401816         1.357870  \n",
       "  1              -0.118950              -0.130793    -11.947877        -0.115190  \n",
       "  2               1.560940               1.990724      1.401816         1.357870  \n",
       "  3               7.707147              -0.064982     -0.024117         0.062999  \n",
       "  4              -0.279729              -6.195552     -0.271075        -0.268438  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  4272            1.560940               1.990724      1.401816         1.357870  \n",
       "  4273          -24.993834              -0.532069     -0.517806        -0.359005  \n",
       "  4274            1.560940               1.990724      1.401816         1.357870  \n",
       "  4275            4.829713              -0.153051     -0.136778         0.137916  \n",
       "  4276            1.560940               1.990724      1.401816         1.357870  \n",
       "  \n",
       "  [4277 rows x 79 columns],\n",
       "  'X_train_sklearn':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "  1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "  8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "  5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "  4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "  4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "  7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "  426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "  7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "  3600        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  1262        -0.161141       2.658437            -0.564175          0.0   \n",
       "  8612        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  5075        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4758        -0.161141       2.658437            -0.564175          0.0   \n",
       "  ...               ...            ...                  ...          ...   \n",
       "  4087        -0.161141      -0.376161            -0.564175          1.0   \n",
       "  4406        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  7111        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  426         -0.161141      -0.376161             1.772499          0.0   \n",
       "  7925        -0.161141      -0.376161             1.772499          0.0   \n",
       "  \n",
       "        CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "  3600          0.0          0.0  ...        1.032894            -4.138413   \n",
       "  1262          0.0          0.0  ...        0.419391            -1.680341   \n",
       "  8612          0.0          0.0  ...       -0.230200             0.922323   \n",
       "  5075          0.0          1.0  ...        0.094596            -0.379009   \n",
       "  4758          0.0          0.0  ...       -1.476003            -0.458639   \n",
       "  ...           ...          ...  ...             ...                  ...   \n",
       "  4087          0.0          0.0  ...        0.778193             0.560169   \n",
       "  4406          0.0          0.0  ...       -0.133888             0.819078   \n",
       "  7111          0.0          0.0  ...       -0.313074             1.568173   \n",
       "  426           0.0          0.0  ...        0.166773            -0.668194   \n",
       "  7925          0.0          0.0  ...        0.146632            -0.731514   \n",
       "  \n",
       "         Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3600  0.542236  0.848438            -0.101809               2.769710   \n",
       "  1262  0.542236  0.848438             0.000000               2.769710   \n",
       "  8612  0.366320  0.665144             0.000000               2.769710   \n",
       "  5075  0.542236  0.848438             0.000000               2.769710   \n",
       "  4758  0.542236  0.848438             0.000000              -0.073199   \n",
       "  ...        ...       ...                  ...                    ...   \n",
       "  4087  0.691785  0.998638             0.000000              -0.130693   \n",
       "  4406  0.501072  0.806529             0.000000              -0.150704   \n",
       "  7111  0.758932  1.065830             0.000000              -0.639943   \n",
       "  426   0.542236  0.848438             0.000000               2.769710   \n",
       "  7925  0.542236  0.848438             0.000000              -1.036715   \n",
       "  \n",
       "        FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "  3600             1.560940                1.990724       1.401816   \n",
       "  1262             1.560940                1.990724       1.401816   \n",
       "  8612             1.560940                1.990724       1.401816   \n",
       "  5075             1.560940                1.990724       1.401816   \n",
       "  4758            -0.061492               -0.043779      -0.058854   \n",
       "  ...                   ...                     ...            ...   \n",
       "  4087             0.722746               -0.119876      -0.106686   \n",
       "  4406            -0.290791               -0.451021      -0.315128   \n",
       "  7111            -0.593120               -0.517760      -3.288903   \n",
       "  426              1.560940                1.990724       1.401816   \n",
       "  7925            -0.922128               -1.034761      -1.039838   \n",
       "  \n",
       "        VRDeck_Dominance  \n",
       "  3600          1.357870  \n",
       "  1262          1.357870  \n",
       "  8612          1.357870  \n",
       "  5075          1.357870  \n",
       "  4758        -51.983508  \n",
       "  ...                ...  \n",
       "  4087          1.185937  \n",
       "  4406          0.236911  \n",
       "  7111         -0.583203  \n",
       "  426           1.357870  \n",
       "  7925         -1.040397  \n",
       "  \n",
       "  [6954 rows x 79 columns],\n",
       "  'X_val_sklearn':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "  8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "  6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "  7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "  1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "  5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "  5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "  4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "  3586        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  7173        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  8559        -0.161141      -0.376161             1.772499          0.0   \n",
       "  6528        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  7934         6.205752      -0.376161            -0.564175          0.0   \n",
       "  ...               ...            ...                  ...          ...   \n",
       "  3749        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  1637        -0.161141       2.658437            -0.564175          0.0   \n",
       "  5820        -0.161141       2.658437            -0.564175          0.0   \n",
       "  5757        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4135        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  \n",
       "        CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "  3586          0.0          0.0  ...       -0.194111             0.777730   \n",
       "  7173          0.0          0.0  ...        0.888540            -3.560043   \n",
       "  8559          0.0          0.0  ...       -0.024116            -0.229157   \n",
       "  6528          0.0          0.0  ...        0.599833            -2.403304   \n",
       "  7934          0.0          0.0  ...        2.162613             1.413441   \n",
       "  ...           ...          ...  ...             ...                  ...   \n",
       "  3749          0.0          0.0  ...       -0.158023             0.633138   \n",
       "  1637          0.0          0.0  ...       -0.001576            -0.943163   \n",
       "  5820          0.0          0.0  ...        0.527657            -2.114119   \n",
       "  5757          0.0          0.0  ...        0.055164            -0.260996   \n",
       "  4135          0.0          0.0  ...       -0.140830             0.767007   \n",
       "  \n",
       "         Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3586  0.317041  0.610786             0.000000               2.769710   \n",
       "  7173  0.542236  0.848438            -0.051555               2.769710   \n",
       "  8559  0.542236  0.848438             0.000000               0.264382   \n",
       "  6528  0.542236  0.848438             0.000000               2.769710   \n",
       "  7934  1.278849  1.610125             0.000000              -0.124232   \n",
       "  ...        ...       ...                  ...                    ...   \n",
       "  3749  0.265208  0.551091             0.000000               2.769710   \n",
       "  1637  0.542236  0.848438             0.000000             -30.404201   \n",
       "  5820  0.542236  0.848438             0.000000               2.769710   \n",
       "  5757  0.542236  0.848438             0.000000              -0.575032   \n",
       "  4135  0.458141  0.762320             0.000000             -31.792846   \n",
       "  \n",
       "        FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "  3586             1.560940                1.990724       1.401816   \n",
       "  7173             1.560940                1.990724       1.401816   \n",
       "  8559            -0.167200               -0.177864       1.744477   \n",
       "  6528             1.560940                1.990724       1.401816   \n",
       "  7934             0.573468               -0.113273       1.383730   \n",
       "  ...                   ...                     ...            ...   \n",
       "  3749             1.560940                1.990724       1.401816   \n",
       "  1637            -0.117736               -0.161268      -0.144270   \n",
       "  5820             1.560940                1.990724       1.401816   \n",
       "  5757            -0.674018               -0.693065      -0.137336   \n",
       "  4135            -0.285593               -0.227834      -0.276827   \n",
       "  \n",
       "        VRDeck_Dominance  \n",
       "  3586          1.357870  \n",
       "  7173          1.357870  \n",
       "  8559         -0.164865  \n",
       "  6528          1.357870  \n",
       "  7934         -0.086094  \n",
       "  ...                ...  \n",
       "  3749          1.357870  \n",
       "  1637         -0.142626  \n",
       "  5820          1.357870  \n",
       "  5757         -0.342659  \n",
       "  4135         -0.274156  \n",
       "  \n",
       "  [1739 rows x 79 columns],\n",
       "  'X_test_sklearn':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  0         -1.165370 -0.112444        1.398797           -0.458742   \n",
       "  1          0.858096 -0.667306       -0.714900           -0.458742   \n",
       "  2         -1.165370  0.164986        1.398797           -0.458742   \n",
       "  3          0.858096  0.650490        1.398797           -0.458742   \n",
       "  4          0.858096 -0.597948       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4272      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  4273       0.858096  0.927920       -0.714900            2.179876   \n",
       "  4274      -1.165370 -0.043087        1.398797           -0.458742   \n",
       "  4275       0.858096  0.234344        1.398797           -0.458742   \n",
       "  4276      -1.165370  0.997278       -0.714900            2.179876   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "  0           -0.161141      -0.376161            -0.564175          0.0   \n",
       "  1           -0.161141      -0.376161             1.772499          0.0   \n",
       "  2           -0.161141      -0.376161            -0.564175          0.0   \n",
       "  3           -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4           -0.161141      -0.376161             1.772499          0.0   \n",
       "  ...               ...            ...                  ...          ...   \n",
       "  4272        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4273        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4274        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4275        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4276        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  \n",
       "        CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "  0             0.0          0.0  ...        0.058507            -0.234417   \n",
       "  1             0.0          0.0  ...       -0.335932            -0.443860   \n",
       "  2             1.0          0.0  ...       -0.085846             0.343953   \n",
       "  3             1.0          0.0  ...        1.405844             0.205772   \n",
       "  4             0.0          0.0  ...        0.171708            -0.838827   \n",
       "  ...           ...          ...  ...             ...                  ...   \n",
       "  4272          0.0          0.0  ...       -0.194111             0.777730   \n",
       "  4273          0.0          0.0  ...       -0.141347             1.094667   \n",
       "  4274          0.0          1.0  ...        0.022419            -0.089824   \n",
       "  4275          0.0          1.0  ...        0.149401             0.143108   \n",
       "  4276          0.0          0.0  ...       -0.518907             2.079062   \n",
       "  \n",
       "         Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  0     0.542236  0.848438             0.000000               2.769710   \n",
       "  1     0.542236  0.848438             0.000000              -0.142436   \n",
       "  2     0.152709  0.406185             0.000000               2.769710   \n",
       "  3     0.501072  0.806529             0.000000              -0.071246   \n",
       "  4     0.542236  0.848438             0.000000              -0.309187   \n",
       "  ...        ...       ...                  ...                    ...   \n",
       "  4272  0.317041  0.610786            -0.128399               2.769710   \n",
       "  4273  0.656442  0.963286             0.000000              -0.582939   \n",
       "  4274  0.542236  0.848438             0.000000               2.769710   \n",
       "  4275  0.210540  0.484091             0.000000              -0.166296   \n",
       "  4276  0.691785  0.998638             0.000000               2.769710   \n",
       "  \n",
       "        FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "  0                1.560940                1.990724       1.401816   \n",
       "  1               -0.118950               -0.130793     -11.947877   \n",
       "  2                1.560940                1.990724       1.401816   \n",
       "  3                7.707147               -0.064982      -0.024117   \n",
       "  4               -0.279729               -6.195552      -0.271075   \n",
       "  ...                   ...                     ...            ...   \n",
       "  4272             1.560940                1.990724       1.401816   \n",
       "  4273           -24.993834               -0.532069      -0.517806   \n",
       "  4274             1.560940                1.990724       1.401816   \n",
       "  4275             4.829713               -0.153051      -0.136778   \n",
       "  4276             1.560940                1.990724       1.401816   \n",
       "  \n",
       "        VRDeck_Dominance  \n",
       "  0             1.357870  \n",
       "  1            -0.115190  \n",
       "  2             1.357870  \n",
       "  3             0.062999  \n",
       "  4            -0.268438  \n",
       "  ...                ...  \n",
       "  4272          1.357870  \n",
       "  4273         -0.359005  \n",
       "  4274          1.357870  \n",
       "  4275          0.137916  \n",
       "  4276          1.357870  \n",
       "  \n",
       "  [4277 rows x 79 columns],\n",
       "  'categorical_features': ['cat_HomePlanet',\n",
       "   'cat_Destination',\n",
       "   'cat_CabinDeck',\n",
       "   'cat_CabinSide',\n",
       "   'cat_AgeGroup',\n",
       "   'cat_Route',\n",
       "   'CabinDeck_B',\n",
       "   'CabinDeck_C',\n",
       "   'CabinDeck_D',\n",
       "   'CabinDeck_E',\n",
       "   'CabinDeck_F',\n",
       "   'CabinDeck_G',\n",
       "   'CabinDeck_T',\n",
       "   'CabinDeck_Unknown',\n",
       "   'CabinSide_S',\n",
       "   'CabinSide_Unknown',\n",
       "   'CryoSleep',\n",
       "   'CryoSleepSpender',\n",
       "   'Destination_PSO J318.5-22',\n",
       "   'Destination_TRAPPIST-1e',\n",
       "   'HasFamily',\n",
       "   'HomePlanet_Europa',\n",
       "   'HomePlanet_Mars',\n",
       "   'PassengerGroup',\n",
       "   'Route_Earth_to_PSO J318.5-22',\n",
       "   'Route_Earth_to_TRAPPIST-1e',\n",
       "   'Route_Europa_to_55 Cancri e',\n",
       "   'Route_Europa_to_PSO J318.5-22',\n",
       "   'Route_Europa_to_TRAPPIST-1e',\n",
       "   'Route_Mars_to_55 Cancri e',\n",
       "   'Route_Mars_to_PSO J318.5-22',\n",
       "   'Route_Mars_to_TRAPPIST-1e',\n",
       "   'TravelingAlone',\n",
       "   'VIP']}}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_optimized_spaceship_solution()"
   ]
  },
  {
   "cell_type": "code",
   "id": "95bb2d40-1ddf-41da-80a0-7b33559976bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:19:43.866098Z",
     "start_time": "2025-03-20T05:19:43.768812Z"
    }
   },
   "source": [
    "def elite_xgboost_solution(train_data, test_data, random_state=42, n_trials=50):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import xgboost as xgb\n",
    "    from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import time\n",
    "    import optuna\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"===== XGBOOST SOLUTION FOR SPACESHIP TITANIC =====\")\n",
    "\n",
    "    print(\"\\n[1/8] Data Preparation\")\n",
    "\n",
    "    test_ids = test_data['PassengerId'].copy()\n",
    "\n",
    "    y = train_data['Transported'].copy()\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "        print(\"Converted boolean target to integer (0/1)\")\n",
    "\n",
    "    X = train_data.drop(['Transported'], axis=1)\n",
    "\n",
    "    df_train = train_data.copy()\n",
    "    df_test = test_data.copy()\n",
    "    all_data = pd.concat([X, df_test], axis=0).reset_index(drop=True)\n",
    "\n",
    "    print(\"[2/8] Basic Feature Engineering\")\n",
    "\n",
    "    if 'PassengerId' in all_data.columns:\n",
    "        all_data['PassengerGroup'] = all_data['PassengerId'].str.split('_').str[0].astype(int)\n",
    "        all_data['PassengerNumber'] = all_data['PassengerId'].str.split('_').str[1].astype(int)\n",
    "\n",
    "    if 'Cabin' in all_data.columns:\n",
    "        all_data['HasCabin'] = all_data['Cabin'].notna().astype(int)\n",
    "\n",
    "        all_data['Deck'] = 'Z'\n",
    "        all_data['CabinNum'] = -1\n",
    "        all_data['Side'] = 'Z'\n",
    "\n",
    "        cabin_mask = all_data['Cabin'].notna()\n",
    "        if cabin_mask.any():\n",
    "            cabin_parts = all_data.loc[cabin_mask, 'Cabin'].str.split('/', expand=True)\n",
    "            if cabin_parts.shape[1] >= 3:\n",
    "                all_data.loc[cabin_mask, 'Deck'] = cabin_parts[0]\n",
    "                all_data.loc[cabin_mask, 'CabinNum'] = pd.to_numeric(cabin_parts[1], errors='coerce')\n",
    "                all_data.loc[cabin_mask, 'Side'] = cabin_parts[2]\n",
    "\n",
    "        all_data['CabinPosition'] = all_data['CabinNum'] % 2\n",
    "        all_data['Deck_is_ABC'] = all_data['Deck'].isin(['A', 'B', 'C']).astype(int)\n",
    "        all_data['Deck_is_FG'] = all_data['Deck'].isin(['F', 'G']).astype(int)\n",
    "\n",
    "    expense_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    available_expenses = [col for col in expense_columns if col in all_data.columns]\n",
    "\n",
    "    for col in available_expenses:\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "    if available_expenses:\n",
    "        all_data['TotalExpense'] = all_data[available_expenses].sum(axis=1)\n",
    "\n",
    "        for col in available_expenses:\n",
    "            all_data[f'{col}_Ratio'] = all_data.apply(\n",
    "                lambda x: x[col] / x['TotalExpense'] if x['TotalExpense'] > 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        all_data['HasExpense'] = (all_data['TotalExpense'] > 0).astype(int)\n",
    "        all_data['ExpenseCount'] = (all_data[available_expenses] > 0).sum(axis=1)\n",
    "\n",
    "        all_data['ExpensePattern'] = all_data.apply(\n",
    "            lambda x: ''.join(['1' if x[col] > 0 else '0' for col in available_expenses]),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        all_data['LogExpense'] = np.log1p(all_data['TotalExpense'])\n",
    "        all_data['SqrtExpense'] = np.sqrt(all_data['TotalExpense'])\n",
    "\n",
    "    if 'PassengerGroup' in all_data.columns:\n",
    "        group_sizes = all_data.groupby('PassengerGroup').size()\n",
    "        all_data['GroupSize'] = all_data['PassengerGroup'].map(group_sizes)\n",
    "\n",
    "        if 'TotalExpense' in all_data.columns:\n",
    "            group_expenses = all_data.groupby('PassengerGroup')['TotalExpense'].agg(['sum', 'mean', 'std']).fillna(0)\n",
    "            all_data['GroupTotalExpense'] = all_data['PassengerGroup'].map(group_expenses['sum'])\n",
    "            all_data['GroupMeanExpense'] = all_data['PassengerGroup'].map(group_expenses['mean'])\n",
    "\n",
    "            all_data['ExpenseVsGroup'] = all_data.apply(\n",
    "                lambda x: x['TotalExpense'] / x['GroupMeanExpense'] if x['GroupMeanExpense'] > 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "    if 'Name' in all_data.columns:\n",
    "        all_data['LastName'] = all_data['Name'].str.split(' ').str[0]\n",
    "\n",
    "        family_sizes = all_data.groupby('LastName').size()\n",
    "        all_data['FamilySize'] = all_data['LastName'].map(family_sizes)\n",
    "\n",
    "    if 'GroupSize' in all_data.columns:\n",
    "        all_data['IsAlone'] = (all_data['GroupSize'] == 1).astype(int)\n",
    "\n",
    "    if 'FamilySize' in all_data.columns:\n",
    "        all_data['HasFamily'] = (all_data['FamilySize'] > 1).astype(int)\n",
    "\n",
    "    print(\"[2/6] Advanced Feature Encoding & Preprocessing\")\n",
    "\n",
    "    train_rows = len(X)\n",
    "    train_with_target = all_data.iloc[:train_rows].copy()\n",
    "    train_with_target['Transported'] = y\n",
    "\n",
    "    mean_target_features = ['PassengerGroup', 'LastName', 'ExpensePattern']\n",
    "    mean_target_features = [col for col in mean_target_features if col in all_data.columns]\n",
    "\n",
    "    for col in mean_target_features:\n",
    "        means = train_with_target.groupby(col)['Transported'].mean().to_dict()\n",
    "        all_data[f'{col}_encoded'] = all_data[col].map(means).fillna(0.5)\n",
    "\n",
    "    categorical_cols = ['HomePlanet', 'Destination', 'Deck', 'Side', 'DeckSide', 'Route']\n",
    "    categorical_cols = [col for col in categorical_cols if col in all_data.columns]\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        top_categories = all_data[col].value_counts().head(5).index.tolist()\n",
    "        for category in top_categories:\n",
    "            all_data[f'{col}_{category}'] = (all_data[col] == category).astype(int)\n",
    "\n",
    "    for col in all_data.columns:\n",
    "        if all_data[col].dtype == 'object' or all_data[col].dtype.name == 'category':\n",
    "            le.fit(all_data[col].fillna('Unknown').astype(str))\n",
    "            all_data[col + '_encoded'] = le.transform(all_data[col].fillna('Unknown').astype(str))\n",
    "\n",
    "            if col + '_encoded' in all_data.columns and col != 'LastName':\n",
    "                all_data = all_data.drop(columns=[col])\n",
    "\n",
    "    print(\"[3/8] Advanced Feature Engineering\")\n",
    "\n",
    "    if 'HomePlanet' in all_data.columns:\n",
    "        all_data['HomePlanet'] = all_data['HomePlanet'].fillna(all_data['HomePlanet'].mode()[0])\n",
    "\n",
    "    if 'CryoSleep' in all_data.columns:\n",
    "        all_data['CryoSleep'] = all_data['CryoSleep'].fillna(False)\n",
    "\n",
    "    if 'Destination' in all_data.columns:\n",
    "        all_data['Destination'] = all_data['Destination'].fillna(all_data['Destination'].mode()[0])\n",
    "\n",
    "    if 'VIP' in all_data.columns:\n",
    "        all_data['VIP'] = all_data['VIP'].fillna(False)\n",
    "\n",
    "    if 'Age' in all_data.columns:\n",
    "        all_data['Age'] = all_data['Age'].fillna(all_data['Age'].median())\n",
    "        all_data['AgeBand'] = pd.qcut(all_data['Age'], 5, labels=False)\n",
    "        all_data['Age_squared'] = all_data['Age'] ** 2\n",
    "        all_data['IsChild'] = (all_data['Age'] < 13).astype(int)\n",
    "        all_data['IsAdult'] = ((all_data['Age'] >= 13) & (all_data['Age'] < 65)).astype(int)\n",
    "        all_data['IsSenior'] = (all_data['Age'] >= 65).astype(int)\n",
    "\n",
    "        if 'HomePlanet' in all_data.columns:\n",
    "            planets = all_data['HomePlanet'].unique()\n",
    "            for planet in planets:\n",
    "                all_data[f'Age_from_{planet}'] = all_data['Age'] * (all_data['HomePlanet'] == planet)\n",
    "\n",
    "    if all(col in all_data.columns for col in ['CryoSleep', 'VIP']):\n",
    "        all_data['CryoSleep_VIP'] = (all_data['CryoSleep'] & all_data['VIP']).astype(int)\n",
    "\n",
    "    if all(col in all_data.columns for col in ['CryoSleep', 'TotalExpense']):\n",
    "        all_data['CryoSleep_HasExpense'] = (all_data['CryoSleep'] & (all_data['TotalExpense'] > 0)).astype(int)\n",
    "        all_data['Unusual_Expense'] = ((all_data['CryoSleep'] & (all_data['TotalExpense'] > 0)) |\n",
    "                                       (~all_data['CryoSleep'] & (all_data['TotalExpense'] == 0))).astype(int)\n",
    "\n",
    "    if all(col in all_data.columns for col in ['HomePlanet', 'Destination']):\n",
    "        all_data['Route'] = all_data['HomePlanet'] + '_to_' + all_data['Destination']\n",
    "\n",
    "        route_counts = all_data['Route'].value_counts()\n",
    "        all_data['RoutePopularity'] = all_data['Route'].map(route_counts)\n",
    "\n",
    "    if all(col in all_data.columns for col in ['Deck', 'Side']):\n",
    "        all_data['DeckSide'] = all_data['Deck'] + all_data['Side']\n",
    "\n",
    "    if all(col in all_data.columns for col in ['VIP', 'TotalExpense']):\n",
    "        all_data['Expense_by_VIP'] = all_data['TotalExpense'] * all_data['VIP'].astype(int)\n",
    "\n",
    "    if all(col in all_data.columns for col in ['Age', 'TotalExpense']):\n",
    "        all_data['ExpenseRatio_by_Age'] = all_data['TotalExpense'] / (all_data['Age'] + 1)\n",
    "    print(\"[4/8] Missing Value Handling and Clustering\")\n",
    "\n",
    "    cols_with_missing = all_data.columns[all_data.isnull().any()].tolist()\n",
    "    for col in cols_with_missing:\n",
    "        all_data[f'{col}_Missing'] = all_data[col].isnull().astype(int)\n",
    "\n",
    "    numeric_cols_with_missing = [\n",
    "        col for col in all_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if all_data[col].isnull().sum() > 0\n",
    "    ]\n",
    "\n",
    "    if numeric_cols_with_missing:\n",
    "        mice_imputer = IterativeImputer(max_iter=10, random_state=random_state)\n",
    "        all_data[numeric_cols_with_missing] = mice_imputer.fit_transform(all_data[numeric_cols_with_missing])\n",
    "\n",
    "    numeric_cols_for_clustering = all_data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    if len(numeric_cols_for_clustering) > 5:\n",
    "        clustering_cols = ['Age', 'TotalExpense', 'GroupSize', 'CabinNum']\n",
    "        clustering_cols = [col for col in clustering_cols if col in numeric_cols_for_clustering]\n",
    "\n",
    "        if len(clustering_cols) >= 3:\n",
    "            kmeans = KMeans(n_clusters=5, random_state=random_state, n_init=10)\n",
    "            all_data['Cluster'] = kmeans.fit_predict(all_data[clustering_cols].fillna(0))\n",
    "\n",
    "    train_rows = len(X)\n",
    "    train_with_target = all_data.iloc[:train_rows].copy()\n",
    "    train_with_target['Transported'] = y\n",
    "\n",
    "    mean_target_features = ['PassengerGroup', 'LastName', 'ExpensePattern', 'Deck', 'HomePlanet', 'Route']\n",
    "    mean_target_features = [col for col in mean_target_features if col in all_data.columns]\n",
    "\n",
    "    for col in mean_target_features:\n",
    "        means = train_with_target.groupby(col)['Transported'].mean().to_dict()\n",
    "        all_data[f'{col}_encoded'] = all_data[col].map(means).fillna(0.5)\n",
    "\n",
    "    drop_cols = ['Name', 'Cabin', 'PassengerId']\n",
    "    drop_cols = [col for col in drop_cols if col in all_data.columns]\n",
    "    all_data = all_data.drop(columns=drop_cols)\n",
    "\n",
    "    print(\"[5/8] Preprocessing and Encoding\")\n",
    "\n",
    "    categorical_cols = ['HomePlanet', 'Destination', 'Deck', 'Side', 'DeckSide', 'Route']\n",
    "    categorical_cols = [col for col in categorical_cols if col in all_data.columns]\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        top_categories = all_data[col].value_counts().head(5).index.tolist()\n",
    "        for category in top_categories:\n",
    "            all_data[f'{col}_{category}'] = (all_data[col] == category).astype(int)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    for col in all_data.columns:\n",
    "        if all_data[col].dtype == 'object' or all_data[col].dtype.name == 'category':\n",
    "            le.fit(all_data[col].fillna('Unknown').astype(str))\n",
    "            all_data[col + '_encoded'] = le.transform(all_data[col].fillna('Unknown').astype(str))\n",
    "\n",
    "            if col + '_encoded' in all_data.columns and col != 'LastName':\n",
    "                all_data = all_data.drop(columns=[col])\n",
    "\n",
    "    X_processed = all_data.iloc[:train_rows]\n",
    "    X_test = all_data.iloc[train_rows:]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_processed,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=random_state,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "    scaler.fit(X_train[numerical_cols])\n",
    "\n",
    "    for df in [X_train, X_val, X_test]:\n",
    "        df[numerical_cols] = scaler.transform(df[numerical_cols])\n",
    "\n",
    "    for df in [X_train, X_val, X_test]:\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "    print(\"[6/8] Optuna Hyperparameter Optimization\")\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'eta': trial.suggest_float('eta', 0.01, 0.3),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 0, 5),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 5.0),\n",
    "            'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.8, 1.2),\n",
    "            'max_delta_step': trial.suggest_int('max_delta_step', 0, 5),\n",
    "            'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "            'tree_method': 'hist',\n",
    "        }\n",
    "\n",
    "        n_estimators = trial.suggest_int('n_estimators', 300, 1000)\n",
    "\n",
    "        cv_scores = []\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_fold_train, label=y_fold_train)\n",
    "            dval = xgb.DMatrix(X_fold_val, label=y_fold_val)\n",
    "\n",
    "            model = xgb.train(\n",
    "                params,\n",
    "                dtrain,\n",
    "                num_boost_round=n_estimators,\n",
    "                evals=[(dval, 'val')],\n",
    "                early_stopping_rounds=50,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "\n",
    "            fold_preds = model.predict(dval)\n",
    "\n",
    "            thresholds = np.linspace(0.3, 0.7, 21)\n",
    "            scores = [accuracy_score(y_fold_val, (fold_preds > t).astype(int)) for t in thresholds]\n",
    "            best_score = max(scores)\n",
    "            cv_scores.append(best_score)\n",
    "\n",
    "        return np.mean(cv_scores)\n",
    "\n",
    "    print(f\"Running {n_trials} Optuna trials...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    best_params = study.best_params.copy()\n",
    "    best_params['objective'] = 'binary:logistic'\n",
    "    best_params['eval_metric'] = 'logloss'\n",
    "    best_params['tree_method'] = 'hist'\n",
    "    n_estimators = best_params.pop('n_estimators')\n",
    "\n",
    "    print(f\"Best CV accuracy: {study.best_value:.4f}\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    print(f\"Best n_estimators: {n_estimators}\")\n",
    "\n",
    "    print(\"[7/8] Model Training & Feature Selection\")\n",
    "\n",
    "    for df in [X_train, X_val, X_test]:\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    cv_models = []\n",
    "    cv_scores = []\n",
    "    oof_predictions = np.zeros(len(X_train))\n",
    "    feature_importances = pd.DataFrame()\n",
    "    feature_importances['Feature'] = X_train.columns\n",
    "    feature_importances['Importance'] = 0\n",
    "\n",
    "    fold_idx = 0\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        fold_idx += 1\n",
    "        print(f\"  Training fold {fold_idx}/5...\")\n",
    "\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_fold_train, label=y_fold_train)\n",
    "        dval = xgb.DMatrix(X_fold_val, label=y_fold_val)\n",
    "\n",
    "        model = xgb.train(\n",
    "            best_params,\n",
    "            dtrain,\n",
    "            num_boost_round=2000,\n",
    "            evals=[(dval, 'val')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        importance = model.get_score(importance_type='gain')\n",
    "        for feature, score in importance.items():\n",
    "            if feature in feature_importances['Feature'].values:\n",
    "                feature_importances.loc[feature_importances['Feature'] == feature, 'Importance'] += score\n",
    "\n",
    "        fold_preds = model.predict(xgb.DMatrix(X_fold_val))\n",
    "        oof_predictions[val_idx] = fold_preds\n",
    "\n",
    "        best_threshold = 0.5\n",
    "        thresholds = np.linspace(0.3, 0.7, 41)\n",
    "        scores = [accuracy_score(y_fold_val, (fold_preds > t).astype(int)) for t in thresholds]\n",
    "        if max(scores) > best_threshold:\n",
    "            best_threshold = thresholds[np.argmax(scores)]\n",
    "\n",
    "        fold_score = accuracy_score(y_fold_val, (fold_preds > best_threshold).astype(int))\n",
    "        cv_scores.append(fold_score)\n",
    "\n",
    "        cv_models.append((model, best_threshold))\n",
    "        print(f\"    Fold score: {fold_score:.4f}, Threshold: {best_threshold:.4f}\")\n",
    "\n",
    "    cv_mean = np.mean(cv_scores)\n",
    "    cv_std = np.std(cv_scores)\n",
    "    print(f\"Cross-validation score: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "\n",
    "    feature_importances = feature_importances.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    important_features = feature_importances.iloc[:int(len(feature_importances) * 0.8)]['Feature'].tolist()\n",
    "\n",
    "    print(f\"Selected {len(important_features)} out of {len(X_train.columns)} features\")\n",
    "\n",
    "    X_train_selected = X_train[important_features]\n",
    "    X_val_selected = X_val[important_features]\n",
    "    X_test_selected = X_test[important_features]\n",
    "\n",
    "    dtrain_selected = xgb.DMatrix(X_train_selected, label=y_train)\n",
    "    dval_selected = xgb.DMatrix(X_val_selected, label=y_val)\n",
    "\n",
    "    final_model = xgb.train(\n",
    "        best_params,\n",
    "        dtrain_selected,\n",
    "        num_boost_round=n_estimators,\n",
    "        evals=[(dval_selected, 'val')],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    print(\"[8/8] Advanced Ensemble Prediction & Submission\")\n",
    "\n",
    "    X_test_meta = np.zeros((len(X_test), len(cv_models) + 1))\n",
    "    X_val_meta = np.zeros((len(X_val), len(cv_models) + 1))\n",
    "\n",
    "    for i, (model, _) in enumerate(cv_models):\n",
    "        X_test_meta[:, i] = model.predict(xgb.DMatrix(X_test))\n",
    "        X_val_meta[:, i] = model.predict(xgb.DMatrix(X_val))\n",
    "\n",
    "    X_test_meta[:, -1] = final_model.predict(xgb.DMatrix(X_test_selected))\n",
    "    X_val_meta[:, -1] = final_model.predict(xgb.DMatrix(X_val_selected))\n",
    "\n",
    "    meta_model = LogisticRegression(C=0.1, solver='liblinear', random_state=random_state)\n",
    "    meta_model.fit(X_val_meta, y_val)\n",
    "\n",
    "    test_meta_preds = meta_model.predict_proba(X_test_meta)[:, 1]\n",
    "\n",
    "    thresholds = np.linspace(0.3, 0.7, 41)\n",
    "    val_scores = [accuracy_score(y_val, (meta_model.predict_proba(X_val_meta)[:, 1] > t).astype(int))\n",
    "                  for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(val_scores)]\n",
    "    best_val_score = max(val_scores)\n",
    "    print(f\"Best stacking threshold: {best_threshold:.4f}, Validation Score: {best_val_score:.4f}\")\n",
    "\n",
    "    final_predictions = (test_meta_preds > best_threshold).astype(bool)\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': test_ids,\n",
    "        'Transported': final_predictions\n",
    "    })\n",
    "\n",
    "    submission_path = 'enhanced_xgboost_submission.csv'\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "\n",
    "    transport_rate = submission['Transported'].mean() * 100\n",
    "    print(f\"Prediction transport rate: {transport_rate:.2f}%\")\n",
    "\n",
    "    exec_time = time.time() - start_time\n",
    "    print(f\"\\nExecution complete in {exec_time:.2f} seconds ({exec_time / 60:.2f} minutes)\")\n",
    "\n",
    "    return {\n",
    "        'submission': submission,\n",
    "        'cv_score': cv_mean,\n",
    "        'validation_accuracy': best_val_score,\n",
    "        'models': cv_models,\n",
    "        'meta_model': meta_model,\n",
    "        'best_threshold': best_threshold,\n",
    "        'feature_importance': feature_importances\n",
    "    }\n",
    "\n",
    "\n",
    "def get_feature_importance(models, feature_names):\n",
    "    importance_df = pd.DataFrame()\n",
    "    importance_df['Feature'] = feature_names\n",
    "    importance_df['Importance'] = 0\n",
    "    for model, _ in models:\n",
    "        importance = model.get_score(importance_type='gain')\n",
    "\n",
    "        model_importance = pd.DataFrame({\n",
    "            'Feature': list(importance.keys()),\n",
    "            'Importance': list(importance.values())\n",
    "        })\n",
    "\n",
    "        importance_df = importance_df.merge(\n",
    "            model_importance,\n",
    "            on='Feature',\n",
    "            how='left',\n",
    "            suffixes=('_old', '')\n",
    "        )\n",
    "\n",
    "        importance_df['Importance'] = importance_df['Importance_old'].fillna(0) + importance_df['Importance'].fillna(0)\n",
    "\n",
    "        importance_df = importance_df[['Feature', 'Importance']]\n",
    "\n",
    "    importance_df['Importance'] /= len(models)\n",
    "\n",
    "    return importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "9b9c8564-6cd6-4dcc-bf16-d44dc4975557",
   "metadata": {},
   "source": [
    "result = elite_xgboost_solution(train_data, test_data)\n",
    "\n",
    "print(f\"Validation accuracy: {result['cv_score']:.4f}\")\n",
    "\n",
    "print(\"\\nTop 15 features:\")\n",
    "print(result['feature_importance'].head(15))\n",
    "print(result['feature_importance'].head(15))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b52a9dfb-d8ed-4969-aa99-4ede75638a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DATA PREPARATION =====\n",
      "Loading and preparing Spaceship Titanic data with preserved categorical features...\n",
      "Training data: 8693 rows, 14 columns\n",
      "Test data: 4277 rows, 13 columns\n",
      "Converted boolean target to integer (0/1)\n",
      "Split into 6954 training samples and 1739 validation samples\n",
      "Preserving categorical feature: HomePlanet\n",
      "Preserving categorical feature: Destination\n",
      "Preserving categorical feature: CabinDeck\n",
      "Preserving categorical feature: CabinSide\n",
      "Preserving categorical feature: AgeGroup\n",
      "Preserving categorical feature: Route\n",
      "After preprocessing: 5350 features created\n",
      "Added 6 preserved categorical features\n",
      "Found NaN values in X_train_proc for columns: ['CabinNum', 'FamilySize', 'cat_AgeGroup']\n",
      "Filling remaining NaNs with appropriate values...\n",
      "  - CabinNum: filled with median (429.0)\n",
      "  - FamilySize: filled with median (6.0)\n",
      "  - cat_AgeGroup: filled with mode (Adult)\n",
      "Found NaN values in X_val_proc for columns: ['CabinNum', 'FamilySize', 'cat_AgeGroup']\n",
      "Filling remaining NaNs with appropriate values...\n",
      "  - CabinNum: filled with median (420.0)\n",
      "  - FamilySize: filled with median (6.0)\n",
      "  - cat_AgeGroup: filled with mode (Adult)\n",
      "Found NaN values in X_test_proc for columns: ['CabinNum', 'FamilySize', 'cat_AgeGroup']\n",
      "Filling remaining NaNs with appropriate values...\n",
      "  - CabinNum: filled with median (442.0)\n",
      "  - FamilySize: filled with median (6.0)\n",
      "  - cat_AgeGroup: filled with mode (Adult)\n",
      "All datasets are now free of NaN values!\n",
      "Data scaling completed with StandardScaler (preserved categorical features were NOT scaled)\n",
      "Processed training features: (6954, 5356)\n",
      "Processed validation features: (1739, 5356)\n",
      "Processed test features: (4277, 5356)\n",
      "Applying enhanced feature engineering...\n",
      "Adding enhanced features...\n",
      "Removing individual name features to prevent dimensionality explosion...\n",
      "Removing 5287 name-based features\n",
      "Feature count after name removal: 79\n",
      "\n",
      "===== STRICT CATEGORICAL FEATURE SELECTION =====\n",
      "Found 6 preserved categorical features\n",
      "Selected 28 additional binary categorical features\n",
      "Using total of 34 categorical features for CatBoost\n",
      "Sample preserved features: ['cat_HomePlanet', 'cat_Destination', 'cat_CabinDeck', 'cat_CabinSide', 'cat_AgeGroup']\n",
      "Sample binary features: ['CabinDeck_B', 'CabinDeck_C', 'CabinDeck_D', 'CabinDeck_E', 'CabinDeck_F']\n",
      "Identified 45 numerical features\n",
      "\n",
      "===== FEATURE COUNT DIAGNOSTICS =====\n",
      "Total features before selection: 79\n",
      "Number of preserved categorical features: 6\n",
      "Number of binary categorical features: 28\n",
      "Number of numerical features: 45\n",
      "\n",
      "===== CREATING MODEL-SPECIFIC DATASETS =====\n",
      "Creating CatBoost dataset with string categorical features...\n",
      "Creating XGBoost dataset with pandas category features...\n",
      "Creating sklearn dataset with numerical features only...\n",
      "Encoding 34 categorical features for sklearn models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:01:59,120] A new study created in memory with name: no-name-8f025d8f-4e15-4894-bf27-b0ffa9a15707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OPTUNA HYPERPARAMETER OPTIMIZATION =====\n",
      "System has 11 CPUs available\n",
      "Using 11 parallel jobs for optimization\n",
      "Starting comprehensive Optuna tuning with model-specific data formats...\n",
      "Creating model-specific datasets...\n",
      "Created specialized datasets for each model type\n",
      "First 5 categorical features: ['cat_HomePlanet', 'cat_Destination', 'cat_CabinDeck', 'cat_CabinSide', 'cat_AgeGroup']\n",
      "Tuning CatBoost with 34 categorical features\n",
      "First 5 categorical features: ['cat_HomePlanet', 'cat_Destination', 'cat_CabinDeck', 'cat_CabinSide', 'cat_AgeGroup']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:02:08,371] Trial 6 finished with value: 0.8027602070155262 and parameters: {'iterations': 1230, 'depth': 6, 'learning_rate': 0.0540169286925386, 'l2_leaf_reg': 0.3224885448071705, 'random_strength': 1.8556473239436837, 'bagging_temperature': 7.964382273601593, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 13, 'max_ctr_complexity': 2, 'one_hot_max_size': 195}. Best is trial 6 with value: 0.8027602070155262.\n",
      "[I 2025-03-18 01:02:11,776] Trial 10 finished with value: 0.8085106382978723 and parameters: {'iterations': 1227, 'depth': 8, 'learning_rate': 0.06450118308764397, 'l2_leaf_reg': 7.580740427063586, 'random_strength': 0.46455210223216953, 'bagging_temperature': 9.312321878296636, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 14, 'max_ctr_complexity': 1, 'one_hot_max_size': 187}. Best is trial 10 with value: 0.8085106382978723.\n",
      "[I 2025-03-18 01:02:11,872] Trial 0 finished with value: 0.8108108108108109 and parameters: {'iterations': 1484, 'depth': 7, 'learning_rate': 0.04765324996342744, 'l2_leaf_reg': 0.2635260496428353, 'random_strength': 0.708745282530663, 'bagging_temperature': 6.247926615645069, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 18, 'max_ctr_complexity': 4, 'one_hot_max_size': 207}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2025-03-18 01:02:12,515] Trial 1 finished with value: 0.80448533640023 and parameters: {'iterations': 1311, 'depth': 8, 'learning_rate': 0.04899101154971915, 'l2_leaf_reg': 1.6339854346256972, 'random_strength': 0.12349787957859795, 'bagging_temperature': 5.9505170284604585, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 8, 'max_ctr_complexity': 4, 'one_hot_max_size': 120}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2025-03-18 01:02:12,639] Trial 7 finished with value: 0.8102357676825762 and parameters: {'iterations': 1435, 'depth': 6, 'learning_rate': 0.048839091331432154, 'l2_leaf_reg': 0.4030563215912184, 'random_strength': 6.6617293073404715, 'bagging_temperature': 9.663597908302815, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'max_ctr_complexity': 3, 'one_hot_max_size': 58}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2025-03-18 01:02:14,046] Trial 3 finished with value: 0.8039102932719954 and parameters: {'iterations': 1452, 'depth': 10, 'learning_rate': 0.04933996856761202, 'l2_leaf_reg': 1.0509272724524878, 'random_strength': 1.5362675833566783, 'bagging_temperature': 3.3130579435121423, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 17, 'max_ctr_complexity': 4, 'one_hot_max_size': 68}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2025-03-18 01:02:20,513] Trial 13 finished with value: 0.8062104657849338 and parameters: {'iterations': 1685, 'depth': 7, 'learning_rate': 0.08132035272664874, 'l2_leaf_reg': 0.4695373075156839, 'random_strength': 1.2541341494815357, 'bagging_temperature': 7.645426431007785, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'max_ctr_complexity': 2, 'one_hot_max_size': 186}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2025-03-18 01:02:22,676] Trial 4 finished with value: 0.8079355951696378 and parameters: {'iterations': 1953, 'depth': 6, 'learning_rate': 0.01879288642197906, 'l2_leaf_reg': 0.14495589546527257, 'random_strength': 1.4324020545445237, 'bagging_temperature': 9.158852218616893, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 14, 'max_ctr_complexity': 2, 'one_hot_max_size': 147}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2025-03-18 01:02:25,629] Trial 2 finished with value: 0.8125359401955147 and parameters: {'iterations': 1959, 'depth': 8, 'learning_rate': 0.019588542034024003, 'l2_leaf_reg': 2.69522416946727, 'random_strength': 0.3737165030294439, 'bagging_temperature': 1.8010549749686922, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 60}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:02:27,443] Trial 14 finished with value: 0.8113858539390454 and parameters: {'iterations': 1868, 'depth': 9, 'learning_rate': 0.05023578454897864, 'l2_leaf_reg': 0.6771127335467871, 'random_strength': 0.5640598565768827, 'bagging_temperature': 2.424068380149353, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 13, 'max_ctr_complexity': 4, 'one_hot_max_size': 47}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:02:28,664] Trial 15 finished with value: 0.8039102932719954 and parameters: {'iterations': 1123, 'depth': 8, 'learning_rate': 0.028977437919125663, 'l2_leaf_reg': 0.12413921328369863, 'random_strength': 0.5041586329656028, 'bagging_temperature': 7.45322062799153, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_ctr_complexity': 2, 'one_hot_max_size': 55}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:02:29,901] Trial 9 finished with value: 0.81196089706728 and parameters: {'iterations': 1036, 'depth': 9, 'learning_rate': 0.02035111545786458, 'l2_leaf_reg': 0.4213398287125378, 'random_strength': 0.3442845368668623, 'bagging_temperature': 3.68055146870837, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 1, 'one_hot_max_size': 227}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:02:32,625] Trial 5 finished with value: 0.8056354226566993 and parameters: {'iterations': 1215, 'depth': 8, 'learning_rate': 0.034261103785458685, 'l2_leaf_reg': 2.016686814052418, 'random_strength': 0.11022687677143794, 'bagging_temperature': 9.228331642703578, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 2, 'max_ctr_complexity': 4, 'one_hot_max_size': 13}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:02:33,722] Trial 17 finished with value: 0.8062104657849338 and parameters: {'iterations': 1918, 'depth': 9, 'learning_rate': 0.03684964738306291, 'l2_leaf_reg': 0.8544235811218823, 'random_strength': 0.20121351967763706, 'bagging_temperature': 2.928719499217774, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 12, 'max_ctr_complexity': 1, 'one_hot_max_size': 100}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:02:45,151] Trial 8 finished with value: 0.8090856814261069 and parameters: {'iterations': 1288, 'depth': 8, 'learning_rate': 0.016789452161676068, 'l2_leaf_reg': 0.9435283568201989, 'random_strength': 8.086369646106967, 'bagging_temperature': 3.3188193855509613, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'max_ctr_complexity': 3, 'one_hot_max_size': 185}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:02:48,013] Trial 11 finished with value: 0.8079355951696378 and parameters: {'iterations': 866, 'depth': 8, 'learning_rate': 0.0100244803261411, 'l2_leaf_reg': 0.26131168792218623, 'random_strength': 1.5692031573218046, 'bagging_temperature': 3.7824357415984036, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 11, 'max_ctr_complexity': 3, 'one_hot_max_size': 101}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:02:52,333] Trial 16 finished with value: 0.7998849913743531 and parameters: {'iterations': 1689, 'depth': 10, 'learning_rate': 0.01702780713361625, 'l2_leaf_reg': 1.0234512226724108, 'random_strength': 3.3762289212763905, 'bagging_temperature': 7.996351180840228, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 18, 'max_ctr_complexity': 3, 'one_hot_max_size': 53}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:02:58,810] Trial 19 finished with value: 0.8090856814261069 and parameters: {'iterations': 1694, 'depth': 8, 'learning_rate': 0.025364995176174982, 'l2_leaf_reg': 7.133299590479848, 'random_strength': 3.674839350808195, 'bagging_temperature': 8.814400881052084, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 10}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:03:03,729] Trial 12 finished with value: 0.8050603795284647 and parameters: {'iterations': 1262, 'depth': 9, 'learning_rate': 0.013124389688331293, 'l2_leaf_reg': 1.4755376067129828, 'random_strength': 2.633851149990536, 'bagging_temperature': 8.017746988823353, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 13, 'max_ctr_complexity': 3, 'one_hot_max_size': 10}. Best is trial 2 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:03:08,522] Trial 20 finished with value: 0.8131109833237493 and parameters: {'iterations': 1704, 'depth': 10, 'learning_rate': 0.011639746087991147, 'l2_leaf_reg': 3.448930519559347, 'random_strength': 0.13451429105999196, 'bagging_temperature': 1.2923043041650635, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 3, 'one_hot_max_size': 108}. Best is trial 20 with value: 0.8131109833237493.\n",
      "[I 2025-03-18 01:03:11,960] Trial 27 finished with value: 0.8125359401955147 and parameters: {'iterations': 860, 'depth': 9, 'learning_rate': 0.023355626673829514, 'l2_leaf_reg': 4.649927822543478, 'random_strength': 0.23013273386931438, 'bagging_temperature': 1.0656160452276349, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 247}. Best is trial 20 with value: 0.8131109833237493.\n",
      "[I 2025-03-18 01:03:16,691] Trial 26 finished with value: 0.8171362852213916 and parameters: {'iterations': 932, 'depth': 10, 'learning_rate': 0.019851755966495216, 'l2_leaf_reg': 7.474036390515991, 'random_strength': 0.24003802875065552, 'bagging_temperature': 1.1271766166716612, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 247}. Best is trial 26 with value: 0.8171362852213916.\n",
      "[I 2025-03-18 01:03:18,659] Trial 22 finished with value: 0.8096607245543416 and parameters: {'iterations': 840, 'depth': 10, 'learning_rate': 0.01068299363532172, 'l2_leaf_reg': 3.7087143517138044, 'random_strength': 0.18485435781782864, 'bagging_temperature': 3.8499815054646573, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 12}. Best is trial 26 with value: 0.8171362852213916.\n",
      "[I 2025-03-18 01:03:18,733] Trial 21 finished with value: 0.8142610695802185 and parameters: {'iterations': 1987, 'depth': 10, 'learning_rate': 0.010007401847390657, 'l2_leaf_reg': 3.090288046237025, 'random_strength': 0.19888174914872211, 'bagging_temperature': 1.1375547352545525, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 3, 'one_hot_max_size': 20}. Best is trial 26 with value: 0.8171362852213916.\n",
      "[I 2025-03-18 01:03:19,014] Trial 29 finished with value: 0.81943645773433 and parameters: {'iterations': 957, 'depth': 7, 'learning_rate': 0.022341665880888803, 'l2_leaf_reg': 3.535997573937274, 'random_strength': 0.29020788462819636, 'bagging_temperature': 1.0553916785367714, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 1, 'one_hot_max_size': 242}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:20,605] Trial 23 finished with value: 0.8154111558366878 and parameters: {'iterations': 806, 'depth': 10, 'learning_rate': 0.010093786469531227, 'l2_leaf_reg': 4.389422163764609, 'random_strength': 0.24402912282123188, 'bagging_temperature': 1.1274990500494395, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 236}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:24,063] Trial 24 finished with value: 0.8159861989649224 and parameters: {'iterations': 908, 'depth': 10, 'learning_rate': 0.010339726017406261, 'l2_leaf_reg': 4.645674722822038, 'random_strength': 0.2647384151203605, 'bagging_temperature': 1.072797975493338, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 3, 'one_hot_max_size': 247}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:28,357] Trial 18 finished with value: 0.8108108108108109 and parameters: {'iterations': 1277, 'depth': 8, 'learning_rate': 0.01296151790969615, 'l2_leaf_reg': 0.28850306424764594, 'random_strength': 0.8320458451985137, 'bagging_temperature': 6.740418071090852, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 8, 'max_ctr_complexity': 3, 'one_hot_max_size': 65}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:30,523] Trial 25 finished with value: 0.816561242093157 and parameters: {'iterations': 813, 'depth': 10, 'learning_rate': 0.010606207039818785, 'l2_leaf_reg': 4.502745465879035, 'random_strength': 0.2559456430873951, 'bagging_temperature': 1.011917619976127, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 3, 'one_hot_max_size': 255}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:36,572] Trial 28 finished with value: 0.8142610695802185 and parameters: {'iterations': 952, 'depth': 9, 'learning_rate': 0.01189212581888592, 'l2_leaf_reg': 3.698669043827027, 'random_strength': 0.28389955604203965, 'bagging_temperature': 1.095274119146311, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 255}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:38,201] Trial 30 finished with value: 0.8131109833237493 and parameters: {'iterations': 1819, 'depth': 7, 'learning_rate': 0.010398087914451041, 'l2_leaf_reg': 3.7034724276006545, 'random_strength': 0.22238794783084337, 'bagging_temperature': 1.0068157556638937, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'max_ctr_complexity': 4, 'one_hot_max_size': 157}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:45,847] Trial 35 finished with value: 0.8067855089131685 and parameters: {'iterations': 945, 'depth': 7, 'learning_rate': 0.014250443564226887, 'l2_leaf_reg': 9.31871390429051, 'random_strength': 0.27132358592219435, 'bagging_temperature': 4.546721590451934, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'max_ctr_complexity': 2, 'one_hot_max_size': 156}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:46,930] Trial 31 finished with value: 0.8171362852213916 and parameters: {'iterations': 1832, 'depth': 10, 'learning_rate': 0.012853567751055098, 'l2_leaf_reg': 3.724464418013127, 'random_strength': 0.2507129605332593, 'bagging_temperature': 1.23561453665741, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 3, 'one_hot_max_size': 147}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:48,576] Trial 36 finished with value: 0.8085106382978723 and parameters: {'iterations': 983, 'depth': 7, 'learning_rate': 0.014140002929902477, 'l2_leaf_reg': 9.758765311338603, 'random_strength': 0.8695092141217267, 'bagging_temperature': 4.683162538549599, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'max_ctr_complexity': 1, 'one_hot_max_size': 253}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:49,797] Trial 37 finished with value: 0.8090856814261069 and parameters: {'iterations': 975, 'depth': 7, 'learning_rate': 0.014582750344628415, 'l2_leaf_reg': 9.101419800085658, 'random_strength': 0.8520575101579111, 'bagging_temperature': 2.061992297193245, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'max_ctr_complexity': 2, 'one_hot_max_size': 255}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:49,952] Trial 33 finished with value: 0.8136860264519838 and parameters: {'iterations': 1818, 'depth': 10, 'learning_rate': 0.01359796512837003, 'l2_leaf_reg': 3.245758347145595, 'random_strength': 0.2929377992225595, 'bagging_temperature': 1.1971021034625005, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 17, 'max_ctr_complexity': 3, 'one_hot_max_size': 159}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:51,467] Trial 32 finished with value: 0.8102357676825762 and parameters: {'iterations': 1829, 'depth': 10, 'learning_rate': 0.013706942913396468, 'l2_leaf_reg': 3.4529006028623996, 'random_strength': 0.23019667012532244, 'bagging_temperature': 1.430152084522192, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'max_ctr_complexity': 3, 'one_hot_max_size': 146}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:53,779] Trial 38 finished with value: 0.81196089706728 and parameters: {'iterations': 970, 'depth': 7, 'learning_rate': 0.014740015878112715, 'l2_leaf_reg': 5.827007914721598, 'random_strength': 0.3119207264032954, 'bagging_temperature': 2.168216931926072, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'max_ctr_complexity': 2, 'one_hot_max_size': 254}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:03:58,212] Trial 39 finished with value: 0.8079355951696378 and parameters: {'iterations': 985, 'depth': 7, 'learning_rate': 0.014149073438967022, 'l2_leaf_reg': 8.346545448779727, 'random_strength': 0.8102980298092605, 'bagging_temperature': 4.57705491760174, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'max_ctr_complexity': 2, 'one_hot_max_size': 219}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:00,713] Trial 34 finished with value: 0.8154111558366878 and parameters: {'iterations': 1821, 'depth': 10, 'learning_rate': 0.013058645586481657, 'l2_leaf_reg': 9.33329994062437, 'random_strength': 0.15392525927141673, 'bagging_temperature': 1.095021236912986, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'max_ctr_complexity': 3, 'one_hot_max_size': 159}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:02,094] Trial 41 finished with value: 0.81196089706728 and parameters: {'iterations': 955, 'depth': 7, 'learning_rate': 0.015015016365293643, 'l2_leaf_reg': 9.378004262223351, 'random_strength': 0.6610494477355479, 'bagging_temperature': 2.20251096015471, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 18, 'max_ctr_complexity': 2, 'one_hot_max_size': 222}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:04,997] Trial 40 finished with value: 0.8073605520414031 and parameters: {'iterations': 1016, 'depth': 7, 'learning_rate': 0.014806927888745009, 'l2_leaf_reg': 9.121263677746777, 'random_strength': 0.67972457802467, 'bagging_temperature': 4.553420855147451, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'max_ctr_complexity': 2, 'one_hot_max_size': 221}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:13,462] Trial 48 finished with value: 0.8142610695802185 and parameters: {'iterations': 1100, 'depth': 6, 'learning_rate': 0.023903137884985784, 'l2_leaf_reg': 2.278453056687258, 'random_strength': 0.13783957852622106, 'bagging_temperature': 2.630460701836308, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 18, 'max_ctr_complexity': 2, 'one_hot_max_size': 215}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:13,689] Trial 45 finished with value: 0.81196089706728 and parameters: {'iterations': 1574, 'depth': 10, 'learning_rate': 0.023895802076787077, 'l2_leaf_reg': 5.919169493673804, 'random_strength': 0.1494065773714141, 'bagging_temperature': 1.9005082840557108, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 18, 'max_ctr_complexity': 2, 'one_hot_max_size': 215}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:13,896] Trial 49 finished with value: 0.8125359401955147 and parameters: {'iterations': 1095, 'depth': 6, 'learning_rate': 0.022280430654916823, 'l2_leaf_reg': 2.150495826957571, 'random_strength': 0.14391202118764085, 'bagging_temperature': 2.648128305718876, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 18, 'max_ctr_complexity': 4, 'one_hot_max_size': 212}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:16,014] Trial 46 finished with value: 0.8113858539390454 and parameters: {'iterations': 1566, 'depth': 10, 'learning_rate': 0.022132424682888025, 'l2_leaf_reg': 6.014710955083783, 'random_strength': 0.14622972528800182, 'bagging_temperature': 1.881063701918959, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 18, 'max_ctr_complexity': 2, 'one_hot_max_size': 217}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:18,753] Trial 47 finished with value: 0.8148361127084531 and parameters: {'iterations': 1518, 'depth': 9, 'learning_rate': 0.021445805785467682, 'l2_leaf_reg': 2.0199858431758315, 'random_strength': 0.15518468390289908, 'bagging_temperature': 2.000684799659397, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 18, 'max_ctr_complexity': 2, 'one_hot_max_size': 220}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:19,234] Trial 50 finished with value: 0.8136860264519838 and parameters: {'iterations': 1368, 'depth': 6, 'learning_rate': 0.021745712612892678, 'l2_leaf_reg': 2.3520003367027735, 'random_strength': 0.10026142810916365, 'bagging_temperature': 2.6401173612401614, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 18, 'max_ctr_complexity': 4, 'one_hot_max_size': 211}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:23,956] Trial 44 finished with value: 0.8073605520414031 and parameters: {'iterations': 1544, 'depth': 10, 'learning_rate': 0.016487585907002833, 'l2_leaf_reg': 6.0625930824891405, 'random_strength': 0.148242414125048, 'bagging_temperature': 2.0544788597251933, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 18, 'max_ctr_complexity': 2, 'one_hot_max_size': 214}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:24,061] Trial 42 finished with value: 0.81196089706728 and parameters: {'iterations': 1032, 'depth': 10, 'learning_rate': 0.015538342760029583, 'l2_leaf_reg': 5.823773467910009, 'random_strength': 0.14848941424536174, 'bagging_temperature': 1.9398283251676265, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 18, 'max_ctr_complexity': 2, 'one_hot_max_size': 218}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:29,937] Trial 52 finished with value: 0.8159861989649224 and parameters: {'iterations': 1131, 'depth': 10, 'learning_rate': 0.021910862043875247, 'l2_leaf_reg': 2.2560922496411617, 'random_strength': 0.38855436753299927, 'bagging_temperature': 1.6803667438799441, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 18, 'max_ctr_complexity': 4, 'one_hot_max_size': 208}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:31,466] Trial 51 finished with value: 0.8125359401955147 and parameters: {'iterations': 1107, 'depth': 10, 'learning_rate': 0.021837725309414066, 'l2_leaf_reg': 2.311611210559119, 'random_strength': 0.3857080341021614, 'bagging_temperature': 1.7124969841775026, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 18, 'max_ctr_complexity': 4, 'one_hot_max_size': 207}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:32,735] Trial 43 finished with value: 0.8090856814261069 and parameters: {'iterations': 1039, 'depth': 10, 'learning_rate': 0.014851384481431465, 'l2_leaf_reg': 6.845710021989479, 'random_strength': 0.15152307599063633, 'bagging_temperature': 2.10386684503616, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 18, 'max_ctr_complexity': 2, 'one_hot_max_size': 219}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:42,293] Trial 56 finished with value: 0.8102357676825762 and parameters: {'iterations': 896, 'depth': 9, 'learning_rate': 0.017401994094396498, 'l2_leaf_reg': 4.859464381635169, 'random_strength': 0.3936245656326728, 'bagging_temperature': 1.66083715006621, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 3, 'one_hot_max_size': 234}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:44,924] Trial 54 finished with value: 0.80448533640023 and parameters: {'iterations': 1146, 'depth': 10, 'learning_rate': 0.019145349760739814, 'l2_leaf_reg': 2.528410482886113, 'random_strength': 0.39970271906039345, 'bagging_temperature': 1.670353389761439, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 19, 'max_ctr_complexity': 4, 'one_hot_max_size': 231}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:46,125] Trial 58 finished with value: 0.81196089706728 and parameters: {'iterations': 901, 'depth': 10, 'learning_rate': 0.01813022996545945, 'l2_leaf_reg': 1.528607667448916, 'random_strength': 0.37968170000409424, 'bagging_temperature': 1.5780255644612382, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 3, 'one_hot_max_size': 236}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:52,788] Trial 60 finished with value: 0.8113858539390454 and parameters: {'iterations': 893, 'depth': 9, 'learning_rate': 0.01764064212181234, 'l2_leaf_reg': 1.4232394554434218, 'random_strength': 0.43019343452358466, 'bagging_temperature': 1.6075771924562179, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 3, 'one_hot_max_size': 199}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:53,368] Trial 55 finished with value: 0.8113858539390454 and parameters: {'iterations': 893, 'depth': 10, 'learning_rate': 0.01761852522338039, 'l2_leaf_reg': 1.5775220486425938, 'random_strength': 0.1099945118966361, 'bagging_temperature': 1.645427810834684, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 3, 'one_hot_max_size': 237}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:53,738] Trial 53 finished with value: 0.8090856814261069 and parameters: {'iterations': 1533, 'depth': 10, 'learning_rate': 0.020901256728413645, 'l2_leaf_reg': 5.826374111730443, 'random_strength': 0.42074824622735785, 'bagging_temperature': 1.8567881718584185, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 19, 'max_ctr_complexity': 4, 'one_hot_max_size': 238}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:56,359] Trial 59 finished with value: 0.816561242093157 and parameters: {'iterations': 912, 'depth': 9, 'learning_rate': 0.018360211197364487, 'l2_leaf_reg': 1.7069687358449102, 'random_strength': 0.40119212296518303, 'bagging_temperature': 1.6081267159423316, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 3, 'one_hot_max_size': 240}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:04:59,009] Trial 62 finished with value: 0.81196089706728 and parameters: {'iterations': 800, 'depth': 9, 'learning_rate': 0.019055529733815402, 'l2_leaf_reg': 1.5283971201177273, 'random_strength': 0.4372641134706595, 'bagging_temperature': 1.5141185487083688, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 3, 'one_hot_max_size': 239}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:00,735] Trial 61 finished with value: 0.8171362852213916 and parameters: {'iterations': 890, 'depth': 9, 'learning_rate': 0.018553725367641827, 'l2_leaf_reg': 1.502636391950323, 'random_strength': 0.402233009886217, 'bagging_temperature': 1.5242261576962302, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 4, 'one_hot_max_size': 238}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:03,691] Trial 63 finished with value: 0.8142610695802185 and parameters: {'iterations': 902, 'depth': 9, 'learning_rate': 0.01878568554991498, 'l2_leaf_reg': 1.4085329738836032, 'random_strength': 0.3698341778085273, 'bagging_temperature': 1.6053015648455073, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 3, 'one_hot_max_size': 238}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:05,680] Trial 64 finished with value: 0.8148361127084531 and parameters: {'iterations': 883, 'depth': 9, 'learning_rate': 0.019110681108082762, 'l2_leaf_reg': 1.4016528899792575, 'random_strength': 0.3543221653373605, 'bagging_temperature': 1.4866863719601775, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 3, 'one_hot_max_size': 239}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:05,783] Trial 65 finished with value: 0.8125359401955147 and parameters: {'iterations': 896, 'depth': 9, 'learning_rate': 0.030175574423225063, 'l2_leaf_reg': 1.5324479901911812, 'random_strength': 0.5111657568102915, 'bagging_temperature': 3.1373698602885383, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 3, 'one_hot_max_size': 241}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:06,502] Trial 57 finished with value: 0.8085106382978723 and parameters: {'iterations': 1381, 'depth': 10, 'learning_rate': 0.018254315180751005, 'l2_leaf_reg': 5.144694354174899, 'random_strength': 0.37352542250979515, 'bagging_temperature': 1.612714103664752, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 19, 'max_ctr_complexity': 3, 'one_hot_max_size': 198}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:16,362] Trial 68 finished with value: 0.81196089706728 and parameters: {'iterations': 826, 'depth': 9, 'learning_rate': 0.028307387950486256, 'l2_leaf_reg': 2.8593117282682203, 'random_strength': 0.5068120607444039, 'bagging_temperature': 3.106588253192859, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 9, 'max_ctr_complexity': 4, 'one_hot_max_size': 177}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:17,351] Trial 67 finished with value: 0.8096607245543416 and parameters: {'iterations': 1181, 'depth': 9, 'learning_rate': 0.02835941706932172, 'l2_leaf_reg': 2.813722475054682, 'random_strength': 0.5376692264783401, 'bagging_temperature': 3.1404978183586585, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 9, 'max_ctr_complexity': 3, 'one_hot_max_size': 243}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:21,239] Trial 70 finished with value: 0.8136860264519838 and parameters: {'iterations': 805, 'depth': 9, 'learning_rate': 0.02784931236892399, 'l2_leaf_reg': 2.8769482170073357, 'random_strength': 0.5297645059958047, 'bagging_temperature': 2.3866460308453314, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 17, 'max_ctr_complexity': 3, 'one_hot_max_size': 172}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:21,580] Trial 72 finished with value: 0.8085106382978723 and parameters: {'iterations': 849, 'depth': 8, 'learning_rate': 0.028529336417915465, 'l2_leaf_reg': 2.855145501279936, 'random_strength': 0.5058970849051805, 'bagging_temperature': 3.1247707302253818, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 9, 'max_ctr_complexity': 3, 'one_hot_max_size': 246}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:22,699] Trial 66 finished with value: 0.8136860264519838 and parameters: {'iterations': 1180, 'depth': 9, 'learning_rate': 0.02912096910175775, 'l2_leaf_reg': 1.8159489605120367, 'random_strength': 0.5484565294651517, 'bagging_temperature': 2.8980657682074744, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 3, 'max_ctr_complexity': 3, 'one_hot_max_size': 199}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:22,821] Trial 69 finished with value: 0.8142610695802185 and parameters: {'iterations': 803, 'depth': 9, 'learning_rate': 0.027281862855107673, 'l2_leaf_reg': 2.780384778367175, 'random_strength': 0.5379302347426889, 'bagging_temperature': 3.305983647230839, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 14, 'max_ctr_complexity': 1, 'one_hot_max_size': 178}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:23,670] Trial 73 finished with value: 0.8108108108108109 and parameters: {'iterations': 852, 'depth': 8, 'learning_rate': 0.02667160508799149, 'l2_leaf_reg': 0.7087364482071057, 'random_strength': 0.5268936653981845, 'bagging_temperature': 3.0200824193186406, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 17, 'max_ctr_complexity': 3, 'one_hot_max_size': 80}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:25,543] Trial 71 finished with value: 0.8148361127084531 and parameters: {'iterations': 1191, 'depth': 9, 'learning_rate': 0.027800239785815015, 'l2_leaf_reg': 2.7870894645815096, 'random_strength': 0.3363476367892879, 'bagging_temperature': 3.011332862997965, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'max_ctr_complexity': 3, 'one_hot_max_size': 175}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:44,219] Trial 78 finished with value: 0.8154111558366878 and parameters: {'iterations': 840, 'depth': 8, 'learning_rate': 0.01206490822504738, 'l2_leaf_reg': 0.730841378666316, 'random_strength': 0.18192147916746063, 'bagging_temperature': 1.2841728885962143, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 17, 'max_ctr_complexity': 1, 'one_hot_max_size': 79}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:44,319] Trial 76 finished with value: 0.8125359401955147 and parameters: {'iterations': 816, 'depth': 8, 'learning_rate': 0.011746882032933142, 'l2_leaf_reg': 2.956070055421727, 'random_strength': 0.1956563943975213, 'bagging_temperature': 2.4064852766936267, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 5, 'max_ctr_complexity': 1, 'one_hot_max_size': 247}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:48,006] Trial 74 finished with value: 0.8050603795284647 and parameters: {'iterations': 836, 'depth': 8, 'learning_rate': 0.012093278511470037, 'l2_leaf_reg': 1.1604219694480669, 'random_strength': 0.5299842728940236, 'bagging_temperature': 3.2614650784438908, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 4, 'max_ctr_complexity': 1, 'one_hot_max_size': 78}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:48,086] Trial 75 finished with value: 0.8079355951696378 and parameters: {'iterations': 857, 'depth': 8, 'learning_rate': 0.011847004749282712, 'l2_leaf_reg': 1.1796614760219957, 'random_strength': 0.17779063526095815, 'bagging_temperature': 2.4271817702217153, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 4, 'max_ctr_complexity': 1, 'one_hot_max_size': 171}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:49,522] Trial 79 finished with value: 0.8113858539390454 and parameters: {'iterations': 848, 'depth': 8, 'learning_rate': 0.011703592011785186, 'l2_leaf_reg': 1.7896740733544578, 'random_strength': 0.19432606416330914, 'bagging_temperature': 1.34719477297059, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 82}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:51,083] Trial 82 finished with value: 0.8131109833237493 and parameters: {'iterations': 1062, 'depth': 8, 'learning_rate': 0.011177182036745819, 'l2_leaf_reg': 3.886550553009818, 'random_strength': 0.18019117302263218, 'bagging_temperature': 1.2198109700786364, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 129}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:52,789] Trial 81 finished with value: 0.8136860264519838 and parameters: {'iterations': 934, 'depth': 8, 'learning_rate': 0.011555025849472163, 'l2_leaf_reg': 3.940795273259299, 'random_strength': 0.2658976393230849, 'bagging_temperature': 1.3126723964407976, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 128}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:05:57,662] Trial 83 finished with value: 0.8154111558366878 and parameters: {'iterations': 1069, 'depth': 10, 'learning_rate': 0.011463427089920618, 'l2_leaf_reg': 1.1946945212600355, 'random_strength': 0.1793648697593429, 'bagging_temperature': 1.3871582548465113, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 227}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:03,091] Trial 84 finished with value: 0.8131109833237493 and parameters: {'iterations': 934, 'depth': 10, 'learning_rate': 0.011150900224878975, 'l2_leaf_reg': 1.2394086411647067, 'random_strength': 0.18252347168799832, 'bagging_temperature': 1.318226653573448, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 133}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:05,018] Trial 80 finished with value: 0.8085106382978723 and parameters: {'iterations': 1631, 'depth': 8, 'learning_rate': 0.011825656122034605, 'l2_leaf_reg': 1.1841767336758224, 'random_strength': 0.18315703713448647, 'bagging_temperature': 5.827093934525241, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'max_ctr_complexity': 1, 'one_hot_max_size': 84}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:05,574] Trial 88 finished with value: 0.8177113283496262 and parameters: {'iterations': 1066, 'depth': 10, 'learning_rate': 0.034067870139364735, 'l2_leaf_reg': 3.870324423282911, 'random_strength': 0.27097933931970297, 'bagging_temperature': 1.3377230564797766, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 126}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:08,317] Trial 91 finished with value: 0.8177113283496262 and parameters: {'iterations': 931, 'depth': 10, 'learning_rate': 0.035280672870858336, 'l2_leaf_reg': 4.366390510138094, 'random_strength': 0.2520928009298228, 'bagging_temperature': 1.0301430709912607, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 228}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:09,472] Trial 85 finished with value: 0.8085106382978723 and parameters: {'iterations': 1052, 'depth': 10, 'learning_rate': 0.033287800719048286, 'l2_leaf_reg': 4.1558543444531075, 'random_strength': 0.2632256935579306, 'bagging_temperature': 5.650539789070809, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 228}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:09,914] Trial 87 finished with value: 0.8062104657849338 and parameters: {'iterations': 927, 'depth': 10, 'learning_rate': 0.03712035223608599, 'l2_leaf_reg': 4.058932181574247, 'random_strength': 0.2552102843100096, 'bagging_temperature': 6.063884136986077, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 228}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:13,219] Trial 89 finished with value: 0.8062104657849338 and parameters: {'iterations': 940, 'depth': 10, 'learning_rate': 0.034286981482085886, 'l2_leaf_reg': 4.170910918597428, 'random_strength': 0.26193689477414694, 'bagging_temperature': 6.669186458309207, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 121}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:14,594] Trial 86 finished with value: 0.816561242093157 and parameters: {'iterations': 1061, 'depth': 10, 'learning_rate': 0.016365490037502727, 'l2_leaf_reg': 7.237979181101352, 'random_strength': 0.2602299010917839, 'bagging_temperature': 1.0003801004634603, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 126}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:17,419] Trial 93 finished with value: 0.8154111558366878 and parameters: {'iterations': 997, 'depth': 10, 'learning_rate': 0.0342372158422798, 'l2_leaf_reg': 4.46896331450639, 'random_strength': 0.26006612198009704, 'bagging_temperature': 1.0069423429832995, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 228}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:18,109] Trial 94 finished with value: 0.8125359401955147 and parameters: {'iterations': 1005, 'depth': 10, 'learning_rate': 0.03716728019310161, 'l2_leaf_reg': 4.220042911146239, 'random_strength': 0.24577500213173192, 'bagging_temperature': 1.0525376342215613, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 15, 'max_ctr_complexity': 1, 'one_hot_max_size': 230}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:18,170] Trial 95 finished with value: 0.8113858539390454 and parameters: {'iterations': 926, 'depth': 10, 'learning_rate': 0.038118628457466726, 'l2_leaf_reg': 4.177835009834097, 'random_strength': 0.30881350748694025, 'bagging_temperature': 1.0099557560194468, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 4, 'one_hot_max_size': 249}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:20,619] Trial 98 finished with value: 0.8125359401955147 and parameters: {'iterations': 1011, 'depth': 10, 'learning_rate': 0.043434670702158756, 'l2_leaf_reg': 7.3847331027250345, 'random_strength': 0.30427551970346595, 'bagging_temperature': 1.1944169269821923, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 112}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:21,886] Trial 77 finished with value: 0.8113858539390454 and parameters: {'iterations': 1185, 'depth': 8, 'learning_rate': 0.011461728206667843, 'l2_leaf_reg': 4.112797761305142, 'random_strength': 0.18032827730790377, 'bagging_temperature': 6.303282829122385, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 3, 'max_ctr_complexity': 1, 'one_hot_max_size': 246}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:21,979] Trial 96 finished with value: 0.8188614146060954 and parameters: {'iterations': 1020, 'depth': 10, 'learning_rate': 0.03909677825624616, 'l2_leaf_reg': 7.049055349548455, 'random_strength': 0.24367610722460617, 'bagging_temperature': 1.0394324867008726, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 251}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:22,227] Trial 97 finished with value: 0.8188614146060954 and parameters: {'iterations': 1011, 'depth': 10, 'learning_rate': 0.03609434665821003, 'l2_leaf_reg': 4.954640830314437, 'random_strength': 0.31098790351436767, 'bagging_temperature': 1.0037437900941228, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 250}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:23,963] Trial 99 finished with value: 0.8125359401955147 and parameters: {'iterations': 1001, 'depth': 10, 'learning_rate': 0.04173171022140051, 'l2_leaf_reg': 5.2934049082623424, 'random_strength': 0.2199194375768396, 'bagging_temperature': 1.050103995148313, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 17, 'max_ctr_complexity': 1, 'one_hot_max_size': 248}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:26,512] Trial 90 finished with value: 0.8062104657849338 and parameters: {'iterations': 936, 'depth': 10, 'learning_rate': 0.012749371707155902, 'l2_leaf_reg': 4.067074569822585, 'random_strength': 0.2513522610887736, 'bagging_temperature': 5.1749911917972256, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 15, 'max_ctr_complexity': 4, 'one_hot_max_size': 227}. Best is trial 29 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:06:28,158] Trial 92 finished with value: 0.8108108108108109 and parameters: {'iterations': 930, 'depth': 10, 'learning_rate': 0.0160360874360856, 'l2_leaf_reg': 4.563371784972807, 'random_strength': 0.24538700762147073, 'bagging_temperature': 6.237652873636165, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 20, 'max_ctr_complexity': 1, 'one_hot_max_size': 227}. Best is trial 29 with value: 0.81943645773433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost parameters: {'iterations': 957, 'depth': 7, 'learning_rate': 0.022341665880888803, 'l2_leaf_reg': 3.535997573937274, 'random_strength': 0.29020788462819636, 'bagging_temperature': 1.0553916785367714, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'max_ctr_complexity': 1, 'one_hot_max_size': 242}\n",
      "0:\tlearn: 0.6774262\ttest: 0.6778540\tbest: 0.6778540 (0)\ttotal: 8.18ms\tremaining: 7.82s\n",
      "100:\tlearn: 0.3341943\ttest: 0.3967874\tbest: 0.3967874 (100)\ttotal: 730ms\tremaining: 6.18s\n",
      "200:\tlearn: 0.2890636\ttest: 0.3811185\tbest: 0.3811185 (200)\ttotal: 1.3s\tremaining: 4.88s\n",
      "300:\tlearn: 0.2608431\ttest: 0.3764918\tbest: 0.3764918 (300)\ttotal: 1.83s\tremaining: 3.98s\n",
      "400:\tlearn: 0.2381301\ttest: 0.3749353\tbest: 0.3748907 (392)\ttotal: 2.34s\tremaining: 3.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:06:30,780] A new study created in memory with name: no-name-efaa3109-94b1-4335-89fd-533e0d18097f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3748906976\n",
      "bestIteration = 392\n",
      "\n",
      "Shrink model to first 393 iterations.\n",
      "Best accuracy: 0.8154 with threshold: 0.5051\n",
      "Best CatBoost validation accuracy: 0.8154\n",
      "\n",
      "==== Tuning XGBoost (11 parallel jobs) ====\n",
      "Tuning XGBoost with 11 threads\n",
      "Tuning XGBoost with 11 threads\n",
      "Converted 34 columns to category type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:06:31,564] Trial 0 finished with value: 0.8148361127084531 and parameters: {'max_depth': 8, 'learning_rate': 0.1143425657658826, 'n_estimators': 262, 'min_child_weight': 10, 'gamma': 0.015107248194741468, 'subsample': 0.6935661716835746, 'colsample_bytree': 0.7727690903657685, 'reg_alpha': 0.07245536017510983, 'reg_lambda': 3.652383230046436}. Best is trial 0 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:06:32,144] Trial 1 finished with value: 0.8171362852213916 and parameters: {'max_depth': 5, 'learning_rate': 0.2791771850108593, 'n_estimators': 300, 'min_child_weight': 6, 'gamma': 0.21122209509177872, 'subsample': 0.7593950629476459, 'colsample_bytree': 0.7683561460433963, 'reg_alpha': 0.08375060664163476, 'reg_lambda': 0.04961943302700498}. Best is trial 1 with value: 0.8171362852213916.\n",
      "[I 2025-03-18 01:06:33,777] Trial 2 finished with value: 0.8188614146060954 and parameters: {'max_depth': 6, 'learning_rate': 0.019228891306406464, 'n_estimators': 646, 'min_child_weight': 3, 'gamma': 0.030827123919548585, 'subsample': 0.7974806309873732, 'colsample_bytree': 0.8593240235268484, 'reg_alpha': 2.056303719835737, 'reg_lambda': 0.11869121303887024}. Best is trial 2 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:06:36,339] Trial 3 finished with value: 0.8205865439907993 and parameters: {'max_depth': 9, 'learning_rate': 0.05357100268085469, 'n_estimators': 803, 'min_child_weight': 9, 'gamma': 0.10946126181909858, 'subsample': 0.7748991547513229, 'colsample_bytree': 0.8433518348278376, 'reg_alpha': 0.022384130463132697, 'reg_lambda': 0.051783434797379846}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:36,595] Trial 4 finished with value: 0.8113858539390454 and parameters: {'max_depth': 3, 'learning_rate': 0.052459638740563225, 'n_estimators': 195, 'min_child_weight': 4, 'gamma': 0.13325941581707726, 'subsample': 0.8135266383470748, 'colsample_bytree': 0.5316685217567565, 'reg_alpha': 0.6568046078603291, 'reg_lambda': 0.010571239525693416}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:37,194] Trial 5 finished with value: 0.8125359401955147 and parameters: {'max_depth': 3, 'learning_rate': 0.08616594636335095, 'n_estimators': 467, 'min_child_weight': 8, 'gamma': 0.15943858336762748, 'subsample': 0.8708949979429559, 'colsample_bytree': 0.9929509497020934, 'reg_alpha': 0.4383924663863728, 'reg_lambda': 0.019574839890077838}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:38,536] Trial 6 finished with value: 0.81196089706728 and parameters: {'max_depth': 8, 'learning_rate': 0.022607920377585855, 'n_estimators': 465, 'min_child_weight': 3, 'gamma': 0.2967593213533174, 'subsample': 0.737390997746907, 'colsample_bytree': 0.6412879864641501, 'reg_alpha': 8.424186543762511, 'reg_lambda': 0.013664301348048451}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:39,785] Trial 7 finished with value: 0.8131109833237493 and parameters: {'max_depth': 3, 'learning_rate': 0.01210855456356074, 'n_estimators': 996, 'min_child_weight': 3, 'gamma': 0.0737629783226516, 'subsample': 0.6697715311800629, 'colsample_bytree': 0.8959107384333396, 'reg_alpha': 0.019932048609322604, 'reg_lambda': 0.9283210433364629}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:41,679] Trial 8 finished with value: 0.8136860264519838 and parameters: {'max_depth': 7, 'learning_rate': 0.05221628057213062, 'n_estimators': 602, 'min_child_weight': 1, 'gamma': 0.0791709127998189, 'subsample': 0.5793165388897381, 'colsample_bytree': 0.7978780808109938, 'reg_alpha': 0.07420461177716604, 'reg_lambda': 1.3873730025425268}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:43,587] Trial 9 finished with value: 0.8154111558366878 and parameters: {'max_depth': 7, 'learning_rate': 0.017832042456834927, 'n_estimators': 705, 'min_child_weight': 9, 'gamma': 0.026404005765873956, 'subsample': 0.7163383958273155, 'colsample_bytree': 0.8829380893625856, 'reg_alpha': 0.08599898044429174, 'reg_lambda': 7.746431023236882}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:44,399] Trial 10 finished with value: 0.8148361127084531 and parameters: {'max_depth': 10, 'learning_rate': 0.19175210849544913, 'n_estimators': 904, 'min_child_weight': 7, 'gamma': 0.7920927813326739, 'subsample': 0.9512943818635395, 'colsample_bytree': 0.6070091098082269, 'reg_alpha': 0.014590119192221144, 'reg_lambda': 0.22634578371892508}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:47,637] Trial 11 finished with value: 0.8148361127084531 and parameters: {'max_depth': 10, 'learning_rate': 0.03039598684884887, 'n_estimators': 786, 'min_child_weight': 5, 'gamma': 0.04500902332635244, 'subsample': 0.8612208909453718, 'colsample_bytree': 0.8929479768864758, 'reg_alpha': 4.049107479003481, 'reg_lambda': 0.11412116967053462}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:49,264] Trial 12 finished with value: 0.8113858539390454 and parameters: {'max_depth': 5, 'learning_rate': 0.03691870214235933, 'n_estimators': 749, 'min_child_weight': 1, 'gamma': 0.03534975246010688, 'subsample': 0.5009374807852893, 'colsample_bytree': 0.9708231082395898, 'reg_alpha': 1.756123185472393, 'reg_lambda': 0.06963544728118988}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:50,425] Trial 13 finished with value: 0.8188614146060954 and parameters: {'max_depth': 5, 'learning_rate': 0.012759398807984419, 'n_estimators': 610, 'min_child_weight': 10, 'gamma': 0.011100060375395626, 'subsample': 0.9775718696162792, 'colsample_bytree': 0.6896509606954228, 'reg_alpha': 1.9041923167921138, 'reg_lambda': 0.3933844980753931}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:52,010] Trial 14 finished with value: 0.8177113283496262 and parameters: {'max_depth': 9, 'learning_rate': 0.09717205537039172, 'n_estimators': 843, 'min_child_weight': 3, 'gamma': 0.5344186451366729, 'subsample': 0.8118778672726482, 'colsample_bytree': 0.8109122308372405, 'reg_alpha': 0.2251700309670229, 'reg_lambda': 0.04484432588309778}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:54,032] Trial 15 finished with value: 0.8200115008625647 and parameters: {'max_depth': 8, 'learning_rate': 0.032303370187464785, 'n_estimators': 633, 'min_child_weight': 6, 'gamma': 0.02003288253128814, 'subsample': 0.6251289672262802, 'colsample_bytree': 0.8375166254640622, 'reg_alpha': 1.14467779363685, 'reg_lambda': 0.17236078527003612}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:55,353] Trial 16 finished with value: 0.8159861989649224 and parameters: {'max_depth': 9, 'learning_rate': 0.035912191145900045, 'n_estimators': 392, 'min_child_weight': 7, 'gamma': 0.06909751721681487, 'subsample': 0.6251003783386662, 'colsample_bytree': 0.7067946993151164, 'reg_alpha': 0.2202525568628054, 'reg_lambda': 0.3284745707812036}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:06:58,434] Trial 17 finished with value: 0.8142610695802185 and parameters: {'max_depth': 9, 'learning_rate': 0.0677807515457388, 'n_estimators': 929, 'min_child_weight': 7, 'gamma': 0.019246171991058304, 'subsample': 0.5965997079024488, 'colsample_bytree': 0.9403935933520693, 'reg_alpha': 0.030792084263796482, 'reg_lambda': 0.02605901586026784}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:07:00,008] Trial 18 finished with value: 0.8085106382978723 and parameters: {'max_depth': 8, 'learning_rate': 0.13212341343237913, 'n_estimators': 543, 'min_child_weight': 9, 'gamma': 0.30316807097951215, 'subsample': 0.5246636416660933, 'colsample_bytree': 0.8145277924272268, 'reg_alpha': 0.7101754118016695, 'reg_lambda': 0.6820430315623692}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:07:02,958] Trial 19 finished with value: 0.8102357676825762 and parameters: {'max_depth': 10, 'learning_rate': 0.044280197539843726, 'n_estimators': 813, 'min_child_weight': 5, 'gamma': 0.05114498566556289, 'subsample': 0.6585571072725885, 'colsample_bytree': 0.729474663648472, 'reg_alpha': 0.03302182196865458, 'reg_lambda': 0.14594245507153747}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:07:03,154] Trial 20 finished with value: 0.8200115008625647 and parameters: {'max_depth': 6, 'learning_rate': 0.07358331147188579, 'n_estimators': 64, 'min_child_weight': 8, 'gamma': 0.1224398625303137, 'subsample': 0.9071269931384623, 'colsample_bytree': 0.8425433940508855, 'reg_alpha': 1.0564422307057337, 'reg_lambda': 1.8111939167405744}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:07:03,451] Trial 21 finished with value: 0.8188614146060954 and parameters: {'max_depth': 6, 'learning_rate': 0.07044993718216505, 'n_estimators': 109, 'min_child_weight': 8, 'gamma': 0.1153168847642354, 'subsample': 0.9114443002468017, 'colsample_bytree': 0.8432628692281178, 'reg_alpha': 1.2312794282316706, 'reg_lambda': 2.22258358372722}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:07:05,344] Trial 22 finished with value: 0.8171362852213916 and parameters: {'max_depth': 7, 'learning_rate': 0.026624769497272736, 'n_estimators': 662, 'min_child_weight': 8, 'gamma': 0.18376957052272805, 'subsample': 0.9016035637034817, 'colsample_bytree': 0.9285267647808254, 'reg_alpha': 3.6773594832257817, 'reg_lambda': 0.5194411699614393}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:07:05,632] Trial 23 finished with value: 0.8131109833237493 and parameters: {'max_depth': 8, 'learning_rate': 0.07529848265607308, 'n_estimators': 73, 'min_child_weight': 6, 'gamma': 0.10132514542439534, 'subsample': 0.7643011587801205, 'colsample_bytree': 0.8453218901939856, 'reg_alpha': 0.8476469294711492, 'reg_lambda': 6.646189691659566}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:07:06,512] Trial 24 finished with value: 0.8085106382978723 and parameters: {'max_depth': 6, 'learning_rate': 0.14291160225581304, 'n_estimators': 378, 'min_child_weight': 9, 'gamma': 0.2797621190939845, 'subsample': 0.5529843197507017, 'colsample_bytree': 0.9177807318208611, 'reg_alpha': 0.38755840786963, 'reg_lambda': 0.21927720191779423}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:07:08,297] Trial 25 finished with value: 0.8159861989649224 and parameters: {'max_depth': 9, 'learning_rate': 0.04242217277620457, 'n_estimators': 530, 'min_child_weight': 8, 'gamma': 0.05804355942389143, 'subsample': 0.6304791983189362, 'colsample_bytree': 0.7493895581437781, 'reg_alpha': 3.6642552196211344, 'reg_lambda': 1.4449957795333095}. Best is trial 3 with value: 0.8205865439907993.\n",
      "[I 2025-03-18 01:07:09,212] Trial 26 finished with value: 0.8223116733755031 and parameters: {'max_depth': 4, 'learning_rate': 0.060718778305850145, 'n_estimators': 723, 'min_child_weight': 6, 'gamma': 0.42049914090308094, 'subsample': 0.9975270634728145, 'colsample_bytree': 0.841713010750031, 'reg_alpha': 0.20162243461831367, 'reg_lambda': 0.07197976001921806}. Best is trial 26 with value: 0.8223116733755031.\n",
      "[I 2025-03-18 01:07:10,048] Trial 27 finished with value: 0.8223116733755031 and parameters: {'max_depth': 4, 'learning_rate': 0.05919541167621511, 'n_estimators': 709, 'min_child_weight': 6, 'gamma': 0.5396530127309767, 'subsample': 0.996164577567688, 'colsample_bytree': 0.7929883224077955, 'reg_alpha': 0.16591285559127106, 'reg_lambda': 0.06712293116399354}. Best is trial 26 with value: 0.8223116733755031.\n",
      "[I 2025-03-18 01:07:10,949] Trial 28 finished with value: 0.8217366302472685 and parameters: {'max_depth': 4, 'learning_rate': 0.058539411600140236, 'n_estimators': 713, 'min_child_weight': 4, 'gamma': 0.5018217723698455, 'subsample': 0.9901130752785973, 'colsample_bytree': 0.666961121634345, 'reg_alpha': 0.13376007708575144, 'reg_lambda': 0.02877581989804386}. Best is trial 26 with value: 0.8223116733755031.\n",
      "[I 2025-03-18 01:07:11,762] Trial 29 finished with value: 0.8205865439907993 and parameters: {'max_depth': 4, 'learning_rate': 0.09708552947402414, 'n_estimators': 899, 'min_child_weight': 4, 'gamma': 0.49823009905730775, 'subsample': 0.9970554990017158, 'colsample_bytree': 0.6479695695319881, 'reg_alpha': 0.13552882591269527, 'reg_lambda': 0.029798618784257082}. Best is trial 26 with value: 0.8223116733755031.\n",
      "[I 2025-03-18 01:07:12,559] Trial 30 finished with value: 0.8217366302472685 and parameters: {'max_depth': 4, 'learning_rate': 0.059331076616665084, 'n_estimators': 704, 'min_child_weight': 4, 'gamma': 0.9802190715987675, 'subsample': 0.9508425622485992, 'colsample_bytree': 0.505810955476526, 'reg_alpha': 0.14289603609219814, 'reg_lambda': 0.07279745754053595}. Best is trial 26 with value: 0.8223116733755031.\n",
      "[I 2025-03-18 01:07:13,394] Trial 31 finished with value: 0.8188614146060954 and parameters: {'max_depth': 4, 'learning_rate': 0.05926506610693474, 'n_estimators': 731, 'min_child_weight': 4, 'gamma': 0.9337417547748996, 'subsample': 0.9503563648924739, 'colsample_bytree': 0.5366931466610805, 'reg_alpha': 0.17871017848888904, 'reg_lambda': 0.07635491982452618}. Best is trial 26 with value: 0.8223116733755031.\n",
      "[I 2025-03-18 01:07:14,392] Trial 32 finished with value: 0.8228867165037378 and parameters: {'max_depth': 4, 'learning_rate': 0.04571576787608944, 'n_estimators': 696, 'min_child_weight': 5, 'gamma': 0.5501976920626643, 'subsample': 0.9688769943161999, 'colsample_bytree': 0.5791617315089538, 'reg_alpha': 0.12476833956817632, 'reg_lambda': 0.03700865665141958}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:15,407] Trial 33 finished with value: 0.81943645773433 and parameters: {'max_depth': 4, 'learning_rate': 0.04346190940363583, 'n_estimators': 855, 'min_child_weight': 5, 'gamma': 0.4675592546625334, 'subsample': 0.9982755594634288, 'colsample_bytree': 0.5827055911558685, 'reg_alpha': 0.10565969445392066, 'reg_lambda': 0.034294309277244306}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:16,076] Trial 34 finished with value: 0.8223116733755031 and parameters: {'max_depth': 5, 'learning_rate': 0.11175402277157251, 'n_estimators': 583, 'min_child_weight': 6, 'gamma': 0.6703100384013461, 'subsample': 0.9708323163121686, 'colsample_bytree': 0.6856606617458658, 'reg_alpha': 0.05432426987938515, 'reg_lambda': 0.018267961662934033}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:16,736] Trial 35 finished with value: 0.8033352501437608 and parameters: {'max_depth': 5, 'learning_rate': 0.2970014454306771, 'n_estimators': 587, 'min_child_weight': 6, 'gamma': 0.657023918684778, 'subsample': 0.9348946566505718, 'colsample_bytree': 0.7812078811860327, 'reg_alpha': 0.04963077019442104, 'reg_lambda': 0.01789947738935686}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:17,561] Trial 36 finished with value: 0.816561242093157 and parameters: {'max_depth': 3, 'learning_rate': 0.16455984741275392, 'n_estimators': 666, 'min_child_weight': 6, 'gamma': 0.23894991473508928, 'subsample': 0.8515841280111622, 'colsample_bytree': 0.758096903578453, 'reg_alpha': 0.048393988042599936, 'reg_lambda': 0.01138830196034}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:18,192] Trial 37 finished with value: 0.8131109833237493 and parameters: {'max_depth': 5, 'learning_rate': 0.2246210273469025, 'n_estimators': 483, 'min_child_weight': 5, 'gamma': 0.36780043025651266, 'subsample': 0.9663493903131939, 'colsample_bytree': 0.7239670680797377, 'reg_alpha': 0.31367199718088984, 'reg_lambda': 0.04651677019813118}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:19,049] Trial 38 finished with value: 0.8131109833237493 and parameters: {'max_depth': 3, 'learning_rate': 0.11071446542434919, 'n_estimators': 768, 'min_child_weight': 7, 'gamma': 0.6741591009606286, 'subsample': 0.9279116860782041, 'colsample_bytree': 0.5993509607867513, 'reg_alpha': 0.055284942540055906, 'reg_lambda': 0.01833161062858632}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:19,896] Trial 39 finished with value: 0.8171362852213916 and parameters: {'max_depth': 4, 'learning_rate': 0.09129522142748542, 'n_estimators': 565, 'min_child_weight': 6, 'gamma': 0.3970885614654341, 'subsample': 0.8900634566935852, 'colsample_bytree': 0.5536537986456997, 'reg_alpha': 0.27881005991364133, 'reg_lambda': 0.09941295678628174}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:20,862] Trial 40 finished with value: 0.8188614146060954 and parameters: {'max_depth': 5, 'learning_rate': 0.12167369096442397, 'n_estimators': 672, 'min_child_weight': 2, 'gamma': 0.6580746339203052, 'subsample': 0.8844003242122673, 'colsample_bytree': 0.7832539930076395, 'reg_alpha': 0.09682639195799234, 'reg_lambda': 0.056447003245391945}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:21,898] Trial 41 finished with value: 0.821161587119034 and parameters: {'max_depth': 4, 'learning_rate': 0.05110638744495322, 'n_estimators': 709, 'min_child_weight': 4, 'gamma': 0.37524174294284907, 'subsample': 0.9803154062217833, 'colsample_bytree': 0.6640938457480953, 'reg_alpha': 0.46990783040860307, 'reg_lambda': 0.024290557711721946}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:22,467] Trial 42 finished with value: 0.8182863714778609 and parameters: {'max_depth': 4, 'learning_rate': 0.08291411311091122, 'n_estimators': 496, 'min_child_weight': 5, 'gamma': 0.5811528060814654, 'subsample': 0.9975407807758228, 'colsample_bytree': 0.6747777908958107, 'reg_alpha': 0.14436939526649492, 'reg_lambda': 0.03768273225007807}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:22,996] Trial 43 finished with value: 0.8131109833237493 and parameters: {'max_depth': 3, 'learning_rate': 0.06280968402445293, 'n_estimators': 421, 'min_child_weight': 5, 'gamma': 0.8406190721338532, 'subsample': 0.9326894043956615, 'colsample_bytree': 0.6204363513436715, 'reg_alpha': 0.061316785590570286, 'reg_lambda': 0.015189555797442456}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:24,072] Trial 44 finished with value: 0.8205865439907993 and parameters: {'max_depth': 5, 'learning_rate': 0.049375563419387335, 'n_estimators': 629, 'min_child_weight': 7, 'gamma': 0.4250304384727296, 'subsample': 0.9679680440363182, 'colsample_bytree': 0.6298312279674948, 'reg_alpha': 0.01101835751609481, 'reg_lambda': 0.02312380097302699}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:25,256] Trial 45 finished with value: 0.8154111558366878 and parameters: {'max_depth': 4, 'learning_rate': 0.024421136509559967, 'n_estimators': 762, 'min_child_weight': 3, 'gamma': 0.7649848403406916, 'subsample': 0.8449294359045786, 'colsample_bytree': 0.6978742964548721, 'reg_alpha': 0.1214674556018861, 'reg_lambda': 0.01023429787317553}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:25,664] Trial 46 finished with value: 0.8131109833237493 and parameters: {'max_depth': 3, 'learning_rate': 0.03911115165988964, 'n_estimators': 302, 'min_child_weight': 6, 'gamma': 0.32785162402227475, 'subsample': 0.9712286386852822, 'colsample_bytree': 0.8703195468314971, 'reg_alpha': 0.03497746184266158, 'reg_lambda': 0.05521861640178629}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:27,193] Trial 47 finished with value: 0.8200115008625647 and parameters: {'max_depth': 5, 'learning_rate': 0.030424356060643504, 'n_estimators': 837, 'min_child_weight': 2, 'gamma': 0.22234620778664477, 'subsample': 0.9259891144943693, 'colsample_bytree': 0.5803598088593459, 'reg_alpha': 0.08098003415222885, 'reg_lambda': 0.09822621531370422}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:28,051] Trial 48 finished with value: 0.8108108108108109 and parameters: {'max_depth': 3, 'learning_rate': 0.018462654053646728, 'n_estimators': 696, 'min_child_weight': 4, 'gamma': 0.15528334037259886, 'subsample': 0.9443787116000941, 'colsample_bytree': 0.6568377975515284, 'reg_alpha': 0.1904726093138019, 'reg_lambda': 0.039169782793437906}. Best is trial 32 with value: 0.8228867165037378.\n",
      "[I 2025-03-18 01:07:28,766] Trial 49 finished with value: 0.824036802760207 and parameters: {'max_depth': 4, 'learning_rate': 0.1061952487054923, 'n_estimators': 590, 'min_child_weight': 5, 'gamma': 0.5518009753468235, 'subsample': 0.9798101771565212, 'colsample_bytree': 0.7227265019389411, 'reg_alpha': 0.022610837915309375, 'reg_lambda': 0.014560841774313882}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:29,385] Trial 50 finished with value: 0.8177113283496262 and parameters: {'max_depth': 5, 'learning_rate': 0.16455826498691498, 'n_estimators': 596, 'min_child_weight': 7, 'gamma': 0.7512636930964819, 'subsample': 0.9618573239032338, 'colsample_bytree': 0.7244144035532036, 'reg_alpha': 0.02205565266792056, 'reg_lambda': 0.013310013755091988}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:30,138] Trial 51 finished with value: 0.8182863714778609 and parameters: {'max_depth': 4, 'learning_rate': 0.10338188183101285, 'n_estimators': 651, 'min_child_weight': 5, 'gamma': 0.5512304586705874, 'subsample': 0.9814843603115422, 'colsample_bytree': 0.7432120740410957, 'reg_alpha': 0.0159702693090513, 'reg_lambda': 0.021442681162881033}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:31,194] Trial 52 finished with value: 0.8228867165037378 and parameters: {'max_depth': 4, 'learning_rate': 0.0554104265250586, 'n_estimators': 739, 'min_child_weight': 5, 'gamma': 0.4504196151184901, 'subsample': 0.9836085334360649, 'colsample_bytree': 0.8160638560378485, 'reg_alpha': 0.042270994958903484, 'reg_lambda': 0.031483471684971114}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:32,160] Trial 53 finished with value: 0.8131109833237493 and parameters: {'max_depth': 3, 'learning_rate': 0.08356969128528134, 'n_estimators': 784, 'min_child_weight': 5, 'gamma': 0.26737783090765954, 'subsample': 0.957149612222517, 'colsample_bytree': 0.8197803119314951, 'reg_alpha': 0.04012176998290427, 'reg_lambda': 0.01444662982452419}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:33,600] Trial 54 finished with value: 0.8171362852213916 and parameters: {'max_depth': 4, 'learning_rate': 0.04681800806525561, 'n_estimators': 561, 'min_child_weight': 6, 'gamma': 0.6209568070880543, 'subsample': 0.9129946265642653, 'colsample_bytree': 0.7842311414224477, 'reg_alpha': 0.025854464701422327, 'reg_lambda': 0.061901341201659785}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:35,109] Trial 55 finished with value: 0.8125359401955147 and parameters: {'max_depth': 5, 'learning_rate': 0.07677390707854494, 'n_estimators': 749, 'min_child_weight': 6, 'gamma': 0.4185957946117221, 'subsample': 0.8333476929895512, 'colsample_bytree': 0.8021162447779508, 'reg_alpha': 0.06181485757159461, 'reg_lambda': 0.033840993121211624}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:36,083] Trial 56 finished with value: 0.8148361127084531 and parameters: {'max_depth': 4, 'learning_rate': 0.06544111942396143, 'n_estimators': 624, 'min_child_weight': 5, 'gamma': 0.4761099645368624, 'subsample': 0.8772739090838853, 'colsample_bytree': 0.765054698572289, 'reg_alpha': 0.07774587497904761, 'reg_lambda': 0.1297112812698258}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:37,960] Trial 57 finished with value: 0.821161587119034 and parameters: {'max_depth': 6, 'learning_rate': 0.0348772609872334, 'n_estimators': 801, 'min_child_weight': 7, 'gamma': 0.32718544728051374, 'subsample': 0.7435980578246795, 'colsample_bytree': 0.8253932290425358, 'reg_alpha': 0.015882162913098328, 'reg_lambda': 0.019321362177288838}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:38,606] Trial 58 finished with value: 0.8113858539390454 and parameters: {'max_depth': 3, 'learning_rate': 0.055260529007694625, 'n_estimators': 511, 'min_child_weight': 6, 'gamma': 0.19371455798800938, 'subsample': 0.9762948142550929, 'colsample_bytree': 0.8636329953099307, 'reg_alpha': 0.0437227237111455, 'reg_lambda': 0.09001360170615905}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:39,469] Trial 59 finished with value: 0.816561242093157 and parameters: {'max_depth': 4, 'learning_rate': 0.12315448216903511, 'n_estimators': 865, 'min_child_weight': 6, 'gamma': 0.8259976219041024, 'subsample': 0.9376175707915508, 'colsample_bytree': 0.7092322673133146, 'reg_alpha': 0.026892563549608207, 'reg_lambda': 0.1813040732592019}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:40,596] Trial 60 finished with value: 0.8079355951696378 and parameters: {'max_depth': 5, 'learning_rate': 0.23273939467037463, 'n_estimators': 683, 'min_child_weight': 5, 'gamma': 0.572992109223864, 'subsample': 0.7916964028890365, 'colsample_bytree': 0.9018582613367612, 'reg_alpha': 0.22531682920076962, 'reg_lambda': 0.04597461420399689}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:41,593] Trial 61 finished with value: 0.8182863714778609 and parameters: {'max_depth': 4, 'learning_rate': 0.05600021069084395, 'n_estimators': 726, 'min_child_weight': 4, 'gamma': 0.45470850130046636, 'subsample': 0.9845270694926035, 'colsample_bytree': 0.6868224602231139, 'reg_alpha': 0.10287302697067693, 'reg_lambda': 0.02930533504646015}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:42,536] Trial 62 finished with value: 0.8159861989649224 and parameters: {'max_depth': 4, 'learning_rate': 0.04000246392261389, 'n_estimators': 728, 'min_child_weight': 4, 'gamma': 0.5504897393528102, 'subsample': 0.9975721141408198, 'colsample_bytree': 0.7403540382822384, 'reg_alpha': 0.17063665908752804, 'reg_lambda': 0.026200090477324092}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:43,937] Trial 63 finished with value: 0.8171362852213916 and parameters: {'max_depth': 4, 'learning_rate': 0.0697989482691296, 'n_estimators': 991, 'min_child_weight': 5, 'gamma': 0.35428183196509555, 'subsample': 0.9561193035106047, 'colsample_bytree': 0.7987343588233871, 'reg_alpha': 0.5144154430116067, 'reg_lambda': 0.016149115776024354}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:44,470] Trial 64 finished with value: 0.816561242093157 and parameters: {'max_depth': 3, 'learning_rate': 0.14025749850429867, 'n_estimators': 579, 'min_child_weight': 4, 'gamma': 0.7173306060623214, 'subsample': 0.9875390863950567, 'colsample_bytree': 0.6711942244375027, 'reg_alpha': 0.1170533899337667, 'reg_lambda': 0.04051390504381755}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:45,668] Trial 65 finished with value: 0.821161587119034 and parameters: {'max_depth': 5, 'learning_rate': 0.04735817884680436, 'n_estimators': 635, 'min_child_weight': 3, 'gamma': 0.2498450760388283, 'subsample': 0.9174350084389391, 'colsample_bytree': 0.6389976215173362, 'reg_alpha': 0.2563165048048025, 'reg_lambda': 0.02959357848759589}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:46,383] Trial 66 finished with value: 0.8108108108108109 and parameters: {'max_depth': 4, 'learning_rate': 0.010220436598943247, 'n_estimators': 436, 'min_child_weight': 6, 'gamma': 0.5069275547681007, 'subsample': 0.8988571748324713, 'colsample_bytree': 0.7135686178209808, 'reg_alpha': 0.35966579628072065, 'reg_lambda': 0.021220573121832034}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:47,969] Trial 67 finished with value: 0.8223116733755031 and parameters: {'max_depth': 5, 'learning_rate': 0.06358436115856161, 'n_estimators': 815, 'min_child_weight': 5, 'gamma': 0.30856457493792017, 'subsample': 0.719075844225466, 'colsample_bytree': 0.8807411254834636, 'reg_alpha': 0.1597377194374353, 'reg_lambda': 0.07973306814884802}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:50,041] Trial 68 finished with value: 0.81196089706728 and parameters: {'max_depth': 6, 'learning_rate': 0.08636812702064446, 'n_estimators': 876, 'min_child_weight': 5, 'gamma': 0.29296245585144354, 'subsample': 0.7190810352615656, 'colsample_bytree': 0.9642100042145644, 'reg_alpha': 0.06665368788587214, 'reg_lambda': 0.07761084080320489}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:51,730] Trial 69 finished with value: 0.8079355951696378 and parameters: {'max_depth': 5, 'learning_rate': 0.10951328059372382, 'n_estimators': 954, 'min_child_weight': 7, 'gamma': 0.9261267912230929, 'subsample': 0.6820719093251927, 'colsample_bytree': 0.8759674929770397, 'reg_alpha': 0.01926842263486899, 'reg_lambda': 0.266868546352352}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:53,561] Trial 70 finished with value: 0.8113858539390454 and parameters: {'max_depth': 6, 'learning_rate': 0.0766741693371232, 'n_estimators': 794, 'min_child_weight': 6, 'gamma': 0.410494315892464, 'subsample': 0.7076804358248661, 'colsample_bytree': 0.8919088827469377, 'reg_alpha': 0.16081372109048933, 'reg_lambda': 0.01240044426776983}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:54,708] Trial 71 finished with value: 0.8200115008625647 and parameters: {'max_depth': 4, 'learning_rate': 0.06098880807712577, 'n_estimators': 829, 'min_child_weight': 5, 'gamma': 0.497579548718957, 'subsample': 0.9666891140429483, 'colsample_bytree': 0.8524951715880789, 'reg_alpha': 0.21592005867277417, 'reg_lambda': 0.06744430089247856}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:55,845] Trial 72 finished with value: 0.8223116733755031 and parameters: {'max_depth': 5, 'learning_rate': 0.05272020647715021, 'n_estimators': 686, 'min_child_weight': 4, 'gamma': 0.6303159094294244, 'subsample': 0.9468317116538065, 'colsample_bytree': 0.8220061259531445, 'reg_alpha': 0.09045165168115793, 'reg_lambda': 0.05012635176250102}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:57,040] Trial 73 finished with value: 0.821161587119034 and parameters: {'max_depth': 5, 'learning_rate': 0.0526729302983159, 'n_estimators': 610, 'min_child_weight': 5, 'gamma': 0.6196825510701678, 'subsample': 0.7600802039602895, 'colsample_bytree': 0.829788583835035, 'reg_alpha': 0.08863379908670181, 'reg_lambda': 0.04984894309074314}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:07:58,479] Trial 74 finished with value: 0.8228867165037378 and parameters: {'max_depth': 5, 'learning_rate': 0.033895972771303344, 'n_estimators': 749, 'min_child_weight': 4, 'gamma': 0.08494027102096165, 'subsample': 0.9463478273821793, 'colsample_bytree': 0.8087372718254991, 'reg_alpha': 0.03689987160018138, 'reg_lambda': 0.12204625082855686}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:00,436] Trial 75 finished with value: 0.816561242093157 and parameters: {'max_depth': 7, 'learning_rate': 0.02867339841491393, 'n_estimators': 741, 'min_child_weight': 6, 'gamma': 0.08170767479843308, 'subsample': 0.6580376559361957, 'colsample_bytree': 0.7744399574659983, 'reg_alpha': 0.03718569373878448, 'reg_lambda': 0.1838716380502673}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:02,242] Trial 76 finished with value: 0.8200115008625647 and parameters: {'max_depth': 6, 'learning_rate': 0.033725589101675356, 'n_estimators': 772, 'min_child_weight': 3, 'gamma': 0.07284370855489006, 'subsample': 0.7242190487007207, 'colsample_bytree': 0.8049938250033479, 'reg_alpha': 0.026834896073089448, 'reg_lambda': 0.12080370697872317}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:03,800] Trial 77 finished with value: 0.8171362852213916 and parameters: {'max_depth': 5, 'learning_rate': 0.020821535227320016, 'n_estimators': 814, 'min_child_weight': 5, 'gamma': 0.037567548138866605, 'subsample': 0.7783496144211451, 'colsample_bytree': 0.792470540434386, 'reg_alpha': 0.010169358871879672, 'reg_lambda': 0.15195124244748057}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:04,620] Trial 78 finished with value: 0.81943645773433 and parameters: {'max_depth': 4, 'learning_rate': 0.03876508137918454, 'n_estimators': 544, 'min_child_weight': 4, 'gamma': 0.137730139939417, 'subsample': 0.9795112501423809, 'colsample_bytree': 0.5010724209605277, 'reg_alpha': 0.051929037875769864, 'reg_lambda': 0.08057699023283595}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:05,457] Trial 79 finished with value: 0.8113858539390454 and parameters: {'max_depth': 3, 'learning_rate': 0.016424696578107943, 'n_estimators': 659, 'min_child_weight': 6, 'gamma': 0.09621178154405446, 'subsample': 0.9228569176910442, 'colsample_bytree': 0.858725522633478, 'reg_alpha': 0.06972778848390855, 'reg_lambda': 0.06095546409255858}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:07,127] Trial 80 finished with value: 0.8182863714778609 and parameters: {'max_depth': 5, 'learning_rate': 0.04432688913427461, 'n_estimators': 909, 'min_child_weight': 7, 'gamma': 0.05533513276941212, 'subsample': 0.9991828899866941, 'colsample_bytree': 0.7673610642563429, 'reg_alpha': 0.03237364061777397, 'reg_lambda': 0.36504618985933696}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:08,141] Trial 81 finished with value: 0.81943645773433 and parameters: {'max_depth': 5, 'learning_rate': 0.06673835971951467, 'n_estimators': 698, 'min_child_weight': 5, 'gamma': 0.6907329371144614, 'subsample': 0.9461459732976187, 'colsample_bytree': 0.8206712201468472, 'reg_alpha': 0.11187850864742485, 'reg_lambda': 0.04566183742415721}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:08,906] Trial 82 finished with value: 0.821161587119034 and parameters: {'max_depth': 5, 'learning_rate': 0.0950500491042605, 'n_estimators': 676, 'min_child_weight': 4, 'gamma': 0.8432737934461977, 'subsample': 0.9581676891449276, 'colsample_bytree': 0.8389481987529216, 'reg_alpha': 0.08708617555512248, 'reg_lambda': 0.10769383186178261}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:10,076] Trial 83 finished with value: 0.8182863714778609 and parameters: {'max_depth': 4, 'learning_rate': 0.050487860770533244, 'n_estimators': 754, 'min_child_weight': 10, 'gamma': 0.33601709527224016, 'subsample': 0.9412047443300088, 'colsample_bytree': 0.8089937817873007, 'reg_alpha': 0.043541210798245945, 'reg_lambda': 0.035337068142143276}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:11,289] Trial 84 finished with value: 0.824036802760207 and parameters: {'max_depth': 6, 'learning_rate': 0.04438081942514967, 'n_estimators': 717, 'min_child_weight': 4, 'gamma': 0.5922771310728819, 'subsample': 0.96745148626842, 'colsample_bytree': 0.8311844906178396, 'reg_alpha': 0.05781516647196503, 'reg_lambda': 0.0564774340850052}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:13,024] Trial 85 finished with value: 0.8217366302472685 and parameters: {'max_depth': 7, 'learning_rate': 0.031530764630775, 'n_estimators': 721, 'min_child_weight': 3, 'gamma': 0.42374791342102636, 'subsample': 0.9725744822060781, 'colsample_bytree': 0.9116347108787277, 'reg_alpha': 0.05747446840643063, 'reg_lambda': 0.08505943618383612}. Best is trial 49 with value: 0.824036802760207.\n",
      "[I 2025-03-18 01:08:14,386] Trial 86 finished with value: 0.8246118458884416 and parameters: {'max_depth': 6, 'learning_rate': 0.04142242715327516, 'n_estimators': 821, 'min_child_weight': 5, 'gamma': 0.38217207728815694, 'subsample': 0.9906279178453894, 'colsample_bytree': 0.8807883364897827, 'reg_alpha': 0.29059160857453864, 'reg_lambda': 0.1373765992934257}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:16,044] Trial 87 finished with value: 0.8246118458884416 and parameters: {'max_depth': 6, 'learning_rate': 0.026490279269741217, 'n_estimators': 781, 'min_child_weight': 4, 'gamma': 0.3686734558481472, 'subsample': 0.9854009533378436, 'colsample_bytree': 0.7551108108926448, 'reg_alpha': 0.34734670563217895, 'reg_lambda': 0.14071951614109673}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:17,666] Trial 88 finished with value: 0.8246118458884416 and parameters: {'max_depth': 6, 'learning_rate': 0.026395634797336833, 'n_estimators': 783, 'min_child_weight': 4, 'gamma': 0.3902974007927319, 'subsample': 0.9875106735278827, 'colsample_bytree': 0.790491815102296, 'reg_alpha': 0.3357681003987991, 'reg_lambda': 0.13323684418327247}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:19,432] Trial 89 finished with value: 0.8182863714778609 and parameters: {'max_depth': 7, 'learning_rate': 0.02662276164378127, 'n_estimators': 779, 'min_child_weight': 4, 'gamma': 0.3677974441492083, 'subsample': 0.9871301772438094, 'colsample_bytree': 0.7533228492513722, 'reg_alpha': 0.3480407045179024, 'reg_lambda': 0.25722189210922375}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:21,338] Trial 90 finished with value: 0.8205865439907993 and parameters: {'max_depth': 6, 'learning_rate': 0.02297613935844011, 'n_estimators': 876, 'min_child_weight': 3, 'gamma': 0.45031966741533513, 'subsample': 0.9606228406193523, 'colsample_bytree': 0.8343830825237368, 'reg_alpha': 0.606419811708891, 'reg_lambda': 0.1529734402817606}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:22,893] Trial 91 finished with value: 0.8223116733755031 and parameters: {'max_depth': 6, 'learning_rate': 0.02592685044103429, 'n_estimators': 756, 'min_child_weight': 4, 'gamma': 0.5322980505086586, 'subsample': 0.9798879638512398, 'colsample_bytree': 0.7920681605410118, 'reg_alpha': 0.32493051121307637, 'reg_lambda': 0.1203733763734601}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:24,325] Trial 92 finished with value: 0.8217366302472685 and parameters: {'max_depth': 6, 'learning_rate': 0.0289577570825456, 'n_estimators': 830, 'min_child_weight': 4, 'gamma': 0.40050188414968996, 'subsample': 0.9999414686595459, 'colsample_bytree': 0.8109496676420073, 'reg_alpha': 0.2638410798722511, 'reg_lambda': 0.20554756463499857}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:26,122] Trial 93 finished with value: 0.8246118458884416 and parameters: {'max_depth': 6, 'learning_rate': 0.036248231456705714, 'n_estimators': 793, 'min_child_weight': 5, 'gamma': 0.06386234435978451, 'subsample': 0.9693039661543521, 'colsample_bytree': 0.8497080272219161, 'reg_alpha': 0.4738504483861502, 'reg_lambda': 0.47398791943601776}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:28,101] Trial 94 finished with value: 0.81943645773433 and parameters: {'max_depth': 6, 'learning_rate': 0.037276568380041085, 'n_estimators': 793, 'min_child_weight': 2, 'gamma': 0.0816003826764114, 'subsample': 0.9694485482467553, 'colsample_bytree': 0.9435767600696829, 'reg_alpha': 0.5488344975417189, 'reg_lambda': 0.5937458984135948}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:29,797] Trial 95 finished with value: 0.821161587119034 and parameters: {'max_depth': 6, 'learning_rate': 0.04198866248328972, 'n_estimators': 736, 'min_child_weight': 5, 'gamma': 0.06151175909863274, 'subsample': 0.9331123512382629, 'colsample_bytree': 0.8540917473374975, 'reg_alpha': 0.4358901184311678, 'reg_lambda': 0.42317389744349343}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:32,157] Trial 96 finished with value: 0.8228867165037378 and parameters: {'max_depth': 7, 'learning_rate': 0.020064243140521423, 'n_estimators': 845, 'min_child_weight': 4, 'gamma': 0.06635931091535197, 'subsample': 0.988840237245807, 'colsample_bytree': 0.8473227951781723, 'reg_alpha': 0.7873721209607516, 'reg_lambda': 0.2471660357994126}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:34,647] Trial 97 finished with value: 0.8182863714778609 and parameters: {'max_depth': 7, 'learning_rate': 0.01632132459722897, 'n_estimators': 841, 'min_child_weight': 3, 'gamma': 0.06527724870514452, 'subsample': 0.9544817386287069, 'colsample_bytree': 0.8476252277770819, 'reg_alpha': 1.343688548907279, 'reg_lambda': 0.8792167063246557}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:37,120] Trial 98 finished with value: 0.821161587119034 and parameters: {'max_depth': 7, 'learning_rate': 0.03383393388864669, 'n_estimators': 898, 'min_child_weight': 4, 'gamma': 0.04562880957653128, 'subsample': 0.9866089558031961, 'colsample_bytree': 0.8654037926681432, 'reg_alpha': 0.7853849294122923, 'reg_lambda': 0.28455299356390334}. Best is trial 86 with value: 0.8246118458884416.\n",
      "[I 2025-03-18 01:08:39,135] Trial 99 finished with value: 0.8234617596319724 and parameters: {'max_depth': 6, 'learning_rate': 0.021920676351971983, 'n_estimators': 860, 'min_child_weight': 4, 'gamma': 0.09187276609687167, 'subsample': 0.9741912210763816, 'colsample_bytree': 0.7815627030529222, 'reg_alpha': 0.8931585705113495, 'reg_lambda': 0.33354674742312335}. Best is trial 86 with value: 0.8246118458884416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost parameters: {'max_depth': 6, 'learning_rate': 0.04142242715327516, 'n_estimators': 821, 'min_child_weight': 5, 'gamma': 0.38217207728815694, 'subsample': 0.9906279178453894, 'colsample_bytree': 0.8807883364897827, 'reg_alpha': 0.29059160857453864, 'reg_lambda': 0.1373765992934257}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:08:40,483] A new study created in memory with name: no-name-19a01ce0-3a1e-4aec-abf4-d0f850a2ef53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.8240 with threshold: 0.4846\n",
      "Best XGBoost validation accuracy: 0.8240\n",
      "\n",
      "==== Tuning RandomForest (11 parallel jobs) ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:08:46,552] Trial 1 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 167, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7952846463484762.\n",
      "[I 2025-03-18 01:08:47,781] Trial 4 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 263, 'max_depth': 23, 'min_samples_split': 10, 'min_samples_leaf': 12, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.7987349051178838.\n",
      "[I 2025-03-18 01:08:49,071] Trial 5 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 327, 'max_depth': 22, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.7987349051178838.\n",
      "[I 2025-03-18 01:08:49,233] Trial 7 finished with value: 0.7964347326049454 and parameters: {'n_estimators': 339, 'max_depth': 27, 'min_samples_split': 20, 'min_samples_leaf': 19, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.7987349051178838.\n",
      "[I 2025-03-18 01:08:51,155] Trial 3 finished with value: 0.7906843013225991 and parameters: {'n_estimators': 495, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 12, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.7987349051178838.\n",
      "[I 2025-03-18 01:08:51,475] Trial 9 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 428, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 19, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.7993099482461185.\n",
      "[I 2025-03-18 01:08:51,955] Trial 11 finished with value: 0.7763082231167338 and parameters: {'n_estimators': 134, 'max_depth': 5, 'min_samples_split': 11, 'min_samples_leaf': 19, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.7993099482461185.\n",
      "[I 2025-03-18 01:08:52,079] Trial 12 finished with value: 0.7947096032202415 and parameters: {'n_estimators': 186, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 9 with value: 0.7993099482461185.\n",
      "[I 2025-03-18 01:08:53,214] Trial 2 finished with value: 0.7826336975273146 and parameters: {'n_estimators': 301, 'max_depth': 30, 'min_samples_split': 18, 'min_samples_leaf': 16, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 9 with value: 0.7993099482461185.\n",
      "[I 2025-03-18 01:08:55,355] Trial 17 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 121, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 17, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.7993099482461185.\n",
      "[I 2025-03-18 01:08:55,869] Trial 10 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 696, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 11, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.7993099482461185.\n",
      "[I 2025-03-18 01:08:56,622] Trial 16 finished with value: 0.7924094307073031 and parameters: {'n_estimators': 240, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 19, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 9 with value: 0.7993099482461185.\n",
      "[I 2025-03-18 01:08:57,976] Trial 8 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 816, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.7993099482461185.\n",
      "[I 2025-03-18 01:08:58,852] Trial 18 finished with value: 0.7924094307073031 and parameters: {'n_estimators': 323, 'max_depth': 20, 'min_samples_split': 19, 'min_samples_leaf': 13, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.7993099482461185.\n",
      "[I 2025-03-18 01:08:59,445] Trial 6 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 899, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 12, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:00,923] Trial 14 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 495, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:06,303] Trial 15 finished with value: 0.7584818861414606 and parameters: {'n_estimators': 299, 'max_depth': 22, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:08,724] Trial 22 finished with value: 0.7929844738355377 and parameters: {'n_estimators': 504, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 14, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:09,885] Trial 13 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 927, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:13,578] Trial 19 finished with value: 0.7958596894767107 and parameters: {'n_estimators': 852, 'max_depth': 27, 'min_samples_split': 19, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:16,442] Trial 20 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 916, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:17,186] Trial 0 finished with value: 0.7400805060379528 and parameters: {'n_estimators': 781, 'max_depth': 24, 'min_samples_split': 14, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:17,293] Trial 21 finished with value: 0.7941345600920069 and parameters: {'n_estimators': 964, 'max_depth': 18, 'min_samples_split': 13, 'min_samples_leaf': 14, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:20,219] Trial 23 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 969, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:20,974] Trial 25 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 997, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:21,441] Trial 26 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 1000, 'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:23,013] Trial 27 finished with value: 0.79700977573318 and parameters: {'n_estimators': 933, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:23,173] Trial 30 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 695, 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:24,012] Trial 24 finished with value: 0.78205865439908 and parameters: {'n_estimators': 926, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:24,223] Trial 28 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 999, 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:24,341] Trial 29 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 982, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:25,023] Trial 33 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 606, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:25,084] Trial 32 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 659, 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:26,741] Trial 31 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 769, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:27,910] Trial 34 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 605, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:29,675] Trial 35 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 652, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 17, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:30,318] Trial 36 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 636, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:31,575] Trial 41 finished with value: 0.7941345600920069 and parameters: {'n_estimators': 431, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:32,007] Trial 42 finished with value: 0.7924094307073031 and parameters: {'n_estimators': 412, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:32,341] Trial 38 finished with value: 0.7958596894767107 and parameters: {'n_estimators': 610, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:32,763] Trial 37 finished with value: 0.7947096032202415 and parameters: {'n_estimators': 664, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:33,338] Trial 44 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 400, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:34,794] Trial 39 finished with value: 0.7935595169637722 and parameters: {'n_estimators': 737, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:35,143] Trial 40 finished with value: 0.79700977573318 and parameters: {'n_estimators': 777, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:36,445] Trial 43 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 818, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:38,121] Trial 46 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 806, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:09:38,346] Trial 45 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 837, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:09,889] Trial 47 finished with value: 0.7768832662449684 and parameters: {'n_estimators': 793, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:09,974] Trial 57 finished with value: 0.7814836112708453 and parameters: {'n_estimators': 547, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 20, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:11,214] Trial 56 finished with value: 0.78205865439908 and parameters: {'n_estimators': 551, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 20, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:17,942] Trial 48 finished with value: 0.7883841288096607 and parameters: {'n_estimators': 819, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 11, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:18,412] Trial 52 finished with value: 0.7837837837837838 and parameters: {'n_estimators': 764, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 18, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:19,689] Trial 51 finished with value: 0.7826336975273146 and parameters: {'n_estimators': 783, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:20,554] Trial 49 finished with value: 0.7722829212190915 and parameters: {'n_estimators': 775, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:21,611] Trial 61 finished with value: 0.7958596894767107 and parameters: {'n_estimators': 238, 'max_depth': 24, 'min_samples_split': 11, 'min_samples_leaf': 18, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:21,926] Trial 62 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 251, 'max_depth': 24, 'min_samples_split': 10, 'min_samples_leaf': 12, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:22,298] Trial 50 finished with value: 0.7878090856814262 and parameters: {'n_estimators': 859, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 11, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:22,518] Trial 63 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 228, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:22,550] Trial 53 finished with value: 0.7814836112708453 and parameters: {'n_estimators': 819, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 20, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:23,640] Trial 54 finished with value: 0.7878090856814262 and parameters: {'n_estimators': 839, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 11, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:24,316] Trial 55 finished with value: 0.7837837837837838 and parameters: {'n_estimators': 866, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:24,629] Trial 60 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 896, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 11, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 6 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:10:25,004] Trial 59 finished with value: 0.8004600345025877 and parameters: {'n_estimators': 873, 'max_depth': 21, 'min_samples_split': 11, 'min_samples_leaf': 11, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:26,625] Trial 58 finished with value: 0.7901092581943646 and parameters: {'n_estimators': 552, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 20, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:28,858] Trial 72 finished with value: 0.7929844738355377 and parameters: {'n_estimators': 127, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 14, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:30,561] Trial 70 finished with value: 0.7958596894767107 and parameters: {'n_estimators': 366, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 14, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:30,945] Trial 71 finished with value: 0.7935595169637722 and parameters: {'n_estimators': 349, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 14, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:32,087] Trial 64 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 881, 'max_depth': 23, 'min_samples_split': 11, 'min_samples_leaf': 12, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:32,779] Trial 67 finished with value: 0.7964347326049454 and parameters: {'n_estimators': 719, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 12, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:33,454] Trial 65 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 870, 'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 12, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:33,849] Trial 66 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 854, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:34,462] Trial 68 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 887, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 13, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:34,705] Trial 69 finished with value: 0.7947096032202415 and parameters: {'n_estimators': 886, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 14, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:34,755] Trial 73 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 726, 'max_depth': 21, 'min_samples_split': 12, 'min_samples_leaf': 13, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:35,106] Trial 74 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 704, 'max_depth': 21, 'min_samples_split': 11, 'min_samples_leaf': 13, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 59 with value: 0.8004600345025877.\n",
      "[I 2025-03-18 01:10:35,911] Trial 81 finished with value: 0.8010350776308223 and parameters: {'n_estimators': 103, 'max_depth': 26, 'min_samples_split': 12, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:35,989] Trial 80 finished with value: 0.79700977573318 and parameters: {'n_estimators': 167, 'max_depth': 17, 'min_samples_split': 12, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:36,135] Trial 82 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 102, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:36,310] Trial 75 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 729, 'max_depth': 21, 'min_samples_split': 12, 'min_samples_leaf': 13, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:36,486] Trial 83 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 103, 'max_depth': 21, 'min_samples_split': 12, 'min_samples_leaf': 17, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:38,013] Trial 78 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 465, 'max_depth': 17, 'min_samples_split': 12, 'min_samples_leaf': 13, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:38,291] Trial 76 finished with value: 0.79700977573318 and parameters: {'n_estimators': 723, 'max_depth': 21, 'min_samples_split': 11, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:38,596] Trial 79 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 460, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 13, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:39,439] Trial 77 finished with value: 0.79700977573318 and parameters: {'n_estimators': 723, 'max_depth': 21, 'min_samples_split': 12, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:44,032] Trial 84 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 678, 'max_depth': 21, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:44,111] Trial 85 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 678, 'max_depth': 26, 'min_samples_split': 12, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:44,327] Trial 92 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 455, 'max_depth': 15, 'min_samples_split': 15, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:44,382] Trial 91 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 465, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 15, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:44,583] Trial 86 finished with value: 0.8004600345025877 and parameters: {'n_estimators': 669, 'max_depth': 26, 'min_samples_split': 12, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:44,781] Trial 87 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 667, 'max_depth': 26, 'min_samples_split': 17, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:44,833] Trial 93 finished with value: 0.8004600345025877 and parameters: {'n_estimators': 467, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 15, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:45,005] Trial 88 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 668, 'max_depth': 28, 'min_samples_split': 17, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:45,241] Trial 90 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 667, 'max_depth': 15, 'min_samples_split': 15, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:45,258] Trial 89 finished with value: 0.8010350776308223 and parameters: {'n_estimators': 658, 'max_depth': 28, 'min_samples_split': 16, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:47,232] Trial 94 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 684, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 15, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:47,722] Trial 95 finished with value: 0.7941345600920069 and parameters: {'n_estimators': 455, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:47,819] Trial 98 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 516, 'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 15, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:47,822] Trial 97 finished with value: 0.79700977573318 and parameters: {'n_estimators': 512, 'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 15, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:47,858] Trial 96 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 648, 'max_depth': 15, 'min_samples_split': 16, 'min_samples_leaf': 15, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:47,873] Trial 99 finished with value: 0.7929844738355377 and parameters: {'n_estimators': 627, 'max_depth': 29, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 81 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:10:48,018] A new study created in memory with name: no-name-ebeff989-d805-496a-af3f-94bdb43fcd56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest parameters: {'n_estimators': 103, 'max_depth': 26, 'min_samples_split': 12, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}\n",
      "Best accuracy: 0.7993\n",
      "Best RandomForest validation accuracy: 0.7993\n",
      "\n",
      "==== Tuning GradientBoosting (11 parallel jobs) ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:10:50,562] Trial 1 finished with value: 0.8016101207590569 and parameters: {'n_estimators': 115, 'learning_rate': 0.13522149946460177, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.8832853283291255, 'max_features': 'log2'}. Best is trial 1 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:10:56,126] Trial 7 finished with value: 0.8004600345025877 and parameters: {'n_estimators': 318, 'learning_rate': 0.13641976768774172, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.6611019670800677, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:10:56,206] Trial 0 finished with value: 0.8090856814261069 and parameters: {'n_estimators': 302, 'learning_rate': 0.03586672560350705, 'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 5, 'subsample': 0.5585284292861541, 'max_features': 'log2'}. Best is trial 0 with value: 0.8090856814261069.\n",
      "[I 2025-03-18 01:10:57,893] Trial 6 finished with value: 0.8027602070155262 and parameters: {'n_estimators': 329, 'learning_rate': 0.02041623193201037, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 20, 'subsample': 0.5853617731843869, 'max_features': 'log2'}. Best is trial 0 with value: 0.8090856814261069.\n",
      "[I 2025-03-18 01:10:58,821] Trial 12 finished with value: 0.8056354226566993 and parameters: {'n_estimators': 144, 'learning_rate': 0.21187609458646914, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 20, 'subsample': 0.5988375468761429, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8090856814261069.\n",
      "[I 2025-03-18 01:10:58,937] Trial 8 finished with value: 0.8050603795284647 and parameters: {'n_estimators': 422, 'learning_rate': 0.12465285366414557, 'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 11, 'subsample': 0.5095533589061538, 'max_features': 'log2'}. Best is trial 0 with value: 0.8090856814261069.\n",
      "[I 2025-03-18 01:11:02,041] Trial 16 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 204, 'learning_rate': 0.21336232038492792, 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 1, 'subsample': 0.7540360355207165, 'max_features': 'log2'}. Best is trial 0 with value: 0.8090856814261069.\n",
      "[I 2025-03-18 01:11:05,799] Trial 9 finished with value: 0.8079355951696378 and parameters: {'n_estimators': 948, 'learning_rate': 0.06907132975984406, 'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 17, 'subsample': 0.9792953775550732, 'max_features': 'log2'}. Best is trial 0 with value: 0.8090856814261069.\n",
      "[I 2025-03-18 01:11:06,302] Trial 3 finished with value: 0.8027602070155262 and parameters: {'n_estimators': 477, 'learning_rate': 0.19839947638495825, 'max_depth': 9, 'min_samples_split': 19, 'min_samples_leaf': 19, 'subsample': 0.7404633877205724, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8090856814261069.\n",
      "[I 2025-03-18 01:11:08,097] Trial 2 finished with value: 0.8113858539390454 and parameters: {'n_estimators': 475, 'learning_rate': 0.03242352301750208, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 18, 'subsample': 0.7824679878846574, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:11:09,882] Trial 13 finished with value: 0.8039102932719954 and parameters: {'n_estimators': 400, 'learning_rate': 0.11717500228233697, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 19, 'subsample': 0.8169711267176817, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:11:10,957] Trial 10 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 522, 'learning_rate': 0.010116173958538607, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.5968081411172761, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:11:11,920] Trial 18 finished with value: 0.8067855089131685 and parameters: {'n_estimators': 334, 'learning_rate': 0.21043562203519958, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 20, 'subsample': 0.6220846578370691, 'max_features': 'log2'}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:11:13,286] Trial 4 finished with value: 0.8102357676825762 and parameters: {'n_estimators': 807, 'learning_rate': 0.020276618458668655, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 16, 'subsample': 0.6153056941250798, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:11:14,721] Trial 17 finished with value: 0.8050603795284647 and parameters: {'n_estimators': 609, 'learning_rate': 0.025244743778183344, 'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 20, 'subsample': 0.8912346277427419, 'max_features': 'log2'}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:11:15,164] Trial 15 finished with value: 0.8010350776308223 and parameters: {'n_estimators': 819, 'learning_rate': 0.02209679655667424, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 14, 'subsample': 0.9978042313531692, 'max_features': 'log2'}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:11:16,172] Trial 14 finished with value: 0.7883841288096607 and parameters: {'n_estimators': 196, 'learning_rate': 0.1822376260296936, 'max_depth': 8, 'min_samples_split': 18, 'min_samples_leaf': 2, 'subsample': 0.971688062484274, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:11:20,863] Trial 5 finished with value: 0.8050603795284647 and parameters: {'n_estimators': 622, 'learning_rate': 0.09929094362507421, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 7, 'subsample': 0.5548574749349302, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:11:52,363] Trial 19 finished with value: 0.8056354226566993 and parameters: {'n_estimators': 994, 'learning_rate': 0.20976143032746042, 'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 13, 'subsample': 0.8757379319510541, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:11:56,298] Trial 11 finished with value: 0.7958596894767107 and parameters: {'n_estimators': 724, 'learning_rate': 0.01903637381593137, 'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 4, 'subsample': 0.8633508753067771, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:05,966] Trial 28 finished with value: 0.8050603795284647 and parameters: {'n_estimators': 772, 'learning_rate': 0.013140431369205856, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 15, 'subsample': 0.714143274026966, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:15,511] Trial 26 finished with value: 0.8033352501437608 and parameters: {'n_estimators': 670, 'learning_rate': 0.012766318028875503, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 15, 'subsample': 0.7067442047752466, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:15,855] Trial 20 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 680, 'learning_rate': 0.011544229322408187, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 13, 'subsample': 0.7722724206118728, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:17,342] Trial 24 finished with value: 0.8021851638872916 and parameters: {'n_estimators': 713, 'learning_rate': 0.027021872674669267, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 15, 'subsample': 0.6982505361363621, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:17,500] Trial 27 finished with value: 0.8050603795284647 and parameters: {'n_estimators': 658, 'learning_rate': 0.011223845800155638, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 15, 'subsample': 0.7273492747645468, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:18,425] Trial 25 finished with value: 0.8056354226566993 and parameters: {'n_estimators': 718, 'learning_rate': 0.01544370999203689, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 15, 'subsample': 0.6887184883219623, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:18,984] Trial 21 finished with value: 0.80448533640023 and parameters: {'n_estimators': 665, 'learning_rate': 0.022147678036322702, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.7009739181131239, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:20,530] Trial 22 finished with value: 0.80448533640023 and parameters: {'n_estimators': 680, 'learning_rate': 0.02422807066707115, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.7225937763904529, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:26,680] Trial 23 finished with value: 0.8050603795284647 and parameters: {'n_estimators': 737, 'learning_rate': 0.030581200341837398, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.7090774410676283, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:32,808] Trial 29 finished with value: 0.8079355951696378 and parameters: {'n_estimators': 743, 'learning_rate': 0.04110228907814196, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 16, 'subsample': 0.6941006217709496, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:39,343] Trial 35 finished with value: 0.8067855089131685 and parameters: {'n_estimators': 850, 'learning_rate': 0.039158274848202404, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 17, 'subsample': 0.5017088429748554, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:40,535] Trial 34 finished with value: 0.8050603795284647 and parameters: {'n_estimators': 879, 'learning_rate': 0.03890732243866023, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 17, 'subsample': 0.5207223491848323, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:41,036] Trial 30 finished with value: 0.8102357676825762 and parameters: {'n_estimators': 820, 'learning_rate': 0.03914200934150022, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 16, 'subsample': 0.6891125232453573, 'max_features': None}. Best is trial 2 with value: 0.8113858539390454.\n",
      "[I 2025-03-18 01:12:41,205] Trial 37 finished with value: 0.8125359401955147 and parameters: {'n_estimators': 848, 'learning_rate': 0.034602412738384415, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 17, 'subsample': 0.5166861966778267, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:12:43,068] Trial 38 finished with value: 0.8067855089131685 and parameters: {'n_estimators': 894, 'learning_rate': 0.03795686547193629, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 17, 'subsample': 0.5030909797853401, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:12:43,730] Trial 31 finished with value: 0.8096607245543416 and parameters: {'n_estimators': 615, 'learning_rate': 0.039294522318577677, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 16, 'subsample': 0.6808521627924982, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:12:45,256] Trial 36 finished with value: 0.8090856814261069 and parameters: {'n_estimators': 898, 'learning_rate': 0.03789320267586723, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 7, 'subsample': 0.5149217512403906, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:12:48,572] Trial 39 finished with value: 0.8096607245543416 and parameters: {'n_estimators': 861, 'learning_rate': 0.03383053764083568, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 17, 'subsample': 0.5196907624524185, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:12:51,902] Trial 43 finished with value: 0.8079355951696378 and parameters: {'n_estimators': 538, 'learning_rate': 0.05843325504916985, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.6516248669752213, 'max_features': 'log2'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:12:55,655] Trial 42 finished with value: 0.8079355951696378 and parameters: {'n_estimators': 924, 'learning_rate': 0.07041149027613365, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 17, 'subsample': 0.934975487503799, 'max_features': 'log2'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:12:55,878] Trial 41 finished with value: 0.8056354226566993 and parameters: {'n_estimators': 992, 'learning_rate': 0.064758878763549, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 18, 'subsample': 0.9391638610520026, 'max_features': 'log2'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:12:57,277] Trial 40 finished with value: 0.8073605520414031 and parameters: {'n_estimators': 858, 'learning_rate': 0.03869421958414331, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.538487020713405, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:00,275] Trial 32 finished with value: 0.8113858539390454 and parameters: {'n_estimators': 830, 'learning_rate': 0.035502240402608895, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.5044275142688529, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:00,618] Trial 44 finished with value: 0.8050603795284647 and parameters: {'n_estimators': 906, 'learning_rate': 0.05263812465768671, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 18, 'subsample': 0.6341265223811542, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:01,665] Trial 45 finished with value: 0.80448533640023 and parameters: {'n_estimators': 559, 'learning_rate': 0.05419525418930907, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 18, 'subsample': 0.5496490443734532, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:04,663] Trial 47 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 530, 'learning_rate': 0.06092196349663133, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 18, 'subsample': 0.6402671273788043, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:06,811] Trial 48 finished with value: 0.8096607245543416 and parameters: {'n_estimators': 496, 'learning_rate': 0.05082808114339529, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 12, 'subsample': 0.5616409181354323, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:08,920] Trial 33 finished with value: 0.8073605520414031 and parameters: {'n_estimators': 862, 'learning_rate': 0.035783935326762634, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 17, 'subsample': 0.661085237284246, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:13,366] Trial 46 finished with value: 0.8102357676825762 and parameters: {'n_estimators': 802, 'learning_rate': 0.05877731779191761, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 18, 'subsample': 0.6319763599138835, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:18,575] Trial 51 finished with value: 0.8056354226566993 and parameters: {'n_estimators': 582, 'learning_rate': 0.049313763135435305, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 12, 'subsample': 0.5583266089113142, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:21,826] Trial 57 finished with value: 0.8090856814261069 and parameters: {'n_estimators': 437, 'learning_rate': 0.08303928692411175, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 19, 'subsample': 0.5760910034406874, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:23,794] Trial 49 finished with value: 0.8021851638872916 and parameters: {'n_estimators': 806, 'learning_rate': 0.050888164755566644, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 12, 'subsample': 0.5464894168570608, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:25,258] Trial 56 finished with value: 0.8079355951696378 and parameters: {'n_estimators': 497, 'learning_rate': 0.08681173655831718, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 11, 'subsample': 0.5704984421548351, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:26,279] Trial 58 finished with value: 0.8085106382978723 and parameters: {'n_estimators': 414, 'learning_rate': 0.08533175327023258, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.5799967044839096, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:27,870] Trial 50 finished with value: 0.8125359401955147 and parameters: {'n_estimators': 794, 'learning_rate': 0.05723706814915142, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 12, 'subsample': 0.5569906501200809, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:29,918] Trial 59 finished with value: 0.8056354226566993 and parameters: {'n_estimators': 399, 'learning_rate': 0.08256832503227543, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.7999293960156959, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:32,668] Trial 53 finished with value: 0.8090856814261069 and parameters: {'n_estimators': 796, 'learning_rate': 0.048002972002263174, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 12, 'subsample': 0.5674502348294284, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:35,126] Trial 60 finished with value: 0.8067855089131685 and parameters: {'n_estimators': 441, 'learning_rate': 0.08461126904775469, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 19, 'subsample': 0.8216403191153975, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:37,230] Trial 55 finished with value: 0.8073605520414031 and parameters: {'n_estimators': 469, 'learning_rate': 0.01732588915980528, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.573237370903594, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:43,151] Trial 65 finished with value: 0.8039102932719954 and parameters: {'n_estimators': 452, 'learning_rate': 0.019160321747426642, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 19, 'subsample': 0.6035398426631962, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:44,879] Trial 66 finished with value: 0.8079355951696378 and parameters: {'n_estimators': 454, 'learning_rate': 0.029741144760993654, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 19, 'subsample': 0.6048966968929874, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:48,326] Trial 68 finished with value: 0.8096607245543416 and parameters: {'n_estimators': 356, 'learning_rate': 0.03140101686405898, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.5983110582281732, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:49,239] Trial 67 finished with value: 0.8056354226566993 and parameters: {'n_estimators': 454, 'learning_rate': 0.029081676796781173, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 9, 'subsample': 0.6135877723515332, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:51,636] Trial 52 finished with value: 0.8004600345025877 and parameters: {'n_estimators': 597, 'learning_rate': 0.0459595607467261, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 13, 'subsample': 0.7909210013133681, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:56,262] Trial 64 finished with value: 0.80448533640023 and parameters: {'n_estimators': 375, 'learning_rate': 0.01784549657840119, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 19, 'subsample': 0.7889491590243758, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:57,608] Trial 54 finished with value: 0.8050603795284647 and parameters: {'n_estimators': 800, 'learning_rate': 0.01804971967190725, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 12, 'subsample': 0.5646739573363603, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:13:59,953] Trial 63 finished with value: 0.8021851638872916 and parameters: {'n_estimators': 436, 'learning_rate': 0.018180027605070016, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 19, 'subsample': 0.790082262555296, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:00,042] Trial 62 finished with value: 0.8056354226566993 and parameters: {'n_estimators': 456, 'learning_rate': 0.029874263885797427, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 19, 'subsample': 0.8086711617708859, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:07,536] Trial 69 finished with value: 0.7947096032202415 and parameters: {'n_estimators': 945, 'learning_rate': 0.28321607352038036, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 14, 'subsample': 0.6097867783160449, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:09,001] Trial 70 finished with value: 0.8085106382978723 and parameters: {'n_estimators': 939, 'learning_rate': 0.03031539792770031, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 14, 'subsample': 0.5341486962337666, 'max_features': 'sqrt'}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:15,761] Trial 77 finished with value: 0.8021851638872916 and parameters: {'n_estimators': 279, 'learning_rate': 0.02366326552726444, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.7478486614553194, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:22,485] Trial 80 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 274, 'learning_rate': 0.04366044500480442, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.6755653777154665, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:23,932] Trial 61 finished with value: 0.8039102932719954 and parameters: {'n_estimators': 802, 'learning_rate': 0.017465943069485346, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 19, 'subsample': 0.8071819248933223, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:29,837] Trial 76 finished with value: 0.8090856814261069 and parameters: {'n_estimators': 764, 'learning_rate': 0.04387222734891732, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.5342227894148938, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:35,178] Trial 72 finished with value: 0.81196089706728 and parameters: {'n_estimators': 828, 'learning_rate': 0.04445707111873914, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 14, 'subsample': 0.7566651979533624, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:37,212] Trial 83 finished with value: 0.8073605520414031 and parameters: {'n_estimators': 263, 'learning_rate': 0.03415294211908203, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 16, 'subsample': 0.666036642986227, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:39,712] Trial 71 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 955, 'learning_rate': 0.044479824970651255, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 14, 'subsample': 0.7572860187094878, 'max_features': None}. Best is trial 37 with value: 0.8125359401955147.\n",
      "[I 2025-03-18 01:14:40,622] Trial 79 finished with value: 0.8142610695802185 and parameters: {'n_estimators': 765, 'learning_rate': 0.04345111296230089, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.5349835888534796, 'max_features': None}. Best is trial 79 with value: 0.8142610695802185.\n",
      "[I 2025-03-18 01:14:40,864] Trial 78 finished with value: 0.8085106382978723 and parameters: {'n_estimators': 941, 'learning_rate': 0.04353609712008941, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.5339836202469186, 'max_features': None}. Best is trial 79 with value: 0.8142610695802185.\n",
      "[I 2025-03-18 01:14:43,916] Trial 73 finished with value: 0.8079355951696378 and parameters: {'n_estimators': 957, 'learning_rate': 0.023780920632665146, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 14, 'subsample': 0.7490978305764773, 'max_features': None}. Best is trial 79 with value: 0.8142610695802185.\n",
      "[I 2025-03-18 01:14:44,170] Trial 75 finished with value: 0.8113858539390454 and parameters: {'n_estimators': 832, 'learning_rate': 0.04414374474741669, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.7574139098657702, 'max_features': None}. Best is trial 79 with value: 0.8142610695802185.\n",
      "[I 2025-03-18 01:14:44,400] Trial 84 finished with value: 0.8085106382978723 and parameters: {'n_estimators': 276, 'learning_rate': 0.026348921839283817, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 16, 'subsample': 0.6517853336292712, 'max_features': None}. Best is trial 79 with value: 0.8142610695802185.\n",
      "[I 2025-03-18 01:14:44,839] Trial 85 finished with value: 0.8010350776308223 and parameters: {'n_estimators': 197, 'learning_rate': 0.043588597495793295, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.6726300762216186, 'max_features': None}. Best is trial 79 with value: 0.8142610695802185.\n",
      "[I 2025-03-18 01:14:46,255] Trial 74 finished with value: 0.8148361127084531 and parameters: {'n_estimators': 960, 'learning_rate': 0.04399758947731055, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.7576050985979715, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:14:46,629] Trial 87 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 122, 'learning_rate': 0.04461141622421877, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 14, 'subsample': 0.8370594490738527, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:14:46,970] Trial 86 finished with value: 0.7964347326049454 and parameters: {'n_estimators': 169, 'learning_rate': 0.02635890132098448, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 14, 'subsample': 0.8361892587928472, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:14:53,994] Trial 81 finished with value: 0.8079355951696378 and parameters: {'n_estimators': 772, 'learning_rate': 0.04456899697325326, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 16, 'subsample': 0.6432617904127668, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:04,613] Trial 82 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 826, 'learning_rate': 0.044131467900834866, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.6704915341461091, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:09,472] Trial 95 finished with value: 0.81196089706728 and parameters: {'n_estimators': 833, 'learning_rate': 0.061937483324284934, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 18, 'subsample': 0.5132289120380327, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:10,985] Trial 98 finished with value: 0.8062104657849338 and parameters: {'n_estimators': 641, 'learning_rate': 0.05945821517220083, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 15, 'subsample': 0.7649505764159675, 'max_features': 'log2'}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:14,124] Trial 88 finished with value: 0.81196089706728 and parameters: {'n_estimators': 699, 'learning_rate': 0.06809637399932886, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 14, 'subsample': 0.7681737394117567, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:16,723] Trial 94 finished with value: 0.8062104657849338 and parameters: {'n_estimators': 835, 'learning_rate': 0.06512142196113829, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 15, 'subsample': 0.7320486937518023, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:17,989] Trial 96 finished with value: 0.8085106382978723 and parameters: {'n_estimators': 829, 'learning_rate': 0.0598231040791029, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 15, 'subsample': 0.7701232589902078, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:19,364] Trial 93 finished with value: 0.8113858539390454 and parameters: {'n_estimators': 765, 'learning_rate': 0.06450186341802322, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 13, 'subsample': 0.7664792211967699, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:21,529] Trial 91 finished with value: 0.8125359401955147 and parameters: {'n_estimators': 833, 'learning_rate': 0.06528205919644055, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 13, 'subsample': 0.762887796474136, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:22,112] Trial 92 finished with value: 0.8027602070155262 and parameters: {'n_estimators': 831, 'learning_rate': 0.06597167703191566, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7727589345295, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:23,342] Trial 90 finished with value: 0.8136860264519838 and parameters: {'n_estimators': 824, 'learning_rate': 0.061903808570331946, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8329357760808342, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:23,621] Trial 89 finished with value: 0.8079355951696378 and parameters: {'n_estimators': 967, 'learning_rate': 0.06946888853721885, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 14, 'subsample': 0.7671271590419206, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:34,121] Trial 99 finished with value: 0.8090856814261069 and parameters: {'n_estimators': 840, 'learning_rate': 0.07041944025551604, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 15, 'subsample': 0.7718453311327789, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n",
      "[I 2025-03-18 01:15:36,892] Trial 97 finished with value: 0.80448533640023 and parameters: {'n_estimators': 840, 'learning_rate': 0.06505813780261024, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 18, 'subsample': 0.7698279837849097, 'max_features': None}. Best is trial 74 with value: 0.8148361127084531.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GradientBoosting parameters: {'n_estimators': 960, 'learning_rate': 0.04399758947731055, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.7576050985979715, 'max_features': None}\n",
      "Best iteration for GradientBoosting: 237/960\n",
      "Pruning model to 237 trees (early stopping)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:16:18,798] A new study created in memory with name: no-name-e4fb48df-5da6-4396-a16c-28f74ac0146f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.8097\n",
      "Best GradientBoosting validation accuracy: 0.8097\n",
      "\n",
      "==== Tuning ExtraTrees (11 parallel jobs) ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:16:21,674] Trial 2 finished with value: 0.7929844738355377 and parameters: {'n_estimators': 101, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.7929844738355377.\n",
      "[I 2025-03-18 01:16:25,537] Trial 6 finished with value: 0.7883841288096607 and parameters: {'n_estimators': 365, 'max_depth': 16, 'min_samples_split': 19, 'min_samples_leaf': 15, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.7929844738355377.\n",
      "[I 2025-03-18 01:16:25,856] Trial 0 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 383, 'max_depth': 20, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 0 with value: 0.7987349051178838.\n",
      "[I 2025-03-18 01:16:26,649] Trial 4 finished with value: 0.7964347326049454 and parameters: {'n_estimators': 547, 'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 15, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 0 with value: 0.7987349051178838.\n",
      "[I 2025-03-18 01:16:27,066] Trial 8 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 491, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 8 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:16:27,427] Trial 7 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 629, 'max_depth': 17, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 8 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:16:27,448] Trial 9 finished with value: 0.7665324899367453 and parameters: {'n_estimators': 644, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 8 with value: 0.7998849913743531.\n",
      "[I 2025-03-18 01:16:27,585] Trial 5 finished with value: 0.8010350776308223 and parameters: {'n_estimators': 658, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:28,203] Trial 10 finished with value: 0.7964347326049454 and parameters: {'n_estimators': 606, 'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 17, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:28,457] Trial 12 finished with value: 0.79700977573318 and parameters: {'n_estimators': 258, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 19, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:28,546] Trial 13 finished with value: 0.7929844738355377 and parameters: {'n_estimators': 286, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 11, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:29,392] Trial 3 finished with value: 0.7912593444508338 and parameters: {'n_estimators': 750, 'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 15, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:29,477] Trial 1 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 884, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:31,157] Trial 16 finished with value: 0.7441058079355952 and parameters: {'n_estimators': 276, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:31,941] Trial 18 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 360, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 14, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:32,538] Trial 11 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 748, 'max_depth': 20, 'min_samples_split': 11, 'min_samples_leaf': 14, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:32,840] Trial 15 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 447, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:35,000] Trial 17 finished with value: 0.78953421506613 and parameters: {'n_estimators': 557, 'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:35,535] Trial 19 finished with value: 0.7958596894767107 and parameters: {'n_estimators': 583, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 19, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:37,157] Trial 14 finished with value: 0.7912593444508338 and parameters: {'n_estimators': 967, 'max_depth': 9, 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:38,573] Trial 20 finished with value: 0.7964347326049454 and parameters: {'n_estimators': 935, 'max_depth': 24, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:39,460] Trial 21 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 919, 'max_depth': 23, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:39,548] Trial 23 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 985, 'max_depth': 23, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:40,592] Trial 22 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 962, 'max_depth': 23, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:40,804] Trial 24 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 1000, 'max_depth': 23, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:41,147] Trial 25 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 982, 'max_depth': 23, 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:42,132] Trial 26 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 994, 'max_depth': 23, 'min_samples_split': 14, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:42,436] Trial 27 finished with value: 0.7866589994249569 and parameters: {'n_estimators': 985, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:43,912] Trial 28 finished with value: 0.7883841288096607 and parameters: {'n_estimators': 948, 'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:44,962] Trial 29 finished with value: 0.7889591719378953 and parameters: {'n_estimators': 994, 'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:46,733] Trial 30 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 978, 'max_depth': 24, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:46,791] Trial 31 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 825, 'max_depth': 20, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:48,334] Trial 32 finished with value: 0.7947096032202415 and parameters: {'n_estimators': 810, 'max_depth': 20, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:49,037] Trial 33 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 835, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:51,140] Trial 34 finished with value: 0.79700977573318 and parameters: {'n_estimators': 819, 'max_depth': 19, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:51,464] Trial 35 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 834, 'max_depth': 19, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:52,260] Trial 36 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 835, 'max_depth': 19, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:53,659] Trial 37 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 821, 'max_depth': 19, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:56,551] Trial 42 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 479, 'max_depth': 30, 'min_samples_split': 16, 'min_samples_leaf': 12, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:56,584] Trial 41 finished with value: 0.8010350776308223 and parameters: {'n_estimators': 476, 'max_depth': 27, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:57,185] Trial 38 finished with value: 0.8004600345025877 and parameters: {'n_estimators': 837, 'max_depth': 18, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:58,145] Trial 39 finished with value: 0.8004600345025877 and parameters: {'n_estimators': 808, 'max_depth': 20, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:58,258] Trial 43 finished with value: 0.8004600345025877 and parameters: {'n_estimators': 485, 'max_depth': 29, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:16:58,298] Trial 44 finished with value: 0.7924094307073031 and parameters: {'n_estimators': 452, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:00,411] Trial 40 finished with value: 0.8010350776308223 and parameters: {'n_estimators': 843, 'max_depth': 20, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:01,487] Trial 46 finished with value: 0.7929844738355377 and parameters: {'n_estimators': 480, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:01,743] Trial 45 finished with value: 0.7935595169637722 and parameters: {'n_estimators': 511, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:02,428] Trial 47 finished with value: 0.7941345600920069 and parameters: {'n_estimators': 480, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:08,922] Trial 48 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 683, 'max_depth': 29, 'min_samples_split': 18, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:11,851] Trial 49 finished with value: 0.7941345600920069 and parameters: {'n_estimators': 675, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:11,995] Trial 50 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 705, 'max_depth': 28, 'min_samples_split': 18, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:12,207] Trial 51 finished with value: 0.7941345600920069 and parameters: {'n_estimators': 672, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:13,295] Trial 52 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 704, 'max_depth': 28, 'min_samples_split': 18, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:13,519] Trial 54 finished with value: 0.8004600345025877 and parameters: {'n_estimators': 694, 'max_depth': 27, 'min_samples_split': 18, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:13,631] Trial 53 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 713, 'max_depth': 27, 'min_samples_split': 18, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:15,308] Trial 55 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 687, 'max_depth': 27, 'min_samples_split': 18, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:16,809] Trial 57 finished with value: 0.7947096032202415 and parameters: {'n_estimators': 704, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:16,853] Trial 56 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 687, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:17,748] Trial 58 finished with value: 0.79700977573318 and parameters: {'n_estimators': 689, 'max_depth': 16, 'min_samples_split': 18, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:23,868] Trial 59 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 755, 'max_depth': 16, 'min_samples_split': 18, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:27,339] Trial 60 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 751, 'max_depth': 15, 'min_samples_split': 18, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:27,936] Trial 61 finished with value: 0.7958596894767107 and parameters: {'n_estimators': 766, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:28,206] Trial 62 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 758, 'max_depth': 16, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:29,657] Trial 63 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 765, 'max_depth': 16, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:30,694] Trial 66 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 759, 'max_depth': 16, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:30,930] Trial 64 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 892, 'max_depth': 16, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:31,029] Trial 65 finished with value: 0.7987349051178838 and parameters: {'n_estimators': 876, 'max_depth': 16, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:32,145] Trial 69 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 887, 'max_depth': 17, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:33,072] Trial 73 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 392, 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:33,189] Trial 68 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 879, 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:33,252] Trial 67 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 896, 'max_depth': 21, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:34,627] Trial 74 finished with value: 0.7998849913743531 and parameters: {'n_estimators': 391, 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:35,403] Trial 70 finished with value: 0.7993099482461185 and parameters: {'n_estimators': 894, 'max_depth': 21, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:36,425] Trial 77 finished with value: 0.7958596894767107 and parameters: {'n_estimators': 390, 'max_depth': 25, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:38,163] Trial 78 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 384, 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:38,783] Trial 72 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 870, 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.8010350776308223.\n",
      "[I 2025-03-18 01:17:39,496] Trial 71 finished with value: 0.8016101207590569 and parameters: {'n_estimators': 883, 'max_depth': 25, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:39,939] Trial 76 finished with value: 0.7964347326049454 and parameters: {'n_estimators': 624, 'max_depth': 21, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:42,646] Trial 81 finished with value: 0.7889591719378953 and parameters: {'n_estimators': 571, 'max_depth': 12, 'min_samples_split': 19, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:43,677] Trial 75 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 870, 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:44,780] Trial 80 finished with value: 0.7941345600920069 and parameters: {'n_estimators': 617, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:44,842] Trial 79 finished with value: 0.7935595169637722 and parameters: {'n_estimators': 617, 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:46,390] Trial 82 finished with value: 0.7924094307073031 and parameters: {'n_estimators': 623, 'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 9, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:48,203] Trial 83 finished with value: 0.7906843013225991 and parameters: {'n_estimators': 590, 'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:49,161] Trial 84 finished with value: 0.7941345600920069 and parameters: {'n_estimators': 602, 'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:49,836] Trial 85 finished with value: 0.7901092581943646 and parameters: {'n_estimators': 576, 'max_depth': 11, 'min_samples_split': 19, 'min_samples_leaf': 9, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:50,194] Trial 86 finished with value: 0.7947096032202415 and parameters: {'n_estimators': 597, 'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 9, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:51,116] Trial 87 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 592, 'max_depth': 26, 'min_samples_split': 19, 'min_samples_leaf': 20, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:51,879] Trial 88 finished with value: 0.7947096032202415 and parameters: {'n_estimators': 567, 'max_depth': 26, 'min_samples_split': 19, 'min_samples_leaf': 17, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:54,596] Trial 89 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 520, 'max_depth': 26, 'min_samples_split': 19, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:58,623] Trial 90 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 590, 'max_depth': 26, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:59,112] Trial 96 finished with value: 0.7763082231167338 and parameters: {'n_estimators': 538, 'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:59,341] Trial 99 finished with value: 0.79700977573318 and parameters: {'n_estimators': 536, 'max_depth': 18, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:59,365] Trial 92 finished with value: 0.7935595169637722 and parameters: {'n_estimators': 791, 'max_depth': 18, 'min_samples_split': 19, 'min_samples_leaf': 8, 'max_features': None, 'bootstrap': False, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:59,479] Trial 93 finished with value: 0.7912593444508338 and parameters: {'n_estimators': 796, 'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:59,498] Trial 94 finished with value: 0.7952846463484762 and parameters: {'n_estimators': 783, 'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:59,504] Trial 91 finished with value: 0.7918343875790684 and parameters: {'n_estimators': 939, 'max_depth': 18, 'min_samples_split': 19, 'min_samples_leaf': 9, 'max_features': None, 'bootstrap': False, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:59,538] Trial 95 finished with value: 0.7901092581943646 and parameters: {'n_estimators': 787, 'max_depth': 26, 'min_samples_split': 12, 'min_samples_leaf': 12, 'max_features': None, 'bootstrap': False, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:59,546] Trial 97 finished with value: 0.7975848188614146 and parameters: {'n_estimators': 788, 'max_depth': 18, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n",
      "[I 2025-03-18 01:17:59,580] Trial 98 finished with value: 0.7981598619896493 and parameters: {'n_estimators': 787, 'max_depth': 18, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 71 with value: 0.8016101207590569.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ExtraTrees parameters: {'n_estimators': 883, 'max_depth': 25, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True, 'class_weight': None}\n",
      "Best accuracy: 0.7976\n",
      "Best ExtraTrees validation accuracy: 0.7976\n",
      "\n",
      "==== Generating Meta Features with Model-Specific Data ====\n",
      "Generating meta-features for catboost\n",
      "Generating meta-features for xgboost\n",
      "Generating meta-features for random_forest\n",
      "Generating meta-features for gradient_boosting\n",
      "Generating meta-features for extra_trees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:19:12,492] A new study created in memory with name: no-name-703ba129-1085-48fa-9692-c8cf9ab084a0\n",
      "[I 2025-03-18 01:19:12,571] Trial 8 finished with value: 0.8142610695802185 and parameters: {'model_type': 'logistic', 'C': 0.01245626328414047, 'solver': 'liblinear'}. Best is trial 8 with value: 0.8142610695802185.\n",
      "[I 2025-03-18 01:19:12,581] Trial 1 finished with value: 0.8159861989649224 and parameters: {'model_type': 'logistic', 'C': 0.4070434730242739, 'solver': 'liblinear'}. Best is trial 1 with value: 0.8159861989649224.\n",
      "[I 2025-03-18 01:19:12,630] Trial 11 finished with value: 0.8148361127084531 and parameters: {'model_type': 'logistic', 'C': 0.07462122377606112, 'solver': 'liblinear'}. Best is trial 1 with value: 0.8159861989649224.\n",
      "[I 2025-03-18 01:19:12,636] Trial 10 finished with value: 0.8188614146060954 and parameters: {'model_type': 'logistic', 'C': 0.6723159356227854, 'solver': 'saga'}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:12,640] Trial 3 finished with value: 0.8142610695802185 and parameters: {'model_type': 'logistic', 'C': 0.0825491472731197, 'solver': 'saga'}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:12,654] Trial 12 finished with value: 0.8154111558366878 and parameters: {'model_type': 'logistic', 'C': 0.009390655307921079, 'solver': 'saga'}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:12,687] Trial 13 finished with value: 0.8136860264519838 and parameters: {'model_type': 'logistic', 'C': 0.012009809677033502, 'solver': 'saga'}. Best is trial 10 with value: 0.8188614146060954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Tuning Meta-Learner (11 parallel jobs) ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 01:19:12,972] Trial 2 finished with value: 0.8136860264519838 and parameters: {'model_type': 'xgboost', 'n_estimators': 61, 'max_depth': 6, 'learning_rate': 0.12377022353648637, 'subsample': 0.6526063721835276, 'colsample_bytree': 0.8389035216867546}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,107] Trial 5 finished with value: 0.8182863714778609 and parameters: {'model_type': 'catboost', 'iterations': 180, 'depth': 6, 'learning_rate': 0.04381023113571828, 'l2_leaf_reg': 0.29269193761965595}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,128] Trial 14 finished with value: 0.8102357676825762 and parameters: {'model_type': 'xgboost', 'n_estimators': 51, 'max_depth': 6, 'learning_rate': 0.1297906278214695, 'subsample': 0.6144977654353476, 'colsample_bytree': 0.6017983891479853}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,206] Trial 19 finished with value: 0.8154111558366878 and parameters: {'model_type': 'logistic', 'C': 0.10080334004029513, 'solver': 'liblinear'}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,270] Trial 17 finished with value: 0.8073605520414031 and parameters: {'model_type': 'xgboost', 'n_estimators': 65, 'max_depth': 6, 'learning_rate': 0.16866472520539272, 'subsample': 0.8627531170219764, 'colsample_bytree': 0.8935424229880156}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,301] Trial 9 finished with value: 0.8154111558366878 and parameters: {'model_type': 'catboost', 'iterations': 102, 'depth': 8, 'learning_rate': 0.01034594519159446, 'l2_leaf_reg': 0.33379905507574703}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,595] Trial 21 finished with value: 0.8171362852213916 and parameters: {'model_type': 'catboost', 'iterations': 174, 'depth': 6, 'learning_rate': 0.012868557989368704, 'l2_leaf_reg': 0.2571334461835065}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,602] Trial 4 finished with value: 0.8039102932719954 and parameters: {'model_type': 'catboost', 'iterations': 394, 'depth': 3, 'learning_rate': 0.17628855717065364, 'l2_leaf_reg': 3.6994759448548904}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,655] Trial 15 finished with value: 0.8154111558366878 and parameters: {'model_type': 'xgboost', 'n_estimators': 239, 'max_depth': 4, 'learning_rate': 0.034611996880526, 'subsample': 0.6773665638266595, 'colsample_bytree': 0.7274984803552785}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,695] Trial 22 finished with value: 0.8177113283496262 and parameters: {'model_type': 'catboost', 'iterations': 162, 'depth': 6, 'learning_rate': 0.01755168500479914, 'l2_leaf_reg': 0.25675570431418615}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,702] Trial 16 finished with value: 0.8136860264519838 and parameters: {'model_type': 'xgboost', 'n_estimators': 299, 'max_depth': 3, 'learning_rate': 0.10257067028684952, 'subsample': 0.951945951850697, 'colsample_bytree': 0.7526659859597049}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,739] Trial 0 finished with value: 0.8004600345025877 and parameters: {'model_type': 'xgboost', 'n_estimators': 206, 'max_depth': 6, 'learning_rate': 0.1449689604064501, 'subsample': 0.8240522393183963, 'colsample_bytree': 0.5650952526458222}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,854] Trial 18 finished with value: 0.8154111558366878 and parameters: {'model_type': 'catboost', 'iterations': 236, 'depth': 6, 'learning_rate': 0.029240197240607446, 'l2_leaf_reg': 4.418817075267514}. Best is trial 10 with value: 0.8188614146060954.\n",
      "[I 2025-03-18 01:19:13,890] Trial 23 finished with value: 0.81943645773433 and parameters: {'model_type': 'catboost', 'iterations': 230, 'depth': 4, 'learning_rate': 0.029487884682076186, 'l2_leaf_reg': 0.1064212098904549}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,399] Trial 20 finished with value: 0.8188614146060954 and parameters: {'model_type': 'catboost', 'iterations': 499, 'depth': 3, 'learning_rate': 0.012208363683304463, 'l2_leaf_reg': 9.857166944973821}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,442] Trial 25 finished with value: 0.8136860264519838 and parameters: {'model_type': 'catboost', 'iterations': 248, 'depth': 5, 'learning_rate': 0.03917056809720854, 'l2_leaf_reg': 0.10203879963382813}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,491] Trial 6 finished with value: 0.8027602070155262 and parameters: {'model_type': 'catboost', 'iterations': 365, 'depth': 7, 'learning_rate': 0.06609273300483928, 'l2_leaf_reg': 1.1518513390643952}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,524] Trial 27 finished with value: 0.81943645773433 and parameters: {'model_type': 'catboost', 'iterations': 294, 'depth': 4, 'learning_rate': 0.04253418099257613, 'l2_leaf_reg': 1.6415604303170412}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,569] Trial 28 finished with value: 0.8159861989649224 and parameters: {'model_type': 'catboost', 'iterations': 291, 'depth': 4, 'learning_rate': 0.05829079569365955, 'l2_leaf_reg': 1.6373650033965437}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,594] Trial 26 finished with value: 0.8131109833237493 and parameters: {'model_type': 'catboost', 'iterations': 266, 'depth': 5, 'learning_rate': 0.0452993988932073, 'l2_leaf_reg': 0.14203281004592805}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,598] Trial 29 finished with value: 0.8136860264519838 and parameters: {'model_type': 'catboost', 'iterations': 310, 'depth': 4, 'learning_rate': 0.058701255344882276, 'l2_leaf_reg': 1.7369195856187056}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,661] Trial 38 finished with value: 0.8159861989649224 and parameters: {'model_type': 'logistic', 'C': 9.771609879385876, 'solver': 'saga'}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,681] Trial 7 finished with value: 0.8177113283496262 and parameters: {'model_type': 'catboost', 'iterations': 397, 'depth': 7, 'learning_rate': 0.010896580257792946, 'l2_leaf_reg': 0.46582814617819523}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,697] Trial 37 finished with value: 0.8159861989649224 and parameters: {'model_type': 'logistic', 'C': 6.953446237892982, 'solver': 'saga'}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,745] Trial 31 finished with value: 0.8079355951696378 and parameters: {'model_type': 'catboost', 'iterations': 280, 'depth': 4, 'learning_rate': 0.061455666309603176, 'l2_leaf_reg': 0.10551401070302513}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,776] Trial 30 finished with value: 0.8067855089131685 and parameters: {'model_type': 'catboost', 'iterations': 341, 'depth': 4, 'learning_rate': 0.06707933774454611, 'l2_leaf_reg': 1.02083421950429}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,797] Trial 39 finished with value: 0.816561242093157 and parameters: {'model_type': 'logistic', 'C': 2.8424608198945656, 'solver': 'saga'}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,823] Trial 40 finished with value: 0.8177113283496262 and parameters: {'model_type': 'logistic', 'C': 1.0921369920214392, 'solver': 'saga'}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:14,824] Trial 24 finished with value: 0.8154111558366878 and parameters: {'model_type': 'catboost', 'iterations': 456, 'depth': 3, 'learning_rate': 0.036887107733496495, 'l2_leaf_reg': 4.182257155737783}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:15,240] Trial 35 finished with value: 0.8171362852213916 and parameters: {'model_type': 'catboost', 'iterations': 333, 'depth': 4, 'learning_rate': 0.023929940081607325, 'l2_leaf_reg': 1.371913941169189}. Best is trial 23 with value: 0.81943645773433.\n",
      "[I 2025-03-18 01:19:15,319] Trial 36 finished with value: 0.8200115008625647 and parameters: {'model_type': 'catboost', 'iterations': 354, 'depth': 4, 'learning_rate': 0.025454904077788297, 'l2_leaf_reg': 0.652245454446724}. Best is trial 36 with value: 0.8200115008625647.\n",
      "[I 2025-03-18 01:19:15,358] Trial 33 finished with value: 0.81943645773433 and parameters: {'model_type': 'catboost', 'iterations': 492, 'depth': 3, 'learning_rate': 0.021799291844286046, 'l2_leaf_reg': 1.4745452419807334}. Best is trial 36 with value: 0.8200115008625647.\n",
      "[I 2025-03-18 01:19:15,405] Trial 32 finished with value: 0.8177113283496262 and parameters: {'model_type': 'catboost', 'iterations': 493, 'depth': 3, 'learning_rate': 0.021648327630667513, 'l2_leaf_reg': 1.1397550727005012}. Best is trial 36 with value: 0.8200115008625647.\n",
      "[I 2025-03-18 01:19:15,439] Trial 34 finished with value: 0.8200115008625647 and parameters: {'model_type': 'catboost', 'iterations': 499, 'depth': 3, 'learning_rate': 0.022663259587135134, 'l2_leaf_reg': 1.5350830798461168}. Best is trial 36 with value: 0.8200115008625647.\n",
      "[I 2025-03-18 01:19:15,592] Trial 45 finished with value: 0.821161587119034 and parameters: {'model_type': 'catboost', 'iterations': 487, 'depth': 3, 'learning_rate': 0.021195362660280104, 'l2_leaf_reg': 7.825521536899684}. Best is trial 45 with value: 0.821161587119034.\n",
      "[I 2025-03-18 01:19:15,649] Trial 41 finished with value: 0.8205865439907993 and parameters: {'model_type': 'catboost', 'iterations': 499, 'depth': 3, 'learning_rate': 0.0209092027911255, 'l2_leaf_reg': 9.870439088435658}. Best is trial 45 with value: 0.821161587119034.\n",
      "[I 2025-03-18 01:19:15,655] Trial 44 finished with value: 0.821161587119034 and parameters: {'model_type': 'catboost', 'iterations': 453, 'depth': 3, 'learning_rate': 0.02149481178984796, 'l2_leaf_reg': 8.291165905351415}. Best is trial 45 with value: 0.821161587119034.\n",
      "[I 2025-03-18 01:19:15,671] Trial 46 finished with value: 0.8217366302472685 and parameters: {'model_type': 'catboost', 'iterations': 466, 'depth': 3, 'learning_rate': 0.023376890411748077, 'l2_leaf_reg': 7.981121262247145}. Best is trial 46 with value: 0.8217366302472685.\n",
      "[I 2025-03-18 01:19:15,675] Trial 43 finished with value: 0.8205865439907993 and parameters: {'model_type': 'catboost', 'iterations': 469, 'depth': 3, 'learning_rate': 0.020057119926271003, 'l2_leaf_reg': 9.496370586222058}. Best is trial 46 with value: 0.8217366302472685.\n",
      "[I 2025-03-18 01:19:15,762] Trial 42 finished with value: 0.8234617596319724 and parameters: {'model_type': 'catboost', 'iterations': 497, 'depth': 3, 'learning_rate': 0.022811901239723674, 'l2_leaf_reg': 8.32475345345865}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:15,811] Trial 49 finished with value: 0.8188614146060954 and parameters: {'model_type': 'catboost', 'iterations': 224, 'depth': 3, 'learning_rate': 0.022400324904238367, 'l2_leaf_reg': 0.6213163746237512}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:15,852] Trial 48 finished with value: 0.8188614146060954 and parameters: {'model_type': 'catboost', 'iterations': 208, 'depth': 5, 'learning_rate': 0.02144847795045555, 'l2_leaf_reg': 0.5756117108968144}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:15,970] Trial 50 finished with value: 0.8217366302472685 and parameters: {'model_type': 'catboost', 'iterations': 214, 'depth': 5, 'learning_rate': 0.0174690497340231, 'l2_leaf_reg': 0.590402580346423}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,081] Trial 59 finished with value: 0.8200115008625647 and parameters: {'model_type': 'xgboost', 'n_estimators': 140, 'max_depth': 2, 'learning_rate': 0.015611040505891393, 'subsample': 0.5014792788566309, 'colsample_bytree': 0.9924930635955671}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,135] Trial 47 finished with value: 0.8182863714778609 and parameters: {'model_type': 'catboost', 'iterations': 458, 'depth': 3, 'learning_rate': 0.02043720401551842, 'l2_leaf_reg': 8.76775641389602}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,255] Trial 51 finished with value: 0.8188614146060954 and parameters: {'model_type': 'catboost', 'iterations': 434, 'depth': 3, 'learning_rate': 0.017557797777488882, 'l2_leaf_reg': 0.6128122938438578}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,306] Trial 60 finished with value: 0.8177113283496262 and parameters: {'model_type': 'xgboost', 'n_estimators': 143, 'max_depth': 2, 'learning_rate': 0.015454040533897363, 'subsample': 0.5203573646222232, 'colsample_bytree': 0.9963941651475281}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,485] Trial 53 finished with value: 0.8188614146060954 and parameters: {'model_type': 'catboost', 'iterations': 440, 'depth': 3, 'learning_rate': 0.01642789406044939, 'l2_leaf_reg': 9.3325200964117}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,502] Trial 55 finished with value: 0.821161587119034 and parameters: {'model_type': 'catboost', 'iterations': 449, 'depth': 3, 'learning_rate': 0.016652105315483733, 'l2_leaf_reg': 9.867661742656665}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,561] Trial 56 finished with value: 0.8217366302472685 and parameters: {'model_type': 'catboost', 'iterations': 449, 'depth': 3, 'learning_rate': 0.015952115745088702, 'l2_leaf_reg': 9.982676614712302}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,605] Trial 54 finished with value: 0.81943645773433 and parameters: {'model_type': 'catboost', 'iterations': 446, 'depth': 3, 'learning_rate': 0.01665298599422727, 'l2_leaf_reg': 8.064350350075118}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,615] Trial 52 finished with value: 0.8188614146060954 and parameters: {'model_type': 'catboost', 'iterations': 444, 'depth': 4, 'learning_rate': 0.01705129033408451, 'l2_leaf_reg': 0.6383177480725284}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,619] Trial 57 finished with value: 0.821161587119034 and parameters: {'model_type': 'catboost', 'iterations': 439, 'depth': 3, 'learning_rate': 0.01571425670719062, 'l2_leaf_reg': 6.545654555128855}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,673] Trial 58 finished with value: 0.8205865439907993 and parameters: {'model_type': 'catboost', 'iterations': 428, 'depth': 3, 'learning_rate': 0.016778663450181846, 'l2_leaf_reg': 6.57202777654613}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,920] Trial 61 finished with value: 0.81943645773433 and parameters: {'model_type': 'catboost', 'iterations': 422, 'depth': 3, 'learning_rate': 0.015808575693944976, 'l2_leaf_reg': 6.58139245034411}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:16,956] Trial 62 finished with value: 0.8188614146060954 and parameters: {'model_type': 'catboost', 'iterations': 430, 'depth': 3, 'learning_rate': 0.01664321518225064, 'l2_leaf_reg': 5.277904002923624}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:17,137] Trial 63 finished with value: 0.8171362852213916 and parameters: {'model_type': 'catboost', 'iterations': 427, 'depth': 3, 'learning_rate': 0.015102574653440294, 'l2_leaf_reg': 6.206271645947847}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:17,183] Trial 64 finished with value: 0.8182863714778609 and parameters: {'model_type': 'catboost', 'iterations': 431, 'depth': 3, 'learning_rate': 0.02910355607696398, 'l2_leaf_reg': 6.356613495457834}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:17,364] Trial 65 finished with value: 0.81943645773433 and parameters: {'model_type': 'catboost', 'iterations': 411, 'depth': 3, 'learning_rate': 0.029312177130711672, 'l2_leaf_reg': 6.2786645229309315}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:17,410] Trial 66 finished with value: 0.821161587119034 and parameters: {'model_type': 'catboost', 'iterations': 411, 'depth': 3, 'learning_rate': 0.014416423493600361, 'l2_leaf_reg': 6.179805882476724}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:17,622] Trial 72 finished with value: 0.8182863714778609 and parameters: {'model_type': 'catboost', 'iterations': 383, 'depth': 3, 'learning_rate': 0.013301807037783497, 'l2_leaf_reg': 5.262678564716782}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:17,674] Trial 70 finished with value: 0.8142610695802185 and parameters: {'model_type': 'catboost', 'iterations': 388, 'depth': 5, 'learning_rate': 0.028051596501629236, 'l2_leaf_reg': 5.864160316866165}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:18,144] Trial 75 finished with value: 0.8177113283496262 and parameters: {'model_type': 'xgboost', 'n_estimators': 295, 'max_depth': 4, 'learning_rate': 0.013014697724548455, 'subsample': 0.9666391301210053, 'colsample_bytree': 0.5199644608011136}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:18,361] Trial 67 finished with value: 0.816561242093157 and parameters: {'model_type': 'catboost', 'iterations': 397, 'depth': 7, 'learning_rate': 0.012744883282143122, 'l2_leaf_reg': 5.657074846927264}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:18,432] Trial 71 finished with value: 0.8171362852213916 and parameters: {'model_type': 'catboost', 'iterations': 405, 'depth': 7, 'learning_rate': 0.013040809763795675, 'l2_leaf_reg': 5.48564885877412}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:18,494] Trial 68 finished with value: 0.81196089706728 and parameters: {'model_type': 'catboost', 'iterations': 411, 'depth': 7, 'learning_rate': 0.028027506036416308, 'l2_leaf_reg': 6.273728960128004}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:18,674] Trial 76 finished with value: 0.821161587119034 and parameters: {'model_type': 'xgboost', 'n_estimators': 294, 'max_depth': 4, 'learning_rate': 0.01267684636162598, 'subsample': 0.9633136699627084, 'colsample_bytree': 0.6624843115228021}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:18,722] Trial 77 finished with value: 0.8171362852213916 and parameters: {'model_type': 'xgboost', 'n_estimators': 283, 'max_depth': 4, 'learning_rate': 0.012198380445374662, 'subsample': 0.9777263237102101, 'colsample_bytree': 0.5112169135692051}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:18,858] Trial 78 finished with value: 0.8200115008625647 and parameters: {'model_type': 'xgboost', 'n_estimators': 298, 'max_depth': 4, 'learning_rate': 0.011222540703508754, 'subsample': 0.9623417442660301, 'colsample_bytree': 0.6400538186647218}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:18,913] Trial 79 finished with value: 0.8182863714778609 and parameters: {'model_type': 'xgboost', 'n_estimators': 298, 'max_depth': 4, 'learning_rate': 0.010568481330288345, 'subsample': 0.7625797889224812, 'colsample_bytree': 0.5079230404393806}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:18,976] Trial 69 finished with value: 0.8102357676825762 and parameters: {'model_type': 'catboost', 'iterations': 392, 'depth': 8, 'learning_rate': 0.02788676312054189, 'l2_leaf_reg': 6.019975157649121}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,088] Trial 73 finished with value: 0.8113858539390454 and parameters: {'model_type': 'catboost', 'iterations': 472, 'depth': 7, 'learning_rate': 0.027001191159744777, 'l2_leaf_reg': 5.320459397826084}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,272] Trial 89 finished with value: 0.81943645773433 and parameters: {'model_type': 'catboost', 'iterations': 144, 'depth': 4, 'learning_rate': 0.01846716456251627, 'l2_leaf_reg': 3.218178977633896}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,411] Trial 74 finished with value: 0.816561242093157 and parameters: {'model_type': 'catboost', 'iterations': 389, 'depth': 8, 'learning_rate': 0.013029750286233537, 'l2_leaf_reg': 2.822243973814135}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,445] Trial 81 finished with value: 0.8200115008625647 and parameters: {'model_type': 'catboost', 'iterations': 470, 'depth': 4, 'learning_rate': 0.01107073552520264, 'l2_leaf_reg': 2.734051297113856}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,567] Trial 83 finished with value: 0.81943645773433 and parameters: {'model_type': 'catboost', 'iterations': 475, 'depth': 4, 'learning_rate': 0.011142132746904565, 'l2_leaf_reg': 3.019211268217477}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,623] Trial 84 finished with value: 0.8223116733755031 and parameters: {'model_type': 'catboost', 'iterations': 466, 'depth': 4, 'learning_rate': 0.010659132510835596, 'l2_leaf_reg': 3.2011706367444432}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,720] Trial 85 finished with value: 0.8205865439907993 and parameters: {'model_type': 'catboost', 'iterations': 473, 'depth': 4, 'learning_rate': 0.018852860766546506, 'l2_leaf_reg': 2.677556318860822}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,772] Trial 86 finished with value: 0.8182863714778609 and parameters: {'model_type': 'catboost', 'iterations': 474, 'depth': 4, 'learning_rate': 0.01869341363296068, 'l2_leaf_reg': 2.3337239152368596}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,848] Trial 87 finished with value: 0.81943645773433 and parameters: {'model_type': 'catboost', 'iterations': 475, 'depth': 4, 'learning_rate': 0.01926455347000239, 'l2_leaf_reg': 3.0870739955102073}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,895] Trial 88 finished with value: 0.8125359401955147 and parameters: {'model_type': 'catboost', 'iterations': 473, 'depth': 4, 'learning_rate': 0.03348265888243697, 'l2_leaf_reg': 2.5049416396863604}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:19,998] Trial 80 finished with value: 0.8125359401955147 and parameters: {'model_type': 'catboost', 'iterations': 474, 'depth': 7, 'learning_rate': 0.01870754854538287, 'l2_leaf_reg': 2.5920257611593405}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:20,228] Trial 92 finished with value: 0.8223116733755031 and parameters: {'model_type': 'catboost', 'iterations': 478, 'depth': 3, 'learning_rate': 0.019280271930526272, 'l2_leaf_reg': 7.687627681554002}. Best is trial 42 with value: 0.8234617596319724.\n",
      "[I 2025-03-18 01:19:20,258] Trial 91 finished with value: 0.8251868890166763 and parameters: {'model_type': 'catboost', 'iterations': 478, 'depth': 3, 'learning_rate': 0.01909995100099854, 'l2_leaf_reg': 7.752355552270788}. Best is trial 91 with value: 0.8251868890166763.\n",
      "[I 2025-03-18 01:19:20,352] Trial 93 finished with value: 0.8148361127084531 and parameters: {'model_type': 'catboost', 'iterations': 456, 'depth': 3, 'learning_rate': 0.033953653379402836, 'l2_leaf_reg': 7.7269645029081895}. Best is trial 91 with value: 0.8251868890166763.\n",
      "[I 2025-03-18 01:19:20,443] Trial 96 finished with value: 0.821161587119034 and parameters: {'model_type': 'catboost', 'iterations': 457, 'depth': 3, 'learning_rate': 0.024031270297137176, 'l2_leaf_reg': 7.561881506952441}. Best is trial 91 with value: 0.8251868890166763.\n",
      "[I 2025-03-18 01:19:20,479] Trial 95 finished with value: 0.8200115008625647 and parameters: {'model_type': 'catboost', 'iterations': 482, 'depth': 3, 'learning_rate': 0.024419758285232695, 'l2_leaf_reg': 7.8688373757839}. Best is trial 91 with value: 0.8251868890166763.\n",
      "[I 2025-03-18 01:19:20,506] Trial 97 finished with value: 0.8171362852213916 and parameters: {'model_type': 'catboost', 'iterations': 454, 'depth': 3, 'learning_rate': 0.031968972730683574, 'l2_leaf_reg': 7.829678668808305}. Best is trial 91 with value: 0.8251868890166763.\n",
      "[I 2025-03-18 01:19:20,510] Trial 90 finished with value: 0.8108108108108109 and parameters: {'model_type': 'catboost', 'iterations': 476, 'depth': 6, 'learning_rate': 0.03366346952889736, 'l2_leaf_reg': 3.2264851347274552}. Best is trial 91 with value: 0.8251868890166763.\n",
      "[I 2025-03-18 01:19:20,548] Trial 98 finished with value: 0.8217366302472685 and parameters: {'model_type': 'catboost', 'iterations': 457, 'depth': 3, 'learning_rate': 0.025329938848607403, 'l2_leaf_reg': 7.66965348717425}. Best is trial 91 with value: 0.8251868890166763.\n",
      "[I 2025-03-18 01:19:20,580] Trial 82 finished with value: 0.816561242093157 and parameters: {'model_type': 'catboost', 'iterations': 475, 'depth': 8, 'learning_rate': 0.01011120251758238, 'l2_leaf_reg': 3.5192603297779765}. Best is trial 91 with value: 0.8251868890166763.\n",
      "[I 2025-03-18 01:19:20,626] Trial 99 finished with value: 0.8246118458884416 and parameters: {'model_type': 'catboost', 'iterations': 459, 'depth': 3, 'learning_rate': 0.02478603974009542, 'l2_leaf_reg': 7.7448985363489}. Best is trial 91 with value: 0.8251868890166763.\n",
      "[I 2025-03-18 01:19:20,734] Trial 94 finished with value: 0.8171362852213916 and parameters: {'model_type': 'catboost', 'iterations': 482, 'depth': 6, 'learning_rate': 0.018936302064904483, 'l2_leaf_reg': 7.748687836146411}. Best is trial 91 with value: 0.8251868890166763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best meta-learner parameters: {'model_type': 'catboost', 'iterations': 478, 'depth': 3, 'learning_rate': 0.01909995100099854, 'l2_leaf_reg': 7.752355552270788}\n",
      "Best threshold: 0.5051\n",
      "Best meta-learner accuracy: 0.8223\n",
      "Best meta-learner validation accuracy: 0.8223\n",
      "\n",
      "===== FINAL PREDICTION =====\n",
      "Optimized submission file created: optimized_submission.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ensemble': {'base_models': {'catboost': <catboost.core.CatBoostClassifier at 0x33a64be80>,\n",
       "   'xgboost': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bynode=None,\n",
       "                 colsample_bytree=0.8807883364897827, device=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=True,\n",
       "                 eval_metric=None, feature_types=None, gamma=0.38217207728815694,\n",
       "                 grow_policy=None, importance_type=None,\n",
       "                 interaction_constraints=None, learning_rate=0.04142242715327516,\n",
       "                 max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                 max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "                 min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "                 multi_strategy=None, n_estimators=821, n_jobs=11,\n",
       "                 num_parallel_tree=None, random_state=42, ...),\n",
       "   'random_forest': RandomForestClassifier(max_depth=26, min_samples_leaf=18, min_samples_split=12,\n",
       "                          n_estimators=103, n_jobs=11),\n",
       "   'gradient_boosting': GradientBoostingClassifier(learning_rate=0.04399758947731055, max_depth=6,\n",
       "                              min_samples_leaf=16, min_samples_split=8,\n",
       "                              n_estimators=237, random_state=42,\n",
       "                              subsample=0.7576050985979715),\n",
       "   'extra_trees': ExtraTreesClassifier(bootstrap=True, max_depth=25, max_features=None,\n",
       "                        min_samples_leaf=2, min_samples_split=17, n_estimators=883,\n",
       "                        n_jobs=11)},\n",
       "  'meta_learner': <catboost.core.CatBoostClassifier at 0x34909a280>,\n",
       "  'model_data_map': {'catboost': (      ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "    1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "    8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "    5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "    4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "    4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "    7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "    426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "    7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  \\\n",
       "    3600        -0.161141      -0.376161            -0.564175   \n",
       "    1262        -0.161141       2.658437            -0.564175   \n",
       "    8612        -0.161141      -0.376161            -0.564175   \n",
       "    5075        -0.161141      -0.376161            -0.564175   \n",
       "    4758        -0.161141       2.658437            -0.564175   \n",
       "    ...               ...            ...                  ...   \n",
       "    4087        -0.161141      -0.376161            -0.564175   \n",
       "    4406        -0.161141      -0.376161            -0.564175   \n",
       "    7111        -0.161141      -0.376161            -0.564175   \n",
       "    426         -0.161141      -0.376161             1.772499   \n",
       "    7925        -0.161141      -0.376161             1.772499   \n",
       "    \n",
       "                  CabinDeck_B           CabinDeck_C          CabinDeck_D  ...  \\\n",
       "    3600  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    1262  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    8612  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    5075  -0.3156271429370956  -0.30278663910847514    4.124990186830846  ...   \n",
       "    4758  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    ...                   ...                   ...                  ...  ...   \n",
       "    4087    3.168295320530464  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    4406  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    7111  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    426   -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    7925  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    \n",
       "         Age_TotalSpend Age_TotalSpendRatio   Age_log  Age_sqrt  \\\n",
       "    3600       1.032894           -4.138413  0.542236  0.848438   \n",
       "    1262       0.419391           -1.680341  0.542236  0.848438   \n",
       "    8612      -0.230200            0.922323  0.366320  0.665144   \n",
       "    5075       0.094596           -0.379009  0.542236  0.848438   \n",
       "    4758      -1.476003           -0.458639  0.542236  0.848438   \n",
       "    ...             ...                 ...       ...       ...   \n",
       "    4087       0.778193            0.560169  0.691785  0.998638   \n",
       "    4406      -0.133888            0.819078  0.501072  0.806529   \n",
       "    7111      -0.313074            1.568173  0.758932  1.065830   \n",
       "    426        0.166773           -0.668194  0.542236  0.848438   \n",
       "    7925       0.146632           -0.731514  0.542236  0.848438   \n",
       "    \n",
       "         GroupSpendDeviation  RoomService_Dominance FoodCourt_Dominance  \\\n",
       "    3600           -0.101809               2.769710            1.560940   \n",
       "    1262            0.000000               2.769710            1.560940   \n",
       "    8612            0.000000               2.769710            1.560940   \n",
       "    5075            0.000000               2.769710            1.560940   \n",
       "    4758            0.000000              -0.073199           -0.061492   \n",
       "    ...                  ...                    ...                 ...   \n",
       "    4087            0.000000              -0.130693            0.722746   \n",
       "    4406            0.000000              -0.150704           -0.290791   \n",
       "    7111            0.000000              -0.639943           -0.593120   \n",
       "    426             0.000000               2.769710            1.560940   \n",
       "    7925            0.000000              -1.036715           -0.922128   \n",
       "    \n",
       "         ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "    3600               1.990724      1.401816         1.357870  \n",
       "    1262               1.990724      1.401816         1.357870  \n",
       "    8612               1.990724      1.401816         1.357870  \n",
       "    5075               1.990724      1.401816         1.357870  \n",
       "    4758              -0.043779     -0.058854       -51.983508  \n",
       "    ...                     ...           ...              ...  \n",
       "    4087              -0.119876     -0.106686         1.185937  \n",
       "    4406              -0.451021     -0.315128         0.236911  \n",
       "    7111              -0.517760     -3.288903        -0.583203  \n",
       "    426                1.990724      1.401816         1.357870  \n",
       "    7925              -1.034761     -1.039838        -1.040397  \n",
       "    \n",
       "    [6954 rows x 79 columns],\n",
       "          ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "    7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "    8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "    6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "    7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "    1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "    5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "    5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "    4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  \\\n",
       "    3586        -0.161141      -0.376161            -0.564175   \n",
       "    7173        -0.161141      -0.376161            -0.564175   \n",
       "    8559        -0.161141      -0.376161             1.772499   \n",
       "    6528        -0.161141      -0.376161            -0.564175   \n",
       "    7934         6.205752      -0.376161            -0.564175   \n",
       "    ...               ...            ...                  ...   \n",
       "    3749        -0.161141      -0.376161            -0.564175   \n",
       "    1637        -0.161141       2.658437            -0.564175   \n",
       "    5820        -0.161141       2.658437            -0.564175   \n",
       "    5757        -0.161141      -0.376161            -0.564175   \n",
       "    4135        -0.161141      -0.376161            -0.564175   \n",
       "    \n",
       "                  CabinDeck_B           CabinDeck_C          CabinDeck_D  ...  \\\n",
       "    3586  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    7173  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    8559  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    6528  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    7934  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    ...                   ...                   ...                  ...  ...   \n",
       "    3749  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    1637  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    5820  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    5757  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    4135  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "    \n",
       "         Age_TotalSpend Age_TotalSpendRatio   Age_log  Age_sqrt  \\\n",
       "    3586      -0.194111            0.777730  0.317041  0.610786   \n",
       "    7173       0.888540           -3.560043  0.542236  0.848438   \n",
       "    8559      -0.024116           -0.229157  0.542236  0.848438   \n",
       "    6528       0.599833           -2.403304  0.542236  0.848438   \n",
       "    7934       2.162613            1.413441  1.278849  1.610125   \n",
       "    ...             ...                 ...       ...       ...   \n",
       "    3749      -0.158023            0.633138  0.265208  0.551091   \n",
       "    1637      -0.001576           -0.943163  0.542236  0.848438   \n",
       "    5820       0.527657           -2.114119  0.542236  0.848438   \n",
       "    5757       0.055164           -0.260996  0.542236  0.848438   \n",
       "    4135      -0.140830            0.767007  0.458141  0.762320   \n",
       "    \n",
       "         GroupSpendDeviation  RoomService_Dominance FoodCourt_Dominance  \\\n",
       "    3586            0.000000               2.769710            1.560940   \n",
       "    7173           -0.051555               2.769710            1.560940   \n",
       "    8559            0.000000               0.264382           -0.167200   \n",
       "    6528            0.000000               2.769710            1.560940   \n",
       "    7934            0.000000              -0.124232            0.573468   \n",
       "    ...                  ...                    ...                 ...   \n",
       "    3749            0.000000               2.769710            1.560940   \n",
       "    1637            0.000000             -30.404201           -0.117736   \n",
       "    5820            0.000000               2.769710            1.560940   \n",
       "    5757            0.000000              -0.575032           -0.674018   \n",
       "    4135            0.000000             -31.792846           -0.285593   \n",
       "    \n",
       "         ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "    3586               1.990724      1.401816         1.357870  \n",
       "    7173               1.990724      1.401816         1.357870  \n",
       "    8559              -0.177864      1.744477        -0.164865  \n",
       "    6528               1.990724      1.401816         1.357870  \n",
       "    7934              -0.113273      1.383730        -0.086094  \n",
       "    ...                     ...           ...              ...  \n",
       "    3749               1.990724      1.401816         1.357870  \n",
       "    1637              -0.161268     -0.144270        -0.142626  \n",
       "    5820               1.990724      1.401816         1.357870  \n",
       "    5757              -0.693065     -0.137336        -0.342659  \n",
       "    4135              -0.227834     -0.276827        -0.274156  \n",
       "    \n",
       "    [1739 rows x 79 columns]),\n",
       "   'xgboost': (      ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "    1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "    8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "    5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "    4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "    4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "    7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "    426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "    7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "    3600        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    1262        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "    8612        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    5075        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    4758        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "    ...               ...            ...                  ...         ...   \n",
       "    4087        -0.161141      -0.376161            -0.564175    3.168295   \n",
       "    4406        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    7111        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    426         -0.161141      -0.376161             1.772499   -0.315627   \n",
       "    7925        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "    \n",
       "         CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "    3600   -0.302787   -0.242425  ...       1.032894           -4.138413   \n",
       "    1262   -0.302787   -0.242425  ...       0.419391           -1.680341   \n",
       "    8612   -0.302787   -0.242425  ...      -0.230200            0.922323   \n",
       "    5075   -0.302787    4.124990  ...       0.094596           -0.379009   \n",
       "    4758   -0.302787   -0.242425  ...      -1.476003           -0.458639   \n",
       "    ...          ...         ...  ...            ...                 ...   \n",
       "    4087   -0.302787   -0.242425  ...       0.778193            0.560169   \n",
       "    4406   -0.302787   -0.242425  ...      -0.133888            0.819078   \n",
       "    7111   -0.302787   -0.242425  ...      -0.313074            1.568173   \n",
       "    426    -0.302787   -0.242425  ...       0.166773           -0.668194   \n",
       "    7925   -0.302787   -0.242425  ...       0.146632           -0.731514   \n",
       "    \n",
       "           Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3600  0.542236  0.848438           -0.101809               2.769710   \n",
       "    1262  0.542236  0.848438            0.000000               2.769710   \n",
       "    8612  0.366320  0.665144            0.000000               2.769710   \n",
       "    5075  0.542236  0.848438            0.000000               2.769710   \n",
       "    4758  0.542236  0.848438            0.000000              -0.073199   \n",
       "    ...        ...       ...                 ...                    ...   \n",
       "    4087  0.691785  0.998638            0.000000              -0.130693   \n",
       "    4406  0.501072  0.806529            0.000000              -0.150704   \n",
       "    7111  0.758932  1.065830            0.000000              -0.639943   \n",
       "    426   0.542236  0.848438            0.000000               2.769710   \n",
       "    7925  0.542236  0.848438            0.000000              -1.036715   \n",
       "    \n",
       "         FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "    3600            1.560940               1.990724      1.401816         1.357870  \n",
       "    1262            1.560940               1.990724      1.401816         1.357870  \n",
       "    8612            1.560940               1.990724      1.401816         1.357870  \n",
       "    5075            1.560940               1.990724      1.401816         1.357870  \n",
       "    4758           -0.061492              -0.043779     -0.058854       -51.983508  \n",
       "    ...                  ...                    ...           ...              ...  \n",
       "    4087            0.722746              -0.119876     -0.106686         1.185937  \n",
       "    4406           -0.290791              -0.451021     -0.315128         0.236911  \n",
       "    7111           -0.593120              -0.517760     -3.288903        -0.583203  \n",
       "    426             1.560940               1.990724      1.401816         1.357870  \n",
       "    7925           -0.922128              -1.034761     -1.039838        -1.040397  \n",
       "    \n",
       "    [6954 rows x 79 columns],\n",
       "          ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "    7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "    8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "    6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "    7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "    1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "    5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "    5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "    4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "    3586        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    7173        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    8559        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "    6528        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    7934         6.205752      -0.376161            -0.564175   -0.315627   \n",
       "    ...               ...            ...                  ...         ...   \n",
       "    3749        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    1637        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "    5820        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "    5757        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    4135        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "    \n",
       "         CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "    3586   -0.302787   -0.242425  ...      -0.194111            0.777730   \n",
       "    7173   -0.302787   -0.242425  ...       0.888540           -3.560043   \n",
       "    8559   -0.302787   -0.242425  ...      -0.024116           -0.229157   \n",
       "    6528   -0.302787   -0.242425  ...       0.599833           -2.403304   \n",
       "    7934   -0.302787   -0.242425  ...       2.162613            1.413441   \n",
       "    ...          ...         ...  ...            ...                 ...   \n",
       "    3749   -0.302787   -0.242425  ...      -0.158023            0.633138   \n",
       "    1637   -0.302787   -0.242425  ...      -0.001576           -0.943163   \n",
       "    5820   -0.302787   -0.242425  ...       0.527657           -2.114119   \n",
       "    5757   -0.302787   -0.242425  ...       0.055164           -0.260996   \n",
       "    4135   -0.302787   -0.242425  ...      -0.140830            0.767007   \n",
       "    \n",
       "           Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3586  0.317041  0.610786            0.000000               2.769710   \n",
       "    7173  0.542236  0.848438           -0.051555               2.769710   \n",
       "    8559  0.542236  0.848438            0.000000               0.264382   \n",
       "    6528  0.542236  0.848438            0.000000               2.769710   \n",
       "    7934  1.278849  1.610125            0.000000              -0.124232   \n",
       "    ...        ...       ...                 ...                    ...   \n",
       "    3749  0.265208  0.551091            0.000000               2.769710   \n",
       "    1637  0.542236  0.848438            0.000000             -30.404201   \n",
       "    5820  0.542236  0.848438            0.000000               2.769710   \n",
       "    5757  0.542236  0.848438            0.000000              -0.575032   \n",
       "    4135  0.458141  0.762320            0.000000             -31.792846   \n",
       "    \n",
       "         FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "    3586            1.560940               1.990724      1.401816         1.357870  \n",
       "    7173            1.560940               1.990724      1.401816         1.357870  \n",
       "    8559           -0.167200              -0.177864      1.744477        -0.164865  \n",
       "    6528            1.560940               1.990724      1.401816         1.357870  \n",
       "    7934            0.573468              -0.113273      1.383730        -0.086094  \n",
       "    ...                  ...                    ...           ...              ...  \n",
       "    3749            1.560940               1.990724      1.401816         1.357870  \n",
       "    1637           -0.117736              -0.161268     -0.144270        -0.142626  \n",
       "    5820            1.560940               1.990724      1.401816         1.357870  \n",
       "    5757           -0.674018              -0.693065     -0.137336        -0.342659  \n",
       "    4135           -0.285593              -0.227834     -0.276827        -0.274156  \n",
       "    \n",
       "    [1739 rows x 79 columns]),\n",
       "   'random_forest': (      ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "    1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "    8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "    5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "    4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "    4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "    7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "    426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "    7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3600        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1262        -0.161141       2.658437            -0.564175          0.0   \n",
       "    8612        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    5075        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4758        -0.161141       2.658437            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    4087        -0.161141      -0.376161            -0.564175          1.0   \n",
       "    4406        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7111        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    426         -0.161141      -0.376161             1.772499          0.0   \n",
       "    7925        -0.161141      -0.376161             1.772499          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3600          0.0          0.0  ...        1.032894            -4.138413   \n",
       "    1262          0.0          0.0  ...        0.419391            -1.680341   \n",
       "    8612          0.0          0.0  ...       -0.230200             0.922323   \n",
       "    5075          0.0          1.0  ...        0.094596            -0.379009   \n",
       "    4758          0.0          0.0  ...       -1.476003            -0.458639   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    4087          0.0          0.0  ...        0.778193             0.560169   \n",
       "    4406          0.0          0.0  ...       -0.133888             0.819078   \n",
       "    7111          0.0          0.0  ...       -0.313074             1.568173   \n",
       "    426           0.0          0.0  ...        0.166773            -0.668194   \n",
       "    7925          0.0          0.0  ...        0.146632            -0.731514   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3600  0.542236  0.848438            -0.101809               2.769710   \n",
       "    1262  0.542236  0.848438             0.000000               2.769710   \n",
       "    8612  0.366320  0.665144             0.000000               2.769710   \n",
       "    5075  0.542236  0.848438             0.000000               2.769710   \n",
       "    4758  0.542236  0.848438             0.000000              -0.073199   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    4087  0.691785  0.998638             0.000000              -0.130693   \n",
       "    4406  0.501072  0.806529             0.000000              -0.150704   \n",
       "    7111  0.758932  1.065830             0.000000              -0.639943   \n",
       "    426   0.542236  0.848438             0.000000               2.769710   \n",
       "    7925  0.542236  0.848438             0.000000              -1.036715   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3600             1.560940                1.990724       1.401816   \n",
       "    1262             1.560940                1.990724       1.401816   \n",
       "    8612             1.560940                1.990724       1.401816   \n",
       "    5075             1.560940                1.990724       1.401816   \n",
       "    4758            -0.061492               -0.043779      -0.058854   \n",
       "    ...                   ...                     ...            ...   \n",
       "    4087             0.722746               -0.119876      -0.106686   \n",
       "    4406            -0.290791               -0.451021      -0.315128   \n",
       "    7111            -0.593120               -0.517760      -3.288903   \n",
       "    426              1.560940                1.990724       1.401816   \n",
       "    7925            -0.922128               -1.034761      -1.039838   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3600          1.357870  \n",
       "    1262          1.357870  \n",
       "    8612          1.357870  \n",
       "    5075          1.357870  \n",
       "    4758        -51.983508  \n",
       "    ...                ...  \n",
       "    4087          1.185937  \n",
       "    4406          0.236911  \n",
       "    7111         -0.583203  \n",
       "    426           1.357870  \n",
       "    7925         -1.040397  \n",
       "    \n",
       "    [6954 rows x 79 columns],\n",
       "          ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "    7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "    8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "    6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "    7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "    1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "    5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "    5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "    4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3586        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7173        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    8559        -0.161141      -0.376161             1.772499          0.0   \n",
       "    6528        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7934         6.205752      -0.376161            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    3749        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1637        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5820        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5757        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4135        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3586          0.0          0.0  ...       -0.194111             0.777730   \n",
       "    7173          0.0          0.0  ...        0.888540            -3.560043   \n",
       "    8559          0.0          0.0  ...       -0.024116            -0.229157   \n",
       "    6528          0.0          0.0  ...        0.599833            -2.403304   \n",
       "    7934          0.0          0.0  ...        2.162613             1.413441   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    3749          0.0          0.0  ...       -0.158023             0.633138   \n",
       "    1637          0.0          0.0  ...       -0.001576            -0.943163   \n",
       "    5820          0.0          0.0  ...        0.527657            -2.114119   \n",
       "    5757          0.0          0.0  ...        0.055164            -0.260996   \n",
       "    4135          0.0          0.0  ...       -0.140830             0.767007   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3586  0.317041  0.610786             0.000000               2.769710   \n",
       "    7173  0.542236  0.848438            -0.051555               2.769710   \n",
       "    8559  0.542236  0.848438             0.000000               0.264382   \n",
       "    6528  0.542236  0.848438             0.000000               2.769710   \n",
       "    7934  1.278849  1.610125             0.000000              -0.124232   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    3749  0.265208  0.551091             0.000000               2.769710   \n",
       "    1637  0.542236  0.848438             0.000000             -30.404201   \n",
       "    5820  0.542236  0.848438             0.000000               2.769710   \n",
       "    5757  0.542236  0.848438             0.000000              -0.575032   \n",
       "    4135  0.458141  0.762320             0.000000             -31.792846   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3586             1.560940                1.990724       1.401816   \n",
       "    7173             1.560940                1.990724       1.401816   \n",
       "    8559            -0.167200               -0.177864       1.744477   \n",
       "    6528             1.560940                1.990724       1.401816   \n",
       "    7934             0.573468               -0.113273       1.383730   \n",
       "    ...                   ...                     ...            ...   \n",
       "    3749             1.560940                1.990724       1.401816   \n",
       "    1637            -0.117736               -0.161268      -0.144270   \n",
       "    5820             1.560940                1.990724       1.401816   \n",
       "    5757            -0.674018               -0.693065      -0.137336   \n",
       "    4135            -0.285593               -0.227834      -0.276827   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3586          1.357870  \n",
       "    7173          1.357870  \n",
       "    8559         -0.164865  \n",
       "    6528          1.357870  \n",
       "    7934         -0.086094  \n",
       "    ...                ...  \n",
       "    3749          1.357870  \n",
       "    1637         -0.142626  \n",
       "    5820          1.357870  \n",
       "    5757         -0.342659  \n",
       "    4135         -0.274156  \n",
       "    \n",
       "    [1739 rows x 79 columns]),\n",
       "   'gradient_boosting': (      ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "    1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "    8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "    5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "    4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "    4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "    7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "    426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "    7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3600        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1262        -0.161141       2.658437            -0.564175          0.0   \n",
       "    8612        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    5075        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4758        -0.161141       2.658437            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    4087        -0.161141      -0.376161            -0.564175          1.0   \n",
       "    4406        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7111        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    426         -0.161141      -0.376161             1.772499          0.0   \n",
       "    7925        -0.161141      -0.376161             1.772499          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3600          0.0          0.0  ...        1.032894            -4.138413   \n",
       "    1262          0.0          0.0  ...        0.419391            -1.680341   \n",
       "    8612          0.0          0.0  ...       -0.230200             0.922323   \n",
       "    5075          0.0          1.0  ...        0.094596            -0.379009   \n",
       "    4758          0.0          0.0  ...       -1.476003            -0.458639   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    4087          0.0          0.0  ...        0.778193             0.560169   \n",
       "    4406          0.0          0.0  ...       -0.133888             0.819078   \n",
       "    7111          0.0          0.0  ...       -0.313074             1.568173   \n",
       "    426           0.0          0.0  ...        0.166773            -0.668194   \n",
       "    7925          0.0          0.0  ...        0.146632            -0.731514   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3600  0.542236  0.848438            -0.101809               2.769710   \n",
       "    1262  0.542236  0.848438             0.000000               2.769710   \n",
       "    8612  0.366320  0.665144             0.000000               2.769710   \n",
       "    5075  0.542236  0.848438             0.000000               2.769710   \n",
       "    4758  0.542236  0.848438             0.000000              -0.073199   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    4087  0.691785  0.998638             0.000000              -0.130693   \n",
       "    4406  0.501072  0.806529             0.000000              -0.150704   \n",
       "    7111  0.758932  1.065830             0.000000              -0.639943   \n",
       "    426   0.542236  0.848438             0.000000               2.769710   \n",
       "    7925  0.542236  0.848438             0.000000              -1.036715   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3600             1.560940                1.990724       1.401816   \n",
       "    1262             1.560940                1.990724       1.401816   \n",
       "    8612             1.560940                1.990724       1.401816   \n",
       "    5075             1.560940                1.990724       1.401816   \n",
       "    4758            -0.061492               -0.043779      -0.058854   \n",
       "    ...                   ...                     ...            ...   \n",
       "    4087             0.722746               -0.119876      -0.106686   \n",
       "    4406            -0.290791               -0.451021      -0.315128   \n",
       "    7111            -0.593120               -0.517760      -3.288903   \n",
       "    426              1.560940                1.990724       1.401816   \n",
       "    7925            -0.922128               -1.034761      -1.039838   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3600          1.357870  \n",
       "    1262          1.357870  \n",
       "    8612          1.357870  \n",
       "    5075          1.357870  \n",
       "    4758        -51.983508  \n",
       "    ...                ...  \n",
       "    4087          1.185937  \n",
       "    4406          0.236911  \n",
       "    7111         -0.583203  \n",
       "    426           1.357870  \n",
       "    7925         -1.040397  \n",
       "    \n",
       "    [6954 rows x 79 columns],\n",
       "          ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "    7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "    8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "    6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "    7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "    1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "    5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "    5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "    4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3586        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7173        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    8559        -0.161141      -0.376161             1.772499          0.0   \n",
       "    6528        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7934         6.205752      -0.376161            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    3749        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1637        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5820        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5757        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4135        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3586          0.0          0.0  ...       -0.194111             0.777730   \n",
       "    7173          0.0          0.0  ...        0.888540            -3.560043   \n",
       "    8559          0.0          0.0  ...       -0.024116            -0.229157   \n",
       "    6528          0.0          0.0  ...        0.599833            -2.403304   \n",
       "    7934          0.0          0.0  ...        2.162613             1.413441   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    3749          0.0          0.0  ...       -0.158023             0.633138   \n",
       "    1637          0.0          0.0  ...       -0.001576            -0.943163   \n",
       "    5820          0.0          0.0  ...        0.527657            -2.114119   \n",
       "    5757          0.0          0.0  ...        0.055164            -0.260996   \n",
       "    4135          0.0          0.0  ...       -0.140830             0.767007   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3586  0.317041  0.610786             0.000000               2.769710   \n",
       "    7173  0.542236  0.848438            -0.051555               2.769710   \n",
       "    8559  0.542236  0.848438             0.000000               0.264382   \n",
       "    6528  0.542236  0.848438             0.000000               2.769710   \n",
       "    7934  1.278849  1.610125             0.000000              -0.124232   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    3749  0.265208  0.551091             0.000000               2.769710   \n",
       "    1637  0.542236  0.848438             0.000000             -30.404201   \n",
       "    5820  0.542236  0.848438             0.000000               2.769710   \n",
       "    5757  0.542236  0.848438             0.000000              -0.575032   \n",
       "    4135  0.458141  0.762320             0.000000             -31.792846   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3586             1.560940                1.990724       1.401816   \n",
       "    7173             1.560940                1.990724       1.401816   \n",
       "    8559            -0.167200               -0.177864       1.744477   \n",
       "    6528             1.560940                1.990724       1.401816   \n",
       "    7934             0.573468               -0.113273       1.383730   \n",
       "    ...                   ...                     ...            ...   \n",
       "    3749             1.560940                1.990724       1.401816   \n",
       "    1637            -0.117736               -0.161268      -0.144270   \n",
       "    5820             1.560940                1.990724       1.401816   \n",
       "    5757            -0.674018               -0.693065      -0.137336   \n",
       "    4135            -0.285593               -0.227834      -0.276827   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3586          1.357870  \n",
       "    7173          1.357870  \n",
       "    8559         -0.164865  \n",
       "    6528          1.357870  \n",
       "    7934         -0.086094  \n",
       "    ...                ...  \n",
       "    3749          1.357870  \n",
       "    1637         -0.142626  \n",
       "    5820          1.357870  \n",
       "    5757         -0.342659  \n",
       "    4135         -0.274156  \n",
       "    \n",
       "    [1739 rows x 79 columns]),\n",
       "   'extra_trees': (      ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "    1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "    8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "    5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "    4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "    4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "    7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "    426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "    7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3600        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1262        -0.161141       2.658437            -0.564175          0.0   \n",
       "    8612        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    5075        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4758        -0.161141       2.658437            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    4087        -0.161141      -0.376161            -0.564175          1.0   \n",
       "    4406        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7111        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    426         -0.161141      -0.376161             1.772499          0.0   \n",
       "    7925        -0.161141      -0.376161             1.772499          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3600          0.0          0.0  ...        1.032894            -4.138413   \n",
       "    1262          0.0          0.0  ...        0.419391            -1.680341   \n",
       "    8612          0.0          0.0  ...       -0.230200             0.922323   \n",
       "    5075          0.0          1.0  ...        0.094596            -0.379009   \n",
       "    4758          0.0          0.0  ...       -1.476003            -0.458639   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    4087          0.0          0.0  ...        0.778193             0.560169   \n",
       "    4406          0.0          0.0  ...       -0.133888             0.819078   \n",
       "    7111          0.0          0.0  ...       -0.313074             1.568173   \n",
       "    426           0.0          0.0  ...        0.166773            -0.668194   \n",
       "    7925          0.0          0.0  ...        0.146632            -0.731514   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3600  0.542236  0.848438            -0.101809               2.769710   \n",
       "    1262  0.542236  0.848438             0.000000               2.769710   \n",
       "    8612  0.366320  0.665144             0.000000               2.769710   \n",
       "    5075  0.542236  0.848438             0.000000               2.769710   \n",
       "    4758  0.542236  0.848438             0.000000              -0.073199   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    4087  0.691785  0.998638             0.000000              -0.130693   \n",
       "    4406  0.501072  0.806529             0.000000              -0.150704   \n",
       "    7111  0.758932  1.065830             0.000000              -0.639943   \n",
       "    426   0.542236  0.848438             0.000000               2.769710   \n",
       "    7925  0.542236  0.848438             0.000000              -1.036715   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3600             1.560940                1.990724       1.401816   \n",
       "    1262             1.560940                1.990724       1.401816   \n",
       "    8612             1.560940                1.990724       1.401816   \n",
       "    5075             1.560940                1.990724       1.401816   \n",
       "    4758            -0.061492               -0.043779      -0.058854   \n",
       "    ...                   ...                     ...            ...   \n",
       "    4087             0.722746               -0.119876      -0.106686   \n",
       "    4406            -0.290791               -0.451021      -0.315128   \n",
       "    7111            -0.593120               -0.517760      -3.288903   \n",
       "    426              1.560940                1.990724       1.401816   \n",
       "    7925            -0.922128               -1.034761      -1.039838   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3600          1.357870  \n",
       "    1262          1.357870  \n",
       "    8612          1.357870  \n",
       "    5075          1.357870  \n",
       "    4758        -51.983508  \n",
       "    ...                ...  \n",
       "    4087          1.185937  \n",
       "    4406          0.236911  \n",
       "    7111         -0.583203  \n",
       "    426           1.357870  \n",
       "    7925         -1.040397  \n",
       "    \n",
       "    [6954 rows x 79 columns],\n",
       "          ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "    3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "    7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "    8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "    6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "    7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "    ...             ...       ...             ...                 ...   \n",
       "    3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "    1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "    5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "    5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "    4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "    \n",
       "          AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "    3586        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7173        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    8559        -0.161141      -0.376161             1.772499          0.0   \n",
       "    6528        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    7934         6.205752      -0.376161            -0.564175          0.0   \n",
       "    ...               ...            ...                  ...          ...   \n",
       "    3749        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    1637        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5820        -0.161141       2.658437            -0.564175          0.0   \n",
       "    5757        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    4135        -0.161141      -0.376161            -0.564175          0.0   \n",
       "    \n",
       "          CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "    3586          0.0          0.0  ...       -0.194111             0.777730   \n",
       "    7173          0.0          0.0  ...        0.888540            -3.560043   \n",
       "    8559          0.0          0.0  ...       -0.024116            -0.229157   \n",
       "    6528          0.0          0.0  ...        0.599833            -2.403304   \n",
       "    7934          0.0          0.0  ...        2.162613             1.413441   \n",
       "    ...           ...          ...  ...             ...                  ...   \n",
       "    3749          0.0          0.0  ...       -0.158023             0.633138   \n",
       "    1637          0.0          0.0  ...       -0.001576            -0.943163   \n",
       "    5820          0.0          0.0  ...        0.527657            -2.114119   \n",
       "    5757          0.0          0.0  ...        0.055164            -0.260996   \n",
       "    4135          0.0          0.0  ...       -0.140830             0.767007   \n",
       "    \n",
       "           Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "    3586  0.317041  0.610786             0.000000               2.769710   \n",
       "    7173  0.542236  0.848438            -0.051555               2.769710   \n",
       "    8559  0.542236  0.848438             0.000000               0.264382   \n",
       "    6528  0.542236  0.848438             0.000000               2.769710   \n",
       "    7934  1.278849  1.610125             0.000000              -0.124232   \n",
       "    ...        ...       ...                  ...                    ...   \n",
       "    3749  0.265208  0.551091             0.000000               2.769710   \n",
       "    1637  0.542236  0.848438             0.000000             -30.404201   \n",
       "    5820  0.542236  0.848438             0.000000               2.769710   \n",
       "    5757  0.542236  0.848438             0.000000              -0.575032   \n",
       "    4135  0.458141  0.762320             0.000000             -31.792846   \n",
       "    \n",
       "          FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "    3586             1.560940                1.990724       1.401816   \n",
       "    7173             1.560940                1.990724       1.401816   \n",
       "    8559            -0.167200               -0.177864       1.744477   \n",
       "    6528             1.560940                1.990724       1.401816   \n",
       "    7934             0.573468               -0.113273       1.383730   \n",
       "    ...                   ...                     ...            ...   \n",
       "    3749             1.560940                1.990724       1.401816   \n",
       "    1637            -0.117736               -0.161268      -0.144270   \n",
       "    5820             1.560940                1.990724       1.401816   \n",
       "    5757            -0.674018               -0.693065      -0.137336   \n",
       "    4135            -0.285593               -0.227834      -0.276827   \n",
       "    \n",
       "          VRDeck_Dominance  \n",
       "    3586          1.357870  \n",
       "    7173          1.357870  \n",
       "    8559         -0.164865  \n",
       "    6528          1.357870  \n",
       "    7934         -0.086094  \n",
       "    ...                ...  \n",
       "    3749          1.357870  \n",
       "    1637         -0.142626  \n",
       "    5820          1.357870  \n",
       "    5757         -0.342659  \n",
       "    4135         -0.274156  \n",
       "    \n",
       "    [1739 rows x 79 columns])},\n",
       "  'meta_score': 0.8223116733755031},\n",
       " 'submission':      PassengerId  Transported\n",
       " 0        0013_01        False\n",
       " 1        0018_01        False\n",
       " 2        0019_01         True\n",
       " 3        0021_01         True\n",
       " 4        0023_01        False\n",
       " ...          ...          ...\n",
       " 4272     9266_02         True\n",
       " 4273     9269_01        False\n",
       " 4274     9271_01         True\n",
       " 4275     9273_01         True\n",
       " 4276     9277_01         True\n",
       " \n",
       " [4277 rows x 2 columns],\n",
       " 'data_dict': {'X_train':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "  1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "  8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "  5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "  4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "  4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "  7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "  426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "  7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  3600        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1262        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  8612        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  5075        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4758        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  4087        -0.161141      -0.376161            -0.564175    3.168295   \n",
       "  4406        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7111        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  426         -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  7925        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  3600   -0.302787   -0.242425  ...       1.032894           -4.138413   \n",
       "  1262   -0.302787   -0.242425  ...       0.419391           -1.680341   \n",
       "  8612   -0.302787   -0.242425  ...      -0.230200            0.922323   \n",
       "  5075   -0.302787     4.12499  ...       0.094596           -0.379009   \n",
       "  4758   -0.302787   -0.242425  ...      -1.476003           -0.458639   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  4087   -0.302787   -0.242425  ...       0.778193            0.560169   \n",
       "  4406   -0.302787   -0.242425  ...      -0.133888            0.819078   \n",
       "  7111   -0.302787   -0.242425  ...      -0.313074            1.568173   \n",
       "  426    -0.302787   -0.242425  ...       0.166773           -0.668194   \n",
       "  7925   -0.302787   -0.242425  ...       0.146632           -0.731514   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3600  0.542236  0.848438           -0.101809               2.769710   \n",
       "  1262  0.542236  0.848438            0.000000               2.769710   \n",
       "  8612  0.366320  0.665144            0.000000               2.769710   \n",
       "  5075  0.542236  0.848438            0.000000               2.769710   \n",
       "  4758  0.542236  0.848438            0.000000              -0.073199   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  4087  0.691785  0.998638            0.000000              -0.130693   \n",
       "  4406  0.501072  0.806529            0.000000              -0.150704   \n",
       "  7111  0.758932  1.065830            0.000000              -0.639943   \n",
       "  426   0.542236  0.848438            0.000000               2.769710   \n",
       "  7925  0.542236  0.848438            0.000000              -1.036715   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3600            1.560940               1.990724      1.401816         1.357870  \n",
       "  1262            1.560940               1.990724      1.401816         1.357870  \n",
       "  8612            1.560940               1.990724      1.401816         1.357870  \n",
       "  5075            1.560940               1.990724      1.401816         1.357870  \n",
       "  4758           -0.061492              -0.043779     -0.058854       -51.983508  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  4087            0.722746              -0.119876     -0.106686         1.185937  \n",
       "  4406           -0.290791              -0.451021     -0.315128         0.236911  \n",
       "  7111           -0.593120              -0.517760     -3.288903        -0.583203  \n",
       "  426             1.560940               1.990724      1.401816         1.357870  \n",
       "  7925           -0.922128              -1.034761     -1.039838        -1.040397  \n",
       "  \n",
       "  [6954 rows x 79 columns],\n",
       "  'X_val':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "  8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "  6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "  7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "  1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "  5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "  5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "  4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  3586        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7173        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  8559        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  6528        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7934         6.205752      -0.376161            -0.564175   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  3749        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1637        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  5820        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  5757        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4135        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  3586   -0.302787   -0.242425  ...      -0.194111            0.777730   \n",
       "  7173   -0.302787   -0.242425  ...       0.888540           -3.560043   \n",
       "  8559   -0.302787   -0.242425  ...      -0.024116           -0.229157   \n",
       "  6528   -0.302787   -0.242425  ...       0.599833           -2.403304   \n",
       "  7934   -0.302787   -0.242425  ...       2.162613            1.413441   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  3749   -0.302787   -0.242425  ...      -0.158023            0.633138   \n",
       "  1637   -0.302787   -0.242425  ...      -0.001576           -0.943163   \n",
       "  5820   -0.302787   -0.242425  ...       0.527657           -2.114119   \n",
       "  5757   -0.302787   -0.242425  ...       0.055164           -0.260996   \n",
       "  4135   -0.302787   -0.242425  ...      -0.140830            0.767007   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3586  0.317041  0.610786            0.000000               2.769710   \n",
       "  7173  0.542236  0.848438           -0.051555               2.769710   \n",
       "  8559  0.542236  0.848438            0.000000               0.264382   \n",
       "  6528  0.542236  0.848438            0.000000               2.769710   \n",
       "  7934  1.278849  1.610125            0.000000              -0.124232   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  3749  0.265208  0.551091            0.000000               2.769710   \n",
       "  1637  0.542236  0.848438            0.000000             -30.404201   \n",
       "  5820  0.542236  0.848438            0.000000               2.769710   \n",
       "  5757  0.542236  0.848438            0.000000              -0.575032   \n",
       "  4135  0.458141  0.762320            0.000000             -31.792846   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3586            1.560940               1.990724      1.401816         1.357870  \n",
       "  7173            1.560940               1.990724      1.401816         1.357870  \n",
       "  8559           -0.167200              -0.177864      1.744477        -0.164865  \n",
       "  6528            1.560940               1.990724      1.401816         1.357870  \n",
       "  7934            0.573468              -0.113273      1.383730        -0.086094  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  3749            1.560940               1.990724      1.401816         1.357870  \n",
       "  1637           -0.117736              -0.161268     -0.144270        -0.142626  \n",
       "  5820            1.560940               1.990724      1.401816         1.357870  \n",
       "  5757           -0.674018              -0.693065     -0.137336        -0.342659  \n",
       "  4135           -0.285593              -0.227834     -0.276827        -0.274156  \n",
       "  \n",
       "  [1739 rows x 79 columns],\n",
       "  'X_test':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  0         -1.165370 -0.112444        1.398797           -0.458742   \n",
       "  1          0.858096 -0.667306       -0.714900           -0.458742   \n",
       "  2         -1.165370  0.164986        1.398797           -0.458742   \n",
       "  3          0.858096  0.650490        1.398797           -0.458742   \n",
       "  4          0.858096 -0.597948       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4272      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  4273       0.858096  0.927920       -0.714900            2.179876   \n",
       "  4274      -1.165370 -0.043087        1.398797           -0.458742   \n",
       "  4275       0.858096  0.234344        1.398797           -0.458742   \n",
       "  4276      -1.165370  0.997278       -0.714900            2.179876   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  0           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1           -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  2           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  3           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4           -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  4272        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4273        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4274        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4275        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4276        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  0      -0.302787   -0.242425  ...       0.058507           -0.234417   \n",
       "  1      -0.302787   -0.242425  ...      -0.335932           -0.443860   \n",
       "  2       3.302656   -0.242425  ...      -0.085846            0.343953   \n",
       "  3       3.302656   -0.242425  ...       1.405844            0.205772   \n",
       "  4      -0.302787   -0.242425  ...       0.171708           -0.838827   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  4272   -0.302787   -0.242425  ...      -0.194111            0.777730   \n",
       "  4273   -0.302787   -0.242425  ...      -0.141347            1.094667   \n",
       "  4274   -0.302787     4.12499  ...       0.022419           -0.089824   \n",
       "  4275   -0.302787     4.12499  ...       0.149401            0.143108   \n",
       "  4276   -0.302787   -0.242425  ...      -0.518907            2.079062   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  0     0.542236  0.848438            0.000000               2.769710   \n",
       "  1     0.542236  0.848438            0.000000              -0.142436   \n",
       "  2     0.152709  0.406185            0.000000               2.769710   \n",
       "  3     0.501072  0.806529            0.000000              -0.071246   \n",
       "  4     0.542236  0.848438            0.000000              -0.309187   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  4272  0.317041  0.610786           -0.128399               2.769710   \n",
       "  4273  0.656442  0.963286            0.000000              -0.582939   \n",
       "  4274  0.542236  0.848438            0.000000               2.769710   \n",
       "  4275  0.210540  0.484091            0.000000              -0.166296   \n",
       "  4276  0.691785  0.998638            0.000000               2.769710   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  0               1.560940               1.990724      1.401816         1.357870  \n",
       "  1              -0.118950              -0.130793    -11.947877        -0.115190  \n",
       "  2               1.560940               1.990724      1.401816         1.357870  \n",
       "  3               7.707147              -0.064982     -0.024117         0.062999  \n",
       "  4              -0.279729              -6.195552     -0.271075        -0.268438  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  4272            1.560940               1.990724      1.401816         1.357870  \n",
       "  4273          -24.993834              -0.532069     -0.517806        -0.359005  \n",
       "  4274            1.560940               1.990724      1.401816         1.357870  \n",
       "  4275            4.829713              -0.153051     -0.136778         0.137916  \n",
       "  4276            1.560940               1.990724      1.401816         1.357870  \n",
       "  \n",
       "  [4277 rows x 79 columns],\n",
       "  'y_train': 3600    1\n",
       "  1262    1\n",
       "  8612    0\n",
       "  5075    1\n",
       "  4758    0\n",
       "         ..\n",
       "  4087    1\n",
       "  4406    0\n",
       "  7111    1\n",
       "  426     1\n",
       "  7925    1\n",
       "  Name: Transported, Length: 6954, dtype: int64,\n",
       "  'y_val': 3586    1\n",
       "  7173    0\n",
       "  8559    0\n",
       "  6528    1\n",
       "  7934    0\n",
       "         ..\n",
       "  3749    1\n",
       "  1637    0\n",
       "  5820    1\n",
       "  5757    0\n",
       "  4135    1\n",
       "  Name: Transported, Length: 1739, dtype: int64,\n",
       "  'train_ids': 0       0001_01\n",
       "  1       0002_01\n",
       "  2       0003_01\n",
       "  3       0003_02\n",
       "  4       0004_01\n",
       "           ...   \n",
       "  8688    9276_01\n",
       "  8689    9278_01\n",
       "  8690    9279_01\n",
       "  8691    9280_01\n",
       "  8692    9280_02\n",
       "  Name: PassengerId, Length: 8693, dtype: object,\n",
       "  'test_ids': 0       0013_01\n",
       "  1       0018_01\n",
       "  2       0019_01\n",
       "  3       0021_01\n",
       "  4       0023_01\n",
       "           ...   \n",
       "  4272    9266_02\n",
       "  4273    9269_01\n",
       "  4274    9271_01\n",
       "  4275    9273_01\n",
       "  4276    9277_01\n",
       "  Name: PassengerId, Length: 4277, dtype: object,\n",
       "  'preserved_categorical_cols': ['cat_HomePlanet',\n",
       "   'cat_Destination',\n",
       "   'cat_CabinDeck',\n",
       "   'cat_CabinSide',\n",
       "   'cat_AgeGroup',\n",
       "   'cat_Route'],\n",
       "  'X_train_catboost':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "  1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "  8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "  5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "  4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "  4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "  7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "  426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "  7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  \\\n",
       "  3600        -0.161141      -0.376161            -0.564175   \n",
       "  1262        -0.161141       2.658437            -0.564175   \n",
       "  8612        -0.161141      -0.376161            -0.564175   \n",
       "  5075        -0.161141      -0.376161            -0.564175   \n",
       "  4758        -0.161141       2.658437            -0.564175   \n",
       "  ...               ...            ...                  ...   \n",
       "  4087        -0.161141      -0.376161            -0.564175   \n",
       "  4406        -0.161141      -0.376161            -0.564175   \n",
       "  7111        -0.161141      -0.376161            -0.564175   \n",
       "  426         -0.161141      -0.376161             1.772499   \n",
       "  7925        -0.161141      -0.376161             1.772499   \n",
       "  \n",
       "                CabinDeck_B           CabinDeck_C          CabinDeck_D  ...  \\\n",
       "  3600  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  1262  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  8612  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  5075  -0.3156271429370956  -0.30278663910847514    4.124990186830846  ...   \n",
       "  4758  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  ...                   ...                   ...                  ...  ...   \n",
       "  4087    3.168295320530464  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  4406  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  7111  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  426   -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  7925  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  \n",
       "       Age_TotalSpend Age_TotalSpendRatio   Age_log  Age_sqrt  \\\n",
       "  3600       1.032894           -4.138413  0.542236  0.848438   \n",
       "  1262       0.419391           -1.680341  0.542236  0.848438   \n",
       "  8612      -0.230200            0.922323  0.366320  0.665144   \n",
       "  5075       0.094596           -0.379009  0.542236  0.848438   \n",
       "  4758      -1.476003           -0.458639  0.542236  0.848438   \n",
       "  ...             ...                 ...       ...       ...   \n",
       "  4087       0.778193            0.560169  0.691785  0.998638   \n",
       "  4406      -0.133888            0.819078  0.501072  0.806529   \n",
       "  7111      -0.313074            1.568173  0.758932  1.065830   \n",
       "  426        0.166773           -0.668194  0.542236  0.848438   \n",
       "  7925       0.146632           -0.731514  0.542236  0.848438   \n",
       "  \n",
       "       GroupSpendDeviation  RoomService_Dominance FoodCourt_Dominance  \\\n",
       "  3600           -0.101809               2.769710            1.560940   \n",
       "  1262            0.000000               2.769710            1.560940   \n",
       "  8612            0.000000               2.769710            1.560940   \n",
       "  5075            0.000000               2.769710            1.560940   \n",
       "  4758            0.000000              -0.073199           -0.061492   \n",
       "  ...                  ...                    ...                 ...   \n",
       "  4087            0.000000              -0.130693            0.722746   \n",
       "  4406            0.000000              -0.150704           -0.290791   \n",
       "  7111            0.000000              -0.639943           -0.593120   \n",
       "  426             0.000000               2.769710            1.560940   \n",
       "  7925            0.000000              -1.036715           -0.922128   \n",
       "  \n",
       "       ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3600               1.990724      1.401816         1.357870  \n",
       "  1262               1.990724      1.401816         1.357870  \n",
       "  8612               1.990724      1.401816         1.357870  \n",
       "  5075               1.990724      1.401816         1.357870  \n",
       "  4758              -0.043779     -0.058854       -51.983508  \n",
       "  ...                     ...           ...              ...  \n",
       "  4087              -0.119876     -0.106686         1.185937  \n",
       "  4406              -0.451021     -0.315128         0.236911  \n",
       "  7111              -0.517760     -3.288903        -0.583203  \n",
       "  426                1.990724      1.401816         1.357870  \n",
       "  7925              -1.034761     -1.039838        -1.040397  \n",
       "  \n",
       "  [6954 rows x 79 columns],\n",
       "  'X_val_catboost':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "  8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "  6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "  7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "  1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "  5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "  5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "  4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  \\\n",
       "  3586        -0.161141      -0.376161            -0.564175   \n",
       "  7173        -0.161141      -0.376161            -0.564175   \n",
       "  8559        -0.161141      -0.376161             1.772499   \n",
       "  6528        -0.161141      -0.376161            -0.564175   \n",
       "  7934         6.205752      -0.376161            -0.564175   \n",
       "  ...               ...            ...                  ...   \n",
       "  3749        -0.161141      -0.376161            -0.564175   \n",
       "  1637        -0.161141       2.658437            -0.564175   \n",
       "  5820        -0.161141       2.658437            -0.564175   \n",
       "  5757        -0.161141      -0.376161            -0.564175   \n",
       "  4135        -0.161141      -0.376161            -0.564175   \n",
       "  \n",
       "                CabinDeck_B           CabinDeck_C          CabinDeck_D  ...  \\\n",
       "  3586  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  7173  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  8559  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  6528  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  7934  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  ...                   ...                   ...                  ...  ...   \n",
       "  3749  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  1637  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  5820  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  5757  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  4135  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  \n",
       "       Age_TotalSpend Age_TotalSpendRatio   Age_log  Age_sqrt  \\\n",
       "  3586      -0.194111            0.777730  0.317041  0.610786   \n",
       "  7173       0.888540           -3.560043  0.542236  0.848438   \n",
       "  8559      -0.024116           -0.229157  0.542236  0.848438   \n",
       "  6528       0.599833           -2.403304  0.542236  0.848438   \n",
       "  7934       2.162613            1.413441  1.278849  1.610125   \n",
       "  ...             ...                 ...       ...       ...   \n",
       "  3749      -0.158023            0.633138  0.265208  0.551091   \n",
       "  1637      -0.001576           -0.943163  0.542236  0.848438   \n",
       "  5820       0.527657           -2.114119  0.542236  0.848438   \n",
       "  5757       0.055164           -0.260996  0.542236  0.848438   \n",
       "  4135      -0.140830            0.767007  0.458141  0.762320   \n",
       "  \n",
       "       GroupSpendDeviation  RoomService_Dominance FoodCourt_Dominance  \\\n",
       "  3586            0.000000               2.769710            1.560940   \n",
       "  7173           -0.051555               2.769710            1.560940   \n",
       "  8559            0.000000               0.264382           -0.167200   \n",
       "  6528            0.000000               2.769710            1.560940   \n",
       "  7934            0.000000              -0.124232            0.573468   \n",
       "  ...                  ...                    ...                 ...   \n",
       "  3749            0.000000               2.769710            1.560940   \n",
       "  1637            0.000000             -30.404201           -0.117736   \n",
       "  5820            0.000000               2.769710            1.560940   \n",
       "  5757            0.000000              -0.575032           -0.674018   \n",
       "  4135            0.000000             -31.792846           -0.285593   \n",
       "  \n",
       "       ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3586               1.990724      1.401816         1.357870  \n",
       "  7173               1.990724      1.401816         1.357870  \n",
       "  8559              -0.177864      1.744477        -0.164865  \n",
       "  6528               1.990724      1.401816         1.357870  \n",
       "  7934              -0.113273      1.383730        -0.086094  \n",
       "  ...                     ...           ...              ...  \n",
       "  3749               1.990724      1.401816         1.357870  \n",
       "  1637              -0.161268     -0.144270        -0.142626  \n",
       "  5820               1.990724      1.401816         1.357870  \n",
       "  5757              -0.693065     -0.137336        -0.342659  \n",
       "  4135              -0.227834     -0.276827        -0.274156  \n",
       "  \n",
       "  [1739 rows x 79 columns],\n",
       "  'X_test_catboost':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  0         -1.165370 -0.112444        1.398797           -0.458742   \n",
       "  1          0.858096 -0.667306       -0.714900           -0.458742   \n",
       "  2         -1.165370  0.164986        1.398797           -0.458742   \n",
       "  3          0.858096  0.650490        1.398797           -0.458742   \n",
       "  4          0.858096 -0.597948       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4272      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  4273       0.858096  0.927920       -0.714900            2.179876   \n",
       "  4274      -1.165370 -0.043087        1.398797           -0.458742   \n",
       "  4275       0.858096  0.234344        1.398797           -0.458742   \n",
       "  4276      -1.165370  0.997278       -0.714900            2.179876   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  \\\n",
       "  0           -0.161141      -0.376161            -0.564175   \n",
       "  1           -0.161141      -0.376161             1.772499   \n",
       "  2           -0.161141      -0.376161            -0.564175   \n",
       "  3           -0.161141      -0.376161            -0.564175   \n",
       "  4           -0.161141      -0.376161             1.772499   \n",
       "  ...               ...            ...                  ...   \n",
       "  4272        -0.161141      -0.376161            -0.564175   \n",
       "  4273        -0.161141      -0.376161            -0.564175   \n",
       "  4274        -0.161141      -0.376161            -0.564175   \n",
       "  4275        -0.161141      -0.376161            -0.564175   \n",
       "  4276        -0.161141      -0.376161            -0.564175   \n",
       "  \n",
       "                CabinDeck_B           CabinDeck_C          CabinDeck_D  ...  \\\n",
       "  0     -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  1     -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  2     -0.3156271429370956    3.3026556354811416  -0.2424248191407897  ...   \n",
       "  3     -0.3156271429370956    3.3026556354811416  -0.2424248191407897  ...   \n",
       "  4     -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  ...                   ...                   ...                  ...  ...   \n",
       "  4272  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  4273  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  4274  -0.3156271429370956  -0.30278663910847514    4.124990186830846  ...   \n",
       "  4275  -0.3156271429370956  -0.30278663910847514    4.124990186830846  ...   \n",
       "  4276  -0.3156271429370956  -0.30278663910847514  -0.2424248191407897  ...   \n",
       "  \n",
       "       Age_TotalSpend Age_TotalSpendRatio   Age_log  Age_sqrt  \\\n",
       "  0          0.058507           -0.234417  0.542236  0.848438   \n",
       "  1         -0.335932           -0.443860  0.542236  0.848438   \n",
       "  2         -0.085846            0.343953  0.152709  0.406185   \n",
       "  3          1.405844            0.205772  0.501072  0.806529   \n",
       "  4          0.171708           -0.838827  0.542236  0.848438   \n",
       "  ...             ...                 ...       ...       ...   \n",
       "  4272      -0.194111            0.777730  0.317041  0.610786   \n",
       "  4273      -0.141347            1.094667  0.656442  0.963286   \n",
       "  4274       0.022419           -0.089824  0.542236  0.848438   \n",
       "  4275       0.149401            0.143108  0.210540  0.484091   \n",
       "  4276      -0.518907            2.079062  0.691785  0.998638   \n",
       "  \n",
       "       GroupSpendDeviation  RoomService_Dominance FoodCourt_Dominance  \\\n",
       "  0               0.000000               2.769710            1.560940   \n",
       "  1               0.000000              -0.142436           -0.118950   \n",
       "  2               0.000000               2.769710            1.560940   \n",
       "  3               0.000000              -0.071246            7.707147   \n",
       "  4               0.000000              -0.309187           -0.279729   \n",
       "  ...                  ...                    ...                 ...   \n",
       "  4272           -0.128399               2.769710            1.560940   \n",
       "  4273            0.000000              -0.582939          -24.993834   \n",
       "  4274            0.000000               2.769710            1.560940   \n",
       "  4275            0.000000              -0.166296            4.829713   \n",
       "  4276            0.000000               2.769710            1.560940   \n",
       "  \n",
       "       ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  0                  1.990724      1.401816         1.357870  \n",
       "  1                 -0.130793    -11.947877        -0.115190  \n",
       "  2                  1.990724      1.401816         1.357870  \n",
       "  3                 -0.064982     -0.024117         0.062999  \n",
       "  4                 -6.195552     -0.271075        -0.268438  \n",
       "  ...                     ...           ...              ...  \n",
       "  4272               1.990724      1.401816         1.357870  \n",
       "  4273              -0.532069     -0.517806        -0.359005  \n",
       "  4274               1.990724      1.401816         1.357870  \n",
       "  4275              -0.153051     -0.136778         0.137916  \n",
       "  4276               1.990724      1.401816         1.357870  \n",
       "  \n",
       "  [4277 rows x 79 columns],\n",
       "  'X_train_xgb':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "  1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "  8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "  5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "  4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "  4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "  7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "  426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "  7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  3600        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1262        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  8612        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  5075        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4758        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  4087        -0.161141      -0.376161            -0.564175    3.168295   \n",
       "  4406        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7111        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  426         -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  7925        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  3600   -0.302787   -0.242425  ...       1.032894           -4.138413   \n",
       "  1262   -0.302787   -0.242425  ...       0.419391           -1.680341   \n",
       "  8612   -0.302787   -0.242425  ...      -0.230200            0.922323   \n",
       "  5075   -0.302787    4.124990  ...       0.094596           -0.379009   \n",
       "  4758   -0.302787   -0.242425  ...      -1.476003           -0.458639   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  4087   -0.302787   -0.242425  ...       0.778193            0.560169   \n",
       "  4406   -0.302787   -0.242425  ...      -0.133888            0.819078   \n",
       "  7111   -0.302787   -0.242425  ...      -0.313074            1.568173   \n",
       "  426    -0.302787   -0.242425  ...       0.166773           -0.668194   \n",
       "  7925   -0.302787   -0.242425  ...       0.146632           -0.731514   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3600  0.542236  0.848438           -0.101809               2.769710   \n",
       "  1262  0.542236  0.848438            0.000000               2.769710   \n",
       "  8612  0.366320  0.665144            0.000000               2.769710   \n",
       "  5075  0.542236  0.848438            0.000000               2.769710   \n",
       "  4758  0.542236  0.848438            0.000000              -0.073199   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  4087  0.691785  0.998638            0.000000              -0.130693   \n",
       "  4406  0.501072  0.806529            0.000000              -0.150704   \n",
       "  7111  0.758932  1.065830            0.000000              -0.639943   \n",
       "  426   0.542236  0.848438            0.000000               2.769710   \n",
       "  7925  0.542236  0.848438            0.000000              -1.036715   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3600            1.560940               1.990724      1.401816         1.357870  \n",
       "  1262            1.560940               1.990724      1.401816         1.357870  \n",
       "  8612            1.560940               1.990724      1.401816         1.357870  \n",
       "  5075            1.560940               1.990724      1.401816         1.357870  \n",
       "  4758           -0.061492              -0.043779     -0.058854       -51.983508  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  4087            0.722746              -0.119876     -0.106686         1.185937  \n",
       "  4406           -0.290791              -0.451021     -0.315128         0.236911  \n",
       "  7111           -0.593120              -0.517760     -3.288903        -0.583203  \n",
       "  426             1.560940               1.990724      1.401816         1.357870  \n",
       "  7925           -0.922128              -1.034761     -1.039838        -1.040397  \n",
       "  \n",
       "  [6954 rows x 79 columns],\n",
       "  'X_val_xgb':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "  8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "  6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "  7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "  1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "  5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "  5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "  4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  3586        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7173        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  8559        -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  6528        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  7934         6.205752      -0.376161            -0.564175   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  3749        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1637        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  5820        -0.161141       2.658437            -0.564175   -0.315627   \n",
       "  5757        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4135        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  3586   -0.302787   -0.242425  ...      -0.194111            0.777730   \n",
       "  7173   -0.302787   -0.242425  ...       0.888540           -3.560043   \n",
       "  8559   -0.302787   -0.242425  ...      -0.024116           -0.229157   \n",
       "  6528   -0.302787   -0.242425  ...       0.599833           -2.403304   \n",
       "  7934   -0.302787   -0.242425  ...       2.162613            1.413441   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  3749   -0.302787   -0.242425  ...      -0.158023            0.633138   \n",
       "  1637   -0.302787   -0.242425  ...      -0.001576           -0.943163   \n",
       "  5820   -0.302787   -0.242425  ...       0.527657           -2.114119   \n",
       "  5757   -0.302787   -0.242425  ...       0.055164           -0.260996   \n",
       "  4135   -0.302787   -0.242425  ...      -0.140830            0.767007   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3586  0.317041  0.610786            0.000000               2.769710   \n",
       "  7173  0.542236  0.848438           -0.051555               2.769710   \n",
       "  8559  0.542236  0.848438            0.000000               0.264382   \n",
       "  6528  0.542236  0.848438            0.000000               2.769710   \n",
       "  7934  1.278849  1.610125            0.000000              -0.124232   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  3749  0.265208  0.551091            0.000000               2.769710   \n",
       "  1637  0.542236  0.848438            0.000000             -30.404201   \n",
       "  5820  0.542236  0.848438            0.000000               2.769710   \n",
       "  5757  0.542236  0.848438            0.000000              -0.575032   \n",
       "  4135  0.458141  0.762320            0.000000             -31.792846   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  3586            1.560940               1.990724      1.401816         1.357870  \n",
       "  7173            1.560940               1.990724      1.401816         1.357870  \n",
       "  8559           -0.167200              -0.177864      1.744477        -0.164865  \n",
       "  6528            1.560940               1.990724      1.401816         1.357870  \n",
       "  7934            0.573468              -0.113273      1.383730        -0.086094  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  3749            1.560940               1.990724      1.401816         1.357870  \n",
       "  1637           -0.117736              -0.161268     -0.144270        -0.142626  \n",
       "  5820            1.560940               1.990724      1.401816         1.357870  \n",
       "  5757           -0.674018              -0.693065     -0.137336        -0.342659  \n",
       "  4135           -0.285593              -0.227834     -0.276827        -0.274156  \n",
       "  \n",
       "  [1739 rows x 79 columns],\n",
       "  'X_test_xgb':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  0         -1.165370 -0.112444        1.398797           -0.458742   \n",
       "  1          0.858096 -0.667306       -0.714900           -0.458742   \n",
       "  2         -1.165370  0.164986        1.398797           -0.458742   \n",
       "  3          0.858096  0.650490        1.398797           -0.458742   \n",
       "  4          0.858096 -0.597948       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4272      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  4273       0.858096  0.927920       -0.714900            2.179876   \n",
       "  4274      -1.165370 -0.043087        1.398797           -0.458742   \n",
       "  4275       0.858096  0.234344        1.398797           -0.458742   \n",
       "  4276      -1.165370  0.997278       -0.714900            2.179876   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult CabinDeck_B  \\\n",
       "  0           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  1           -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  2           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  3           -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4           -0.161141      -0.376161             1.772499   -0.315627   \n",
       "  ...               ...            ...                  ...         ...   \n",
       "  4272        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4273        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4274        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4275        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  4276        -0.161141      -0.376161            -0.564175   -0.315627   \n",
       "  \n",
       "       CabinDeck_C CabinDeck_D  ... Age_TotalSpend Age_TotalSpendRatio  \\\n",
       "  0      -0.302787   -0.242425  ...       0.058507           -0.234417   \n",
       "  1      -0.302787   -0.242425  ...      -0.335932           -0.443860   \n",
       "  2       3.302656   -0.242425  ...      -0.085846            0.343953   \n",
       "  3       3.302656   -0.242425  ...       1.405844            0.205772   \n",
       "  4      -0.302787   -0.242425  ...       0.171708           -0.838827   \n",
       "  ...          ...         ...  ...            ...                 ...   \n",
       "  4272   -0.302787   -0.242425  ...      -0.194111            0.777730   \n",
       "  4273   -0.302787   -0.242425  ...      -0.141347            1.094667   \n",
       "  4274   -0.302787    4.124990  ...       0.022419           -0.089824   \n",
       "  4275   -0.302787    4.124990  ...       0.149401            0.143108   \n",
       "  4276   -0.302787   -0.242425  ...      -0.518907            2.079062   \n",
       "  \n",
       "         Age_log  Age_sqrt GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  0     0.542236  0.848438            0.000000               2.769710   \n",
       "  1     0.542236  0.848438            0.000000              -0.142436   \n",
       "  2     0.152709  0.406185            0.000000               2.769710   \n",
       "  3     0.501072  0.806529            0.000000              -0.071246   \n",
       "  4     0.542236  0.848438            0.000000              -0.309187   \n",
       "  ...        ...       ...                 ...                    ...   \n",
       "  4272  0.317041  0.610786           -0.128399               2.769710   \n",
       "  4273  0.656442  0.963286            0.000000              -0.582939   \n",
       "  4274  0.542236  0.848438            0.000000               2.769710   \n",
       "  4275  0.210540  0.484091            0.000000              -0.166296   \n",
       "  4276  0.691785  0.998638            0.000000               2.769710   \n",
       "  \n",
       "       FoodCourt_Dominance ShoppingMall_Dominance Spa_Dominance VRDeck_Dominance  \n",
       "  0               1.560940               1.990724      1.401816         1.357870  \n",
       "  1              -0.118950              -0.130793    -11.947877        -0.115190  \n",
       "  2               1.560940               1.990724      1.401816         1.357870  \n",
       "  3               7.707147              -0.064982     -0.024117         0.062999  \n",
       "  4              -0.279729              -6.195552     -0.271075        -0.268438  \n",
       "  ...                  ...                    ...           ...              ...  \n",
       "  4272            1.560940               1.990724      1.401816         1.357870  \n",
       "  4273          -24.993834              -0.532069     -0.517806        -0.359005  \n",
       "  4274            1.560940               1.990724      1.401816         1.357870  \n",
       "  4275            4.829713              -0.153051     -0.136778         0.137916  \n",
       "  4276            1.560940               1.990724      1.401816         1.357870  \n",
       "  \n",
       "  [4277 rows x 79 columns],\n",
       "  'X_train_sklearn':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3600      -1.165370 -1.985101       -0.714900           -0.458742   \n",
       "  1262      -1.165370 -0.806021       -0.714900           -0.458742   \n",
       "  8612      -1.165370  0.442417        1.398797           -0.458742   \n",
       "  5075      -1.165370 -0.181802        1.398797           -0.458742   \n",
       "  4758       0.858096 -1.083451       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4087       0.858096  0.997278       -0.714900            2.179876   \n",
       "  4406       0.858096  0.650490        1.398797           -0.458742   \n",
       "  7111       0.858096  1.135993       -0.714900            2.179876   \n",
       "  426       -1.165370 -0.320517       -0.714900           -0.458742   \n",
       "  7925       0.858096 -0.528590       -0.714900           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "  3600        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  1262        -0.161141       2.658437            -0.564175          0.0   \n",
       "  8612        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  5075        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4758        -0.161141       2.658437            -0.564175          0.0   \n",
       "  ...               ...            ...                  ...          ...   \n",
       "  4087        -0.161141      -0.376161            -0.564175          1.0   \n",
       "  4406        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  7111        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  426         -0.161141      -0.376161             1.772499          0.0   \n",
       "  7925        -0.161141      -0.376161             1.772499          0.0   \n",
       "  \n",
       "        CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "  3600          0.0          0.0  ...        1.032894            -4.138413   \n",
       "  1262          0.0          0.0  ...        0.419391            -1.680341   \n",
       "  8612          0.0          0.0  ...       -0.230200             0.922323   \n",
       "  5075          0.0          1.0  ...        0.094596            -0.379009   \n",
       "  4758          0.0          0.0  ...       -1.476003            -0.458639   \n",
       "  ...           ...          ...  ...             ...                  ...   \n",
       "  4087          0.0          0.0  ...        0.778193             0.560169   \n",
       "  4406          0.0          0.0  ...       -0.133888             0.819078   \n",
       "  7111          0.0          0.0  ...       -0.313074             1.568173   \n",
       "  426           0.0          0.0  ...        0.166773            -0.668194   \n",
       "  7925          0.0          0.0  ...        0.146632            -0.731514   \n",
       "  \n",
       "         Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3600  0.542236  0.848438            -0.101809               2.769710   \n",
       "  1262  0.542236  0.848438             0.000000               2.769710   \n",
       "  8612  0.366320  0.665144             0.000000               2.769710   \n",
       "  5075  0.542236  0.848438             0.000000               2.769710   \n",
       "  4758  0.542236  0.848438             0.000000              -0.073199   \n",
       "  ...        ...       ...                  ...                    ...   \n",
       "  4087  0.691785  0.998638             0.000000              -0.130693   \n",
       "  4406  0.501072  0.806529             0.000000              -0.150704   \n",
       "  7111  0.758932  1.065830             0.000000              -0.639943   \n",
       "  426   0.542236  0.848438             0.000000               2.769710   \n",
       "  7925  0.542236  0.848438             0.000000              -1.036715   \n",
       "  \n",
       "        FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "  3600             1.560940                1.990724       1.401816   \n",
       "  1262             1.560940                1.990724       1.401816   \n",
       "  8612             1.560940                1.990724       1.401816   \n",
       "  5075             1.560940                1.990724       1.401816   \n",
       "  4758            -0.061492               -0.043779      -0.058854   \n",
       "  ...                   ...                     ...            ...   \n",
       "  4087             0.722746               -0.119876      -0.106686   \n",
       "  4406            -0.290791               -0.451021      -0.315128   \n",
       "  7111            -0.593120               -0.517760      -3.288903   \n",
       "  426              1.560940                1.990724       1.401816   \n",
       "  7925            -0.922128               -1.034761      -1.039838   \n",
       "  \n",
       "        VRDeck_Dominance  \n",
       "  3600          1.357870  \n",
       "  1262          1.357870  \n",
       "  8612          1.357870  \n",
       "  5075          1.357870  \n",
       "  4758        -51.983508  \n",
       "  ...                ...  \n",
       "  4087          1.185937  \n",
       "  4406          0.236911  \n",
       "  7111         -0.583203  \n",
       "  426           1.357870  \n",
       "  7925         -1.040397  \n",
       "  \n",
       "  [6954 rows x 79 columns],\n",
       "  'X_val_sklearn':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  3586      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  7173      -1.165370 -1.707670       -0.714900           -0.458742   \n",
       "  8559       0.858096 -0.251160       -0.714900           -0.458742   \n",
       "  6528      -1.165370 -1.152809       -0.714900           -0.458742   \n",
       "  7934       0.858096  2.592504       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  3749      -1.165370  0.303702        1.398797           -0.458742   \n",
       "  1637       0.858096 -0.944736       -0.714900           -0.458742   \n",
       "  5820      -1.165370 -1.014094       -0.714900           -0.458742   \n",
       "  5757       0.858096 -0.181802        1.398797           -0.458742   \n",
       "  4135       0.858096  0.581132        1.398797           -0.458742   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "  3586        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  7173        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  8559        -0.161141      -0.376161             1.772499          0.0   \n",
       "  6528        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  7934         6.205752      -0.376161            -0.564175          0.0   \n",
       "  ...               ...            ...                  ...          ...   \n",
       "  3749        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  1637        -0.161141       2.658437            -0.564175          0.0   \n",
       "  5820        -0.161141       2.658437            -0.564175          0.0   \n",
       "  5757        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4135        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  \n",
       "        CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "  3586          0.0          0.0  ...       -0.194111             0.777730   \n",
       "  7173          0.0          0.0  ...        0.888540            -3.560043   \n",
       "  8559          0.0          0.0  ...       -0.024116            -0.229157   \n",
       "  6528          0.0          0.0  ...        0.599833            -2.403304   \n",
       "  7934          0.0          0.0  ...        2.162613             1.413441   \n",
       "  ...           ...          ...  ...             ...                  ...   \n",
       "  3749          0.0          0.0  ...       -0.158023             0.633138   \n",
       "  1637          0.0          0.0  ...       -0.001576            -0.943163   \n",
       "  5820          0.0          0.0  ...        0.527657            -2.114119   \n",
       "  5757          0.0          0.0  ...        0.055164            -0.260996   \n",
       "  4135          0.0          0.0  ...       -0.140830             0.767007   \n",
       "  \n",
       "         Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  3586  0.317041  0.610786             0.000000               2.769710   \n",
       "  7173  0.542236  0.848438            -0.051555               2.769710   \n",
       "  8559  0.542236  0.848438             0.000000               0.264382   \n",
       "  6528  0.542236  0.848438             0.000000               2.769710   \n",
       "  7934  1.278849  1.610125             0.000000              -0.124232   \n",
       "  ...        ...       ...                  ...                    ...   \n",
       "  3749  0.265208  0.551091             0.000000               2.769710   \n",
       "  1637  0.542236  0.848438             0.000000             -30.404201   \n",
       "  5820  0.542236  0.848438             0.000000               2.769710   \n",
       "  5757  0.542236  0.848438             0.000000              -0.575032   \n",
       "  4135  0.458141  0.762320             0.000000             -31.792846   \n",
       "  \n",
       "        FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "  3586             1.560940                1.990724       1.401816   \n",
       "  7173             1.560940                1.990724       1.401816   \n",
       "  8559            -0.167200               -0.177864       1.744477   \n",
       "  6528             1.560940                1.990724       1.401816   \n",
       "  7934             0.573468               -0.113273       1.383730   \n",
       "  ...                   ...                     ...            ...   \n",
       "  3749             1.560940                1.990724       1.401816   \n",
       "  1637            -0.117736               -0.161268      -0.144270   \n",
       "  5820             1.560940                1.990724       1.401816   \n",
       "  5757            -0.674018               -0.693065      -0.137336   \n",
       "  4135            -0.285593               -0.227834      -0.276827   \n",
       "  \n",
       "        VRDeck_Dominance  \n",
       "  3586          1.357870  \n",
       "  7173          1.357870  \n",
       "  8559         -0.164865  \n",
       "  6528          1.357870  \n",
       "  7934         -0.086094  \n",
       "  ...                ...  \n",
       "  3749          1.357870  \n",
       "  1637         -0.142626  \n",
       "  5820          1.357870  \n",
       "  5757         -0.342659  \n",
       "  4135         -0.274156  \n",
       "  \n",
       "  [1739 rows x 79 columns],\n",
       "  'X_test_sklearn':       ActiveSpender       Age  AgeGroup_Adult  AgeGroup_MiddleAge  \\\n",
       "  0         -1.165370 -0.112444        1.398797           -0.458742   \n",
       "  1          0.858096 -0.667306       -0.714900           -0.458742   \n",
       "  2         -1.165370  0.164986        1.398797           -0.458742   \n",
       "  3          0.858096  0.650490        1.398797           -0.458742   \n",
       "  4          0.858096 -0.597948       -0.714900           -0.458742   \n",
       "  ...             ...       ...             ...                 ...   \n",
       "  4272      -1.165370  0.373059        1.398797           -0.458742   \n",
       "  4273       0.858096  0.927920       -0.714900            2.179876   \n",
       "  4274      -1.165370 -0.043087        1.398797           -0.458742   \n",
       "  4275       0.858096  0.234344        1.398797           -0.458742   \n",
       "  4276      -1.165370  0.997278       -0.714900            2.179876   \n",
       "  \n",
       "        AgeGroup_Senior  AgeGroup_Teen  AgeGroup_YoungAdult  CabinDeck_B  \\\n",
       "  0           -0.161141      -0.376161            -0.564175          0.0   \n",
       "  1           -0.161141      -0.376161             1.772499          0.0   \n",
       "  2           -0.161141      -0.376161            -0.564175          0.0   \n",
       "  3           -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4           -0.161141      -0.376161             1.772499          0.0   \n",
       "  ...               ...            ...                  ...          ...   \n",
       "  4272        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4273        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4274        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4275        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  4276        -0.161141      -0.376161            -0.564175          0.0   \n",
       "  \n",
       "        CabinDeck_C  CabinDeck_D  ...  Age_TotalSpend  Age_TotalSpendRatio  \\\n",
       "  0             0.0          0.0  ...        0.058507            -0.234417   \n",
       "  1             0.0          0.0  ...       -0.335932            -0.443860   \n",
       "  2             1.0          0.0  ...       -0.085846             0.343953   \n",
       "  3             1.0          0.0  ...        1.405844             0.205772   \n",
       "  4             0.0          0.0  ...        0.171708            -0.838827   \n",
       "  ...           ...          ...  ...             ...                  ...   \n",
       "  4272          0.0          0.0  ...       -0.194111             0.777730   \n",
       "  4273          0.0          0.0  ...       -0.141347             1.094667   \n",
       "  4274          0.0          1.0  ...        0.022419            -0.089824   \n",
       "  4275          0.0          1.0  ...        0.149401             0.143108   \n",
       "  4276          0.0          0.0  ...       -0.518907             2.079062   \n",
       "  \n",
       "         Age_log  Age_sqrt  GroupSpendDeviation  RoomService_Dominance  \\\n",
       "  0     0.542236  0.848438             0.000000               2.769710   \n",
       "  1     0.542236  0.848438             0.000000              -0.142436   \n",
       "  2     0.152709  0.406185             0.000000               2.769710   \n",
       "  3     0.501072  0.806529             0.000000              -0.071246   \n",
       "  4     0.542236  0.848438             0.000000              -0.309187   \n",
       "  ...        ...       ...                  ...                    ...   \n",
       "  4272  0.317041  0.610786            -0.128399               2.769710   \n",
       "  4273  0.656442  0.963286             0.000000              -0.582939   \n",
       "  4274  0.542236  0.848438             0.000000               2.769710   \n",
       "  4275  0.210540  0.484091             0.000000              -0.166296   \n",
       "  4276  0.691785  0.998638             0.000000               2.769710   \n",
       "  \n",
       "        FoodCourt_Dominance  ShoppingMall_Dominance  Spa_Dominance  \\\n",
       "  0                1.560940                1.990724       1.401816   \n",
       "  1               -0.118950               -0.130793     -11.947877   \n",
       "  2                1.560940                1.990724       1.401816   \n",
       "  3                7.707147               -0.064982      -0.024117   \n",
       "  4               -0.279729               -6.195552      -0.271075   \n",
       "  ...                   ...                     ...            ...   \n",
       "  4272             1.560940                1.990724       1.401816   \n",
       "  4273           -24.993834               -0.532069      -0.517806   \n",
       "  4274             1.560940                1.990724       1.401816   \n",
       "  4275             4.829713               -0.153051      -0.136778   \n",
       "  4276             1.560940                1.990724       1.401816   \n",
       "  \n",
       "        VRDeck_Dominance  \n",
       "  0             1.357870  \n",
       "  1            -0.115190  \n",
       "  2             1.357870  \n",
       "  3             0.062999  \n",
       "  4            -0.268438  \n",
       "  ...                ...  \n",
       "  4272          1.357870  \n",
       "  4273         -0.359005  \n",
       "  4274          1.357870  \n",
       "  4275          0.137916  \n",
       "  4276          1.357870  \n",
       "  \n",
       "  [4277 rows x 79 columns],\n",
       "  'categorical_features': ['cat_HomePlanet',\n",
       "   'cat_Destination',\n",
       "   'cat_CabinDeck',\n",
       "   'cat_CabinSide',\n",
       "   'cat_AgeGroup',\n",
       "   'cat_Route',\n",
       "   'CabinDeck_B',\n",
       "   'CabinDeck_C',\n",
       "   'CabinDeck_D',\n",
       "   'CabinDeck_E',\n",
       "   'CabinDeck_F',\n",
       "   'CabinDeck_G',\n",
       "   'CabinDeck_T',\n",
       "   'CabinDeck_Unknown',\n",
       "   'CabinSide_S',\n",
       "   'CabinSide_Unknown',\n",
       "   'CryoSleep',\n",
       "   'CryoSleepSpender',\n",
       "   'Destination_PSO J318.5-22',\n",
       "   'Destination_TRAPPIST-1e',\n",
       "   'HasFamily',\n",
       "   'HomePlanet_Europa',\n",
       "   'HomePlanet_Mars',\n",
       "   'PassengerGroup',\n",
       "   'Route_Earth_to_PSO J318.5-22',\n",
       "   'Route_Earth_to_TRAPPIST-1e',\n",
       "   'Route_Europa_to_55 Cancri e',\n",
       "   'Route_Europa_to_PSO J318.5-22',\n",
       "   'Route_Europa_to_TRAPPIST-1e',\n",
       "   'Route_Mars_to_55 Cancri e',\n",
       "   'Route_Mars_to_PSO J318.5-22',\n",
       "   'Route_Mars_to_TRAPPIST-1e',\n",
       "   'TravelingAlone',\n",
       "   'VIP']}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_optimized_spaceship_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06aae79-c3fa-4544-a3a0-f0b1b3c6fafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
